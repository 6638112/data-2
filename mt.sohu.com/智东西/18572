➜能插5G卡的VR头显！裸手操作XRSPACE一体机，在虚拟世界中“捏”个自己
http://www.sohu.com/a/429914881_115978	14911
<p><img src="http://p4.itc.cn/q_70/images03/20201106/093d03232121475d8a71bdaff61e4c83.png" /></p>
<p><strong>智东西（公众号：zhidxcom）</strong></p>
<p><strong>文 | 信仪</strong></p>
<p>智东西11月5日深圳报道，今天，前HTC CEO周永明的新公司XRSPACE首次携新品亮相中国大陆，发布了XRSPACE Manova VR一体机和虚拟世界平台。</p>
<p>周永明认为，如果将HTC的Vive呈现出的VR形式称为VR 1.0的话，XRSPACE呈现出的则称得上是VR 2.0时代。VR 2.0相对于VR 1.0加入了5G、AI、云以及多人使用的体验，在场景中加入多人互动、多维的场景，让用户用手和语音做交互，使VR体验更加灵活有趣。</p>
<p>在接受智东西的采访时，周永明说，他认为未来虚拟和实际混合的体验将会是后智能手机时代的一个新方向。R代表着Reality，X则是各种虚拟和现实混合的体验，这样结合起来就是他所想象的XR。</p>
<p>智东西此前就报道过XRSPACE及其新品，借助此次机会，智东西记者也在现场亲身佩戴XRSPACE Manova VR一体机，体验了一把虚拟世界里的“KTV”。</p>
<p><img src="http://p0.itc.cn/q_70/images03/20201106/0e355e270ef94bc981a1ebb5da8ee168.jpeg" width="1000" height="667" /></p>            <div class="lookall-box">
<div class="lookall-shadow"></div>
<section class="lookall">
<a href="javascript:;" class="show-all" id="showMore">
<em>展开全文</em>
</a>
</section>
</div>
<div class="hidden-content control-hide">
<p>▲智东西记者与其他媒体记者体验XRSPACE产品</p>
<p>与其他的VR一体机不同的是，以往用户在佩戴上头显后需要在App Store中寻找想进入的内容，而配戴上XRSPACE Monova VR一体机后就可以立即进入虚拟世界。我将手抬起到视野内，虚拟世界中就会出现一个蓝色半透明的手，直接用手就可以实现点击、转移场景、抓取物体等基本动作。</p>
<p>将手掌转向自己并握拳，我的视野内出现了一个选项屏幕，可以通过选择其中的emoji表情或“拍手”“握手”等动作，以动作或表情形式操作自己的虚拟人行为，还能与不同地区的用户进行社交。</p>
<p>据现场的工作人员称，体验区的VR一体机都是连接WiFi的，此外，XRSPACE的VR一体机最重要的一个特色是支持5G，也就是在一体机中插入5G SIM卡，就可以随时拿出一体机进入虚拟世界。</p>
<p>XRSPACE成立三年半以来做了什么？智能手机“教父”，也是HTC Vive创始人周永明所描述的VR 2.0时代到底是什么样子？这个时代就能能为我们带来什么？让我们跟随文章一起来看。</p>
<p>一、加入5G、AI、云实现虚拟世界内多人社交 </p>
<p>在会议伊始，XRSPACE创始人周永明以视频的形式出现在大屏幕上，讲述了自己接触VR的经历。</p>
<p><img src="http://p4.itc.cn/q_70/images03/20201106/2fbecae127e4422a9a5cfb3a0e2154bf.jpeg" width="1000" height="667" /></p>
<p>▲XRSPACE创始人周永明</p>
<p>周永明说：“我在10年前开始接触到VR体验时，就觉得这是自从黑白电影以来，第一次人和内容关系的重大改变。以前观看者和内容是在两个不同的空间里，VR第一次能够让观看的人进入内容，并且成为内容的一部分。之后，我就认为这种沉浸式的互动体验会改变人们的生活及产业发展。”</p>
<p>周永明认为，自从2016年VR设备逐渐面世以来，VR产业还停留在一个小规模产业或仅限游戏内容，还无法突破并进入到一般消费者的生活中。VR 1.0就像是在孤岛上一种笨重的体验，而VR 2.0就是想把这种体验变得有趣、灵活。</p>
<p>VR 2.0在周永明看来是在VR 1.0的基础上叠加了5G、AI、云、多人社交以及用手势和语音交互的体验。这样以来，就可以跨越时空的界限将不同地区的人连接起来，聚合在同一个空间。</p>
<p>为此，XRSPACE做出了虚拟人，由使用者的动作和AI技术调动，有丰富的表情和具备真实感的皮肤。周永明对智东西说：“如果没有虚拟人元件，就不会有很好的沉浸式体验。机器人以及其他粗糙的拟人元件都无法达到虚拟人进入场景的体验。我们过去三年半一直在专注做这个事情。”</p>
<p>所有人都可以通过自拍获取自己的虚拟人，并且可以通过“捏脸”自定义自己虚拟人的形象。这样一来，每一个用户的“虚拟人”都不会“撞脸”且有与现实用户外貌相似的“神韵”。</p>
<p>在XRSPACE Monova的虚拟世界中，有包括教室、唱吧、游戏、会场、操场等各种私人或公众的空间，用户可以和朋友甚至是陌生人在同一个空间互动。</p>
<p><img src="http://p1.itc.cn/q_70/images03/20201106/c5eb63ea406845819fca155428e39234.gif" width="640" height="368" /></p>
<p>▲用户戴上VR头显马上进入虚拟世界</p>
<p>拿教育场景举例，周永明说在虚拟世界中，老师和同学都可以互相看到，老师还可以通过场景的转移带领学生到世界各地进行体验，以此可以增强教育的趣味性。</p>
<p>为了降低一般消费者使用的门槛，XRSPACE采用了“语音+裸手”作为用户操作画面的主要方式，尽量避免使用手柄。</p>
<p>周永明在会上提出，VR 2.0另一个很重要的元件就是5G，VR相对于智能手机更能发挥出5G的优势。未来的XR是一个移动的体验，用户将可以和朋友用眼镜打电话，到那时候5G的价值能展现得更加明显。</p>
<p>此外，周永明也提到了与高通、德国电信，以及百度和中国电信的合作。他说，XRSPACE采用的是高通的骁龙845处理器以支撑虚拟人和裸手操作等技术的运行，并且与德国电信合作致力于消费者体验。</p>
<p>XRSPACE将百度的AI语音互动、百度翻译以及百度云等内容整合，并结合中国电信的VR内容，逐步进入中国大陆市场。</p>
<p>周永明对智东西说，目前VR一体机硬件已经成熟并开始量产了，后续还将进行一些内容的搭配，产品在中国大陆的商业化还需要1~2个月，并且国内的产品售价也正在敲定中。</p>
<p>二、跨平台多终端，配追踪器能在虚拟世界打太极 </p>
<p>接着，XRSPACE大中华区的CEO郑礼崧、CMO格欣以及CPO王宁分别针对公司的产品、内容和战略方面做了解读。</p>
<p>CPO王宁在会上通过屏幕展示了XRSPACE Monova的虚拟世界，这个世界中有包括教室、会议室等的私人空间，也有游乐场、体育场等公共空间。</p>
<p><img src="http://p7.itc.cn/q_70/images03/20201106/be2fe27fad5642589ac1292979b66104.jpeg" width="1000" height="667" /></p>
<p>▲XRSPACE Monova虚拟世界中的各种场景</p>
<p>王宁说，戴上VR头显就似乎进入了一个虚拟的城市，推开一扇门，可能就会进到市中心，可以碰到来自各个省份，甚至是各个国家的人们，在虚拟世界中相逢相聚。</p>
<p>通过一张自拍，XRSPACE就可以在几秒内生成一个与自拍人十分相似的用户专属的虚拟人，并且人物面部细节也能通过应用进行修正。此外，在这里用户还可以搭配不同的服装，创造自己的虚拟人风格。</p>
<p><img src="http://p9.itc.cn/q_70/images03/20201106/bd31810123194766827187d0c2154014.jpeg" width="1000" height="750" /></p>
<p>▲虚拟人</p>
<p>在会上，王宁还展示了自己在虚拟世界中“KTV”内的互动。用户可以在虚拟世界中抓话筒、掷飞镖、投篮。此外，搭配一款拥有6个自由度的追踪器，用户可以将手脚的行动都纳入虚拟场景中，实现在虚拟世界内踢足球、做瑜伽、打太极。</p>
<p><img src="http://p0.itc.cn/q_70/images03/20201106/0e707b71eaaa44689f21af089f5db0c3.gif" width="640" height="368" /></p>
<p>▲用户在虚拟世界中投球、练瑜伽</p>
<p>CMO格欣在会上解构了XR的内容部分。她说，作为一个新亮相的VR平台，XRSPACE Manova虚拟世界中有400多个内容场景免费提供。</p>
<p><img src="http://p4.itc.cn/q_70/images03/20201106/5fd215e8cbeb455e886d6044948c4e9a.jpeg" width="1000" height="667" /></p>
<p>▲格欣和她的虚拟人</p>
<p>在VR内容场景中，游戏是一个非常重要的环节。虚拟世界平台上配备的VR版“愤怒的小鸟”“钓鱼游戏”“滑雪游戏”都能让用户有新体验。</p>
<p>这种新体验体现在“同在感”，也就是用户可以实时、异地、跨平台多终端和朋友一起玩，甚至可以在虚拟世界中创建“英语角”“旅游群组”等小群体，实现线上的“面对面”交互。</p>
<p>而后，XRSPACE大中华区CEO郑礼崧在会上强调了一点，就是XRSPACE的跨平台多终端解决方案。这也就意味着人们不仅可以通过VR头显进入XRSPACE Manova的虚拟世界，还能通过PC、手机和平板进入并参与到虚拟世界中。这样以来，XRSPACE的产品面对的就不仅是拥有VR一体机的用户，而是所有拥有PC、智能手机和平板电脑的用户。</p>
<p><img src="http://p0.itc.cn/q_70/images03/20201106/b99e91b392544768bc91b2dfbec6ffb5.jpeg" width="1000" height="750" /></p>
<p>▲XRSPACE的跨平台多终端解决方案</p>
<p>在此之前，周永明也曾告诉智东西，XRSPACE的跨平台多终端解决方案可以让用户用手边的电子设备进入虚拟世界看到朋友，甚至还能跟他们说话。</p>
<p>结语：“头号玩家”时代或将来临 </p>
<p>“捏”一个自己放到虚拟世界中，并与朋友实现跨越时空的互动是电影《头号玩家》中的场景，或许也是很多人的梦想，而如今周永明和他的团队正在做的就是这样一件事情。</p>
<p>为了做好这件事情，周永明进入各种相关行业学习，团队也从最初的10人扩大到了200人。XRSPACE在现有VR的基础上更加便捷且更具交互性，我们期待几个月后能够在中国大陆真正能进入到XRSPACE Monova的场景中，也梦想着进入一个“真实的虚拟世界”。</p>
➜AWS AI应用科学家邹洋： 领域自适应在识别任务中的研究与应用 | 公开课预告
http://www.sohu.com/a/429930312_115978	23195
<p>识别是计算机视觉中的一类重要且基础的问题，包括图像分类，语义分割，目标重识别（Target re-identification）等。识别在各种智能机器的感知系统中都有广泛的应用，比如自动驾驶汽车，机器人，智能手机，安防系统等。近十年来，深度学习极大程度的提高了各项计算机视觉识别任务的精度。然而，即使通过大量标注样本去训练模型，目前的识别模型仍然缺少泛化性，即对于数据分布和训练样本不同的测试样本，模型的识别能力不高。为此，无监督领域自适应（Domain Adaptation）旨在通过大量的标注样本与无标注样本提高模型在新测试数据中的泛化性能。</p>
<p>在当前的任务中，通常标记的训练（源数据）和未见到的测试（目标数据）之间存在巨大的差异，而无监督域适应（UDA）能够在没有目标域标签的情况下解决这一问题。在ECCV 2018会议上，来自卡内基梅隆大学（CMU）的邹洋博士团队提出了一种通用的领域自适应self-training框架，该框架将问题表述为潜在变量损失最小化，通过在目标数据上交替生成伪标签，并使用这些标签对模型进行再训练来解决。在此基础上，为了以避免大类在伪标签生成中的逐渐占据优势，邹博团队还提出了一种新的类平衡自训练框架，并引入空间先验对生成的伪标签进行精炼。实验结果表明，该方法在多种主要的UDA设置下都能达到最佳的语义分割性能。</p>
<p>深度自我训练是实现无监督领域适应的有效手段，通常需要对目标域进行迭代预测，然后将预测结果作为伪标签进行再训练。然而由于伪标签可能会有噪声，自我训练可能会把过度的标签置信度放在错误的类别上，导致错误传播的偏差解。在ICCV 2019会议上，邹博团队提出一种信心正则化自我训练（CRST）框架，该框架通过交替优化把伪标签看作是连续潜变量进行优化。在此基础上，邹博团队还提出两种置信正则化方法：标签正则化（LR）和模型正则化（MR）。CRST-LR生成软伪标签，而CRST-MR鼓励网络输出的平滑性。大量实验表明，CRSTs的性能优于最先进的非正则化方法。</p>
<p>无监督域自适应同样可以用于行人重识别。在ECCV 2020会议上，邹博团队通过净化待适应的表示空间来改进自适应，提出了一个联合学习框架，该框架可以分离与ID相关/不相关的特征，并强制适应只适用于与ID相关的特征空间。框架包括一个分解模块，该模块将跨域的图像编码为一个共享的外观空间和两个独立的结构空间，以及一个可以共享的空间中执行对抗性对齐和自训练的适应模块。</p>
<p><strong>10月13日上午10点</strong>，智东西公开课邀请到AWS AI应用科学家、CMU博士邹洋参与到「CV前沿讲座」第23讲，带来主题为《领域自适应在识别任务中的研究与应用》的直播讲解。在本讲座的第一部分，邹博将详解一种通用的端到端领域自适应self-training框架。该框架能够简单有效地提高识别模型（图像分类，语义分割）在新测试数据上的泛化性。在本讲座的第二部分，邹博会介绍一种应用于行人重识别的领域自适应算法，该算法设计将特征分离（feature disentanglement）与领域自适应协同互助。在讲座最后，邹博将讨论领域自适应与弱监督/半监督/自监督学习等关键问题的关联与以后可能的发展。感兴趣的朋友一定不要错过！</p>
<p>邹洋现任Amazon Website Service (AWS) AI应用科学家，2020年秋于卡内基梅隆大学电气与计算机工程系获得博士学位，导师是Vijayakumar Bhagavatula。他的主要研究领域为计算机视觉与机器学习，专注于计算机视觉任务中的领域自适应、弱监督/半监督/自监督学习等关键问题，学术成果发表在ECCV、ICCV、CVPR、NeurIPS等领域内重要学术会议，Google Scholar总引用率500余次。邹博曾在美国硅谷英伟达研究院以及美国通用汽车研发部实习，在CVPR 2018领域自适应竞赛获得第三名。</p>
<p><strong>课程内容</strong></p>
<p><strong>课程主题</strong></p>            <div class="lookall-box">
<div class="lookall-shadow"></div>
<section class="lookall">
<a href="javascript:;" class="show-all" id="showMore">
<em>展开全文</em>
</a>
</section>
</div>
<div class="hidden-content control-hide">
<p>《领域自适应在识别任务中的研究与应用》</p>
<p><strong>课程提纲</strong></p>
<p>1、通用的领域自适应self-training框架</p>
<p>2、基于特征分离与领域自适应协同的行人重识别算法</p>
<p>3、领域自适应的发展方向</p>
<p>4、领域自适应与弱监督/半监督/自监督学习等关键问题的关联</p>
<p><strong>讲师介绍</strong></p>
<p>邹洋，Amazon Website Service (AWS) AI应用科学家，2020年秋于卡内基梅隆大学电气与计算机工程系获得博士学位，导师是Vijayakumar Bhagavatula；主要研究领域为计算机视觉与机器学习，专注于计算机视觉任务中的领域自适应、弱监督/半监督/自监督学习等关键问题，学术成果发表在ECCV、ICCV、CVPR、NeurIPS等领域内重要学术会议，Google Scholar总引用率500余次；曾在美国硅谷英伟达研究院以及美国通用汽车研发部实习，在CVPR 2018领域自适应竞赛获得第三名。</p>
<p><strong>直播信息</strong></p>
<p>直播时间：10月13日10:00</p>
<p>直播地点：智东西公开课小程序</p>
<p><strong>加入讨论群</strong></p>
<p>本次课程的讲解分为主讲和答疑两部分，主讲以视频直播形式，答疑以语音或文字形式进行。</p>
<p>加入讨论群，除了可以免费收看直播之外，还能认识讲师，与更多同行和同学一起学习，并进行深度讨论。</p>
<p>添加小助手小开（ID：hikai19）即可申请，备注“姓名-公司/学校/单位-职位/专业”的朋友将会优先审核通过哦~</p>
➜MIT芯片创企获3500万美元融资！押注光学互连赛道，带宽密度提高1000倍
http://www.sohu.com/a/430033827_115978	27015
<p><img src="//p2.itc.cn/q_70/images03/20201106/7c1f90ca28564a88a6977e053492d4e4.jpeg" /></p>
<p><strong>芯东西（公众号：aichip001）</strong></p>
<p><strong>编 | 韦世玮</strong></p>
<p>芯东西11月6日消息，美国芯片创企Ayar Labs获得了3500万美元（约2.32亿人民币）B轮融资，将用于光学互连芯片的研发及解决方案的商业化。</p>
<p>自2015年创立以来，Ayar Labs一直通过利用新的硅处理技术，来开发高速、高密度、低功耗的光学互连芯片，以取代传统的I/O形式。简单地说，该公司希望利用光来实现芯片之间的数据传输，而不是靠传统的铜线传输。</p>
<p>Ayar Labs声称，该解决方案基于麻省理工学院、加州大学伯克利分校、科罗拉多大学博尔德分校的十年研究合作经验，克服了半导体功率和性能伸缩的挑战，以及设备之间互连带宽的瓶颈。</p>
<p>早在2018年11月，Ayar Labs就完成了2400万美元的A轮融资。该轮融资结束后，Ayar Labs的融资总额将超过6000万美元（约3.98亿人民币）。</p>
<p><img src="http://p0.itc.cn/q_70/images03/20201106/84218efe64294471bf5d1f01c129d273.png" width="1000" height="500" /></p>            <div class="lookall-box">
<div class="lookall-shadow"></div>
<section class="lookall">
<a href="javascript:;" class="show-all" id="showMore">
<em>展开全文</em>
</a>
</section>
</div>
<div class="hidden-content control-hide">
<p>▲Ayar Labs联合创始人Chen Sun、Alex Wright-Gladstein、Mark Wade（从左至右）</p>
<p>据了解，Chen Sun和Alex均为麻省理工学院背景，Mark Wade则出身于科罗拉多大学博尔德分校。</p>
<p>一、铜线是芯片晶体管发展的重要挑战 </p>
<p>如何把硅芯片内部的晶体管做的越来越小，是推动计算机革命和电子工业不断发展的重要一步，但电子元器件中晶体管之间的铜互连是发展过程中的重要挑战。</p>
<p>一方面，互连线中的阻容延时（RC延时）阻碍了晶体管收缩的速度；另一方面，即使采用由屏蔽材料制成的绝缘体，铜在小尺寸的情况下仍不可靠。</p>
<p>由于光产生的热量比电要少得多，使得光子电路对热量的要求有限。同时，光子电路还能降低延时，不易受到温度、电磁场及噪音变化的影响。</p>
<p>因此，Ayar Labs将目光放在了光子电路的研发上，通过设计小芯片和多波长激光器来取代基于电子的I/O。</p>
<p>除了Ayar Labs之外，Lightelligence（曦智科技）、LightOn、Lightmatter等芯片创企均在进行光学半导体相关研究。</p>
<p>其中，和Ayar Labs相似，Lightelligence和Lightmatter的创始团队均源自麻省理工学院，且公司均创立于2017年，Lightelligence在2018年获得百度风投和美国半导体财团领投的1000万美元种子轮融资，而Lightmatter在2019年拿到由谷歌风投领投的2200万美元B轮融资。</p>
<p>二、功耗降低10倍，互连带宽密度提高千倍 </p>
<p>Ayar Labs的研发团队认为，这些小芯片能够在功耗降低10倍的情况下，将互连带宽密度提高1000倍，从而为AI、云、高性能计算、5G和激光雷达等应用提供新的系统架构。</p>
<p><img src="http://p5.itc.cn/q_70/images03/20201106/f01091f2a8e749a9b3c2ece97e8c9b22.png" width="1000" height="624" /></p>
<p>例如，Ayar Labs的TeraPhy芯片理论上能够实现数十TB/s的带宽，这主要得益于模块化的多端口设计，其端口拥有8个光通道。</p>
<p>同时，TeraPhy芯片拥有宽的高带宽电接口还可连接到同硅芯片（partner silicon）上。</p>
<p>此外，TeraPhy芯片还有一个名为SuperNova的光源。SuperNova是一个光子集成电路，可产生8或16种波长的光，并将这些光进行多路传输、分配功率，最后放大到8或16个输出端口。</p>
<p>Ayar Labs研究人员谈到，SuperNova能够为256个数据通道提供光，最高带宽相当于8.192 TB/s。</p>
<p>“这些智能光学I/O芯片使SoC公司和系统集成商能够专注于核心功能的集成和流程扩展，同时将I/O任务转移到低功耗、高吞吐量和光学I/O上。”Ayar Labs研究人员谈到，这实现了逻辑链接和物理联合的系统。</p>
<p>结语：摩尔定律放缓，硅光芯片或成新突破口 </p>
<p>随着摩尔定律发展的逐渐放缓，越来越多的学术机构和企业想要通过新材料、新架构、新封装等方式，进一步推动半导体领域的创新发展，而硅光芯片就是近年来一个新的研究方向。</p>
<p>但他们面临的挑战也不止于此。当研发完成后，如何将这些创新性的产品和技术更好地落地、推广，让社会工作及生活实现降本增效，这也是人们需要思考的问题。</p>
<p>文章来源：VentureBeat</p>
➜华为起诉美国FBI等16部门！孟晚舟案两年屈辱，59页报告揭不公
http://www.sohu.com/a/429993619_115978	37111
<p class="ql-align-center"><img src="http://p7.itc.cn/images01/20201106/8ec322eb7df94289ad682165d75e327c.jpeg" max-width="600" /></p>
<p class="ql-align-justify"><strong>智东西（公众号：zhidxcom）</strong></p>
<p class="ql-align-justify"><strong>编 | 李水青</strong></p>
<p class="ql-align-justify">智东西11月6日消息，近日，华为正式起诉美国联邦调查局（FBI）、美国司法部、商务部等<strong>16个部门，</strong>指控这些部门<strong>故意拖延公开多份涉及其首席财务官孟晚舟被捕案的文件</strong>。这些文件据称涉及孟晚舟近两年来遭拘捕、引渡的许多细节，将可能证明拘捕孟晚舟的背后存在政治动机。</p>
<p class="ql-align-center"><img src="http://p8.itc.cn/images01/20201106/c68a323da9d04c0495958f28c4e2f9d0.png" max-width="600" /></p>
<p class="ql-align-justify">孟晚舟于2018年12月1日被加拿大政府以所谓的“欺诈和串谋欺诈以规避美国对伊朗的制裁”理由被拘捕。近两年过去了，事件多出周折，不见更多的治罪证据，孟晚舟也没有被释放。2020年5月，孟晚舟案件的第一轮审理已经结束，当下已开始第二轮审理。目前，她仍戴着一条监测脚环在异国加拿大，被人全天候监视。</p>
<p class="ql-align-center"><img src="http://p6.itc.cn/images01/20201106/1bb5179aca394d1c9d90063a988aeb81.png" max-width="600" /></p>            <div class="lookall-box">
<div class="lookall-shadow"></div>
<section class="lookall">
<a href="javascript:;" class="show-all" id="showMore">
<em>展开全文</em>
</a>
</section>
</div>
<div class="hidden-content control-hide">
<p class="ql-align-justify">孟晚舟案情的走向令许多国人牵挂。这不仅因为涉事公司是华为，涉事人是华为创始人任正非的女儿，更因为这个案件在很多人心里一定程度代表着，中国人和及中国企业是否真的走出过去“落后挨打”的阴霾，在国际交往中是否<strong>被公平、公正地对待</strong>。</p>
<p class="ql-align-justify">华为本次如何起诉美国政府16部门？孟晚舟案件是否将迎来重大进展？让我们从这份长达59页的起诉书说起。</p>
<p class="ql-align-justify">一、华为要求美加部门公布通信记录</p>
<p class="ql-align-justify">本次华为起诉的部门包括美国国土安全部、司法部，商务部、联邦调查局、国务院等16个部门。华为公司在美国提出诉讼，控告美国政府这16个部门故意拖延公开多份涉及孟晚舟被捕案的文件。</p>
<p class="ql-align-justify">文件包括美国<strong>多个部门之间关于此案的通信记录，以及美执法人员拘捕行动前与加拿大警方及边境服务局的通信记录</strong>。诉讼要求获得一些政府机构之间的相关文件，例如美国国土安全部、司法部以及白宫之间的联络文件，以及美国一些部门“参与调查或拘捕孟晚舟的加拿大当局”之间的通信记录。</p>
<p class="ql-align-justify">华为公司律师说，有迹象表明，美国希望通过对华为及孟晚舟的刑事指控“达到与司法正义无关的政治目的”。</p>
<p class="ql-align-justify">起诉书中列出了孟晚舟被引渡更可能的原因，包括干涉<strong>华为公司在5G市场的“主导地位”、增加在与中国贸易谈判中的筹码等。 </strong></p>
<p class="ql-align-center"><img src="http://p4.itc.cn/images01/20201106/dd7b59043daf461185ef60b93a5c61a0.png" max-width="600" /></p>
<p class="ql-align-justify">孟的律师引用了CNN关于美国总统唐纳德·特朗普（Donald Trump）言论的报道，暗示他愿意在与中国的贸易战中将她用作讨价还价的筹码。但我们打开诉讼中的CNN新闻链接发现，该稿件已经消失不见。</p>
<p class="ql-align-center"><img src="http://p7.itc.cn/images01/20201106/21c58e17fad94567b6f51962753c962a.png" max-width="600" /></p>
<p class="ql-align-justify">起诉书中还提到许多<strong>程序不正当的案件细节</strong>，比如，加拿大当局串谋协助联邦调查局进行调查，在加拿大皇家骑警逮捕孟晚舟之前，让加拿大边境服务局官员在没有律师的情况下<strong>用特权对孟进行了三个小时的讯问。</strong></p>
<p class="ql-align-center"><img src="http://p5.itc.cn/images01/20201106/baea562bb240425799ee01e101bd4124.jpeg" max-width="600" /></p>
<p class="ql-align-justify">▲孟晚舟在CBSA监护期间没有律师的情况下被讯问</p>
<p class="ql-align-justify">华为称，早在一年前就依据美国《信息自由法案》赋予的权利向美政府部门提出了12项信息披露要求。尽管法律规定“申请快速处理的要求通常应在20个工作日内给予答复”，但华为几乎没有获得任何回复。</p>
<p class="ql-align-justify">起诉书称，“此案可能存在的很多问题一定程度上反映了政府诚信度影响公众的信心。”相关部门有必要尽快公开相关文件。目前，被起诉的美国政府部门没有任何回复。</p>
<p class="ql-align-justify">二、孟晚舟案两年回顾，审理第一阶段在5月结束</p>
<p class="ql-align-justify">加拿大政府于2018年12月1日逮捕了华为的首席财务官孟晚舟，当时她正在温哥华飞往墨西哥的途中。逮捕是应美国政府美国地方法院纽约州东区的要求进行的，最初的指控是“欺诈和串谋欺诈以规避美国对伊朗的制裁”。</p>
<p class="ql-align-justify"><strong>实际上，美国的单方面制裁是违反国际法的行为</strong>。与伊朗进行贸易往来在加拿大几乎不是犯罪，指控不能促成引渡。</p>
<p class="ql-align-justify">而后，新的罪责被扣了上来，孟晚舟“涉嫌欺诈汇丰银行子公司”。荒谬的是，该<strong>银行是英国公司（HSBC），“犯罪”发生在香港，被告是中国人，而逮捕是在加拿大。</strong></p>
<p class="ql-align-center"><img src="http://p5.itc.cn/images01/20201106/66ac7939467948c9af34e9677f76cc46.png" max-width="600" /></p>
<p class="ql-align-justify">由此孟晚舟开始了漫漫无期被圈禁的生活。</p>
<p class="ql-align-justify"><strong>2020年5月27日，孟晚舟案件审理的第一阶段节点到来</strong>。主审本案的不列颠哥伦比亚省高等法院法官作出第一次判决，<strong>驳回了孟晚舟律师提出的“引渡不符合双重犯罪标准”的这个理由</strong>。</p>
<p class="ql-align-justify"><strong>孟晚舟的律师认为</strong>，加拿大没有参与对伊朗的制裁，因此，孟晚舟代表华为公司与伊朗进行商业活动，在加拿大不算违法。<strong>而法官的判决认为</strong>，孟晚舟对汇丰银行存在的欺诈行为在加拿大也是犯罪，因此符合双重犯罪标准。</p>
<p class="ql-align-justify">欲加之罪，何患无辞。孟晚舟对汇丰银行欺诈指控背后的真相明显存疑。后续有幻灯片和电子邮件实际上表明，在孟晚舟作证之前以及会议期间，汇丰银行已获悉Skycom和华为之间的关系，因此有关欺诈的指控没有成立。</p>
<p class="ql-align-justify">尽管存在争议，<strong>案件审理的第一阶段在5月27日结束</strong>。</p>
<p class="ql-align-justify">三、案件审理进入第二阶段，聚焦“程序正义”</p>
<p class="ql-align-justify">随后，案件审理进入了第二阶段，这一阶段审理是<strong>围绕“孟晚舟的逮捕和引渡过程中是否存在程序滥用”。</strong></p>
<p class="ql-align-justify">孟晚舟的律师认为，对孟晚舟的指控和逮捕存在<strong>三种程序滥用的情况</strong>：</p>
<blockquote>
1、政治干预，也就是美国政府利用逮捕孟晚舟来达到其他目的；
</blockquote>
<blockquote>
2、加拿大执法部门逮捕孟晚舟的过程存在“不当行为”；
</blockquote>
<blockquote>
3、误导法庭，检方代表美国提交的证据存在重大遗漏等。
</blockquote>
<p class="ql-align-justify"><strong>自10月26日开始，庭审进入交叉询问阶段</strong>。这一阶段主要了解对孟晚舟的逮捕过程是否存在“程序滥用”的情况，以及情况是否足以终止引渡程序。<strong>交叉询问将在今年12月之前完成</strong>。</p>
<p class="ql-align-justify">目前，孟晚舟仍以软禁的形式生活，他以1千万美元的保释金获释。作为保释条件的一部分，她在脚踝上戴了一条监测脚环，并由私人保安人员全天候监视。</p>
<p class="ql-align-justify">按照不列颠哥伦比亚省高等法院的审理安排，<strong>预计案件的审理将在2021年4月份结束</strong>。如果法官接受辩方律师终止引渡程序的要求，则引渡程序就将提前结束，孟晚舟便可回国。</p>
<p class="ql-align-center"><img src="http://p8.itc.cn/images01/20201106/1434bfcb46be4399a8c84494373035ae.jpeg" max-width="600" /></p>
<p class="ql-align-justify">四、最新进展：加拿大执法人员承认多处操作不当</p>
<p class="ql-align-justify">就在<strong>10月30日，孟晚舟引渡案一轮聆讯结束</strong>，暴露出加拿大执法部门在拘捕过程中存在众多程序问题。</p>
<p class="ql-align-justify">在此轮为期5天的聆讯中，来自加拿大皇家骑警和边境服务局的3名证人先后出庭，接受控辩双方交叉询问。交叉询问中<strong>首次公开了孟晚舟2018年12月1日在温哥华国际机场被捕的一些具体过程。</strong></p>
<p class="ql-align-justify"><strong>前半程出庭的是加皇家骑警警官温斯顿·叶</strong>（Winston Yep），他承认，在行动前提交给法官的一份宣誓书描述孟晚舟与加拿大“没有关联”，他在未作背景信息核实的情形下签字。而在孟晚舟被捕前一天的晚上，他发现内容与事实不符，但并未作出更正或任何补救措施。</p>
<p class="ql-align-justify">也就是说，<strong>该警员没有在宣誓书中向法官提供准确的内容，且明知宣誓书中有错误却不及时更正。</strong></p>
<p class="ql-align-justify">除此之外，叶没有按照原计划在飞机上立即逮捕孟晚舟，也没有遵照检方事先要求，在行动后写一份事件时间表。对于改变行动计划等诸多细节信息，叶回应称自己已“记不清”。这些不合规和信息缺漏的地方让人不得不怀疑。</p>
<p class="ql-align-justify"><strong>聆讯后半程出庭应询的主要是加边境服务局官员柯克兰（</strong>Scott Kirkland）。他表示，行动前获悉孟晚舟被加边境服务局的系统列为“国家安全”警戒人物。但在对孟盘查后，他认为她并不涉及国家安全问题。</p>
<p class="ql-align-justify">柯克兰表示，自己收缴了孟晚舟的手机并放入美国联邦调查局提供的防射线袋中，当时并不确定皇家骑警会否将物品交给美方。</p>
<p class="ql-align-justify">他承认，自己“无意之中”将写有孟晚舟手机密码的纸条连同手机交给了皇家骑警，而这一<strong>做法基本上已违反隐私法</strong>。他说，自己为此感到心痛和头疼。</p>
<p class="ql-align-justify">孟晚舟律师团队认为，该案存在程序滥用，故应中止引渡程序，并为此设置三条分支线进行申诉。</p>
<blockquote>
其一是以美方高层政治人物表态证明此案的政治属性；
</blockquote>
<blockquote>
其二是论证加执法部门在机场拘押孟的过程中存在程序滥用；
</blockquote>
<blockquote>
其三是指出美方向加官方提供的案件记录等文件具有误导性，存在重大遗漏和错误陈述。
</blockquote>
<blockquote>
此轮聆讯属于第二分支。
</blockquote>
<p class="ql-align-justify">由于质询证人的进度慢于预期，法庭对后续排期作出调查，下一轮聆讯将在11月中旬展开。</p>
<p class="ql-align-justify">结语：中国企业需要在国际上被公平对待</p>
<p class="ql-align-justify">距离孟晚舟被捕已经过去近两年了，当下随着多轮审讯的推进，案件和拘捕引渡过程的更多细节证据也被披露出来，但探寻更多证据的长夜仍在继续。</p>
<p class="ql-align-justify">当下，孟晚舟案件已经不仅仅是关于一起个人、企业的案件，而成为国人牵挂的标志性事件。因为在很多人心中，它也意味着中国企业在国际交往中是否被公平、公正的对待，世界各国的科技、经济是否能够获得平等公平的机会取得发展。</p>
➜首届tinyML技术论坛（亚洲分论坛）将于11月16日至19日线上直播！
http://www.sohu.com/a/429998500_115978	38868
<p>当国内还在热火朝天的谈论5G、 IoT、 大数据、 超算、 视觉识别、 智能监控、 车联网、 无人机 等等热门主题的时候，当人们还在寻找人工智能行业下一个最具商业前景的发展方向，专注于视觉和语音技术，纠结于提高算力、创新算法模型、大数据存储标记清洗的时候，太平洋彼岸已经悄然开启了在低功耗边缘侧人工智能，即tinyML这一垂直细分上的第三轮交流与发展， 一轮又一轮的企业间访谈、平台支持、线下线上互动、研讨讲座、学术探讨多维度多层次交流层出不穷。</p>
<p><strong>究竟何为tinyML</strong><strong>？ </strong><strong>t</strong><strong>inyML魅力何在？未来市场何在？</strong></p>
<p>相信在座各位非学术专业、非这一方向的观众一时都不能讲清楚。</p>
<p>引述EEFOCUS的iot101君在之前发布的一篇对tinyML看法的文章中的定义：<strong>在终端和边缘侧的微处理器上实现的机器学习过程就叫做tiny Machine Learning(即tinyML).</strong></p>
<p>如果您和我一样还是觉得拗口，难于理解这一定义，那么我们先来看看它面向的是哪些对象市场—-</p>
<p>1）分布最广的物联网设备。</p>
<p>在即将到来的IoT时代，或者AIoT时代。万物互联是大势所趋，人物互联、物物互联，物理世界全面升级到数字世界。哪怕工厂里犄角旮旯的各台设备，只要使用MCU（微型控制单元），就是数字世界里可追踪到的一个tinyML载体。</p>
<p>2）智能家居网联设备。</p>
<p>既然是AIoT时代，智能家居这一方向的所有接入必然不能缺席！这也是为何阿里、华为、腾讯、百度、小米、海尔、美的等国内一线，国外Amazon、Honeywell、Google NEST、Ecobee、Philips、Samsung…的主攻方向。</p>
<p>3）(消费电子)数字移动设备、可穿戴设备。</p>
<p>以手机为首、随身的、移动的、可穿戴的各类设备也都是tinyML的载体。</p>
<p>4）长时在线安防、监控设备。</p>
<p>那些长时在线、常期在网的，尤其电池驱动的安防、监控设备（包括无人机等）。</p>
<p>……其他等等（欢迎补充）</p>
<p>由此我们得知tinyML具备几个特征：</p>
<p>低功耗(超低乃至低于1mW)、长在线(超长待机或在线)、电池驱动(或新能源以满足长在线)， 当然既然他挂着Machine Learning的旗号，那么必然与提供AI算力的芯片有关（诸如ARM、Qualcomm、Infinieon、SynSense等）、与AI算法有关（CNN卷积神经网络、）、与算法框架有关（诸如谷歌的TensorFlow、脸书的Caffe2、百度的paddle paddle、华为的MindSpore等）、与AI基础技术有关（诸如NLP自然语言处理、ASR语音识别等）、与大量端侧应用有关（诸如小型无人机、无人搬运车AGV、移动端智慧金融/智慧医疗/智慧教育/个人助理/智能出行、AR/VR/MR、等等）</p>            <div class="lookall-box">
<div class="lookall-shadow"></div>
<section class="lookall">
<a href="javascript:;" class="show-all" id="showMore">
<em>展开全文</em>
</a>
</section>
</div>
<div class="hidden-content control-hide">
<p>当国内的IoT伴随着华为领先的5G技术即将进入一个新的时代场景，人工智能也正好从云端走向边缘侧、端侧。</p>
<p>处于边缘侧、端侧的设备往往需要更快速的响应（5G下的低延时场景）、更多的推理运算（云端训练，边缘推理），因此发展边缘侧的机器学习变得越发重要。</p>
<p>加上超低功耗的加持，这一领域的影响力正在持续发酵，市场也将随AIoT+5G的发展呈现爆发式增长。</p>
<p>根据 IDC 的分析，到 2025 年，全球创建的数据中，超过四分之一的数据在本质上都是实时数据，而物联网实时数据将占这部分数据的 95%以上。属于数据分析的全球数据总量将增长至原来的 50 倍，达到 5.2ZB；而机器学习所“触及”的分析数据总量将增长至原来的 100 倍，达到 1.4ZB。另外，目前全球有 2500 亿个微控制器在各地运行。 IC Insights 预测，到 2023 年，微控制器的年出货量将增长到 382 亿个。</p>
<p>这显然是一个前景无比巨大的市场。</p>
<p>因此也就不难理解为何大洋彼岸tinyML的活动仅仅举办了2届高峰论坛，就有如此多的国际一线企业、业内独角兽初创公司和知名院校云集于此了：谷歌、高通、脸书、微软、三星、苹果、意法半导体、ARM、英伟达、IBM、Greenwaves、PixART Imaging、BubbleLabs、Byteflies、OctoML、Syntiant、Qeexo、KU鲁汶大学、普林斯顿大学、密歇根大学、埃里克斯霍尔姆大学、加州大学伯克利分校、苏黎世大学、苏黎世联邦理工、麻省理工学院、斯坦福大学等等…参会者中高管（创始人、决策者、研发/技术总监）占90%以上。</p>
<p>2019年成立的tinyML® Foundation正是这个活动的组织者，这是一个由工程师们自发构建的社群，专注于“全栈式”的发展，包括使用案例、应用、 软件、 工具、算法、硬件、专用集成电路(ASICs)、设备、半导体制造等。每年举办多场交流活动，将“产”“学”“研”进行深度融合，并完整覆盖整个生态体系。目前为满足这个方向上的需求，已经将tinyML Summit美国峰会扩容至欧洲分论坛、亚洲分论坛和tinyML研究峰会，以及更多的周期性tinyML访谈、tinyML Meetups线下互动。</p>
<p>TinyML 的出现，是为了更好的缓解边缘 ML 和云端 ML 中，无法突破的多种问题，包括数据隐私、网络带宽、时间延迟、可靠性和能源效率。</p>
<p>我们有理由相信在当前软硬件协同设计、开发的趋势下，顺着5G+AIoT的发展浪潮，tinyML将在软件、硬件、应用三大方向上分别获得巨大的成功！</p>
<p>Tiny的世界并不微小，相反，它是巨大的，将构建我们难以想象的超大而美好的未来！</p>
<p><strong>立即</strong><strong>登记，免费报名！</strong></p>
<p>http://testconx.mikecrm.com/hQ21nMc</p>
<p><img src="http://p1.itc.cn/q_70/images03/20201106/691d14a14aa54a9ea1948d4195f8b2fa.jpeg" width="45" height="300" /></p>
➜英特尔AI百佳边缘计算专场下周开启，两位大牛主讲边缘AI计算在牧场生物安全防控中的应用以及3D人脸识别系统｜直播预告
http://www.sohu.com/a/430013940_115978	43999
<p><img src="http://p4.itc.cn/q_70/images03/20201106/69777382697a41e8bd8d4ae1baee06f0.jpeg" /></p>
<p>按照IDC的统计数据，到2020年将有超过500亿的终端与设备联网，未来超过50%的数据需要在网络边缘侧分析、处理与储存。Gartner也将边缘计算列为2020年十大战略技术趋势之一。</p>
<p>相比云计算，边缘计算的信息处理、收集、存储都放在距离信息源更近的位置，避免了数据传输带来的延迟问题，由于计算、存储都在本地进行，安全性也更高。不过终端设备往往算力有限，并且对功耗要求较高，因此给边缘计算相关的产品设计和实际应用开发带来了诸多的挑战。</p>
<p>在实际的产品设计和应用开发中，如何选择最合适的硬件，如何高效利用边缘计算设备有限的硬件资源，实现最优的边缘计算方案，是开发者们在不断思考的问题。</p>
<p>11月12日晚7点，智东西公开课联合英特尔推出的英特尔AI百佳创新激励计划边缘计算专场将开讲，由英特尔AI百佳创新激励计划优秀企业代表小龙潜行、小钴科技共同参与，小龙潜行产业数据中心总监孙胜男、小钴科技CTO Richard Li博士将分别带来主题讲解。其中：</p>
<p>孙胜男老师将以《边缘AI计算在牧场生物安全防控中的应用》为主题，从牧场生物安全防控的现状、基于边缘AI计算的生物安全智能防控系统、利用OpenVINO加速系统的图像识别效率以及牧场数字化生物安全的未来发展等方面，为我们带来系统讲解；</p>
<p>Richard Li博士将以《基于Intel Movidius &amp; RealSense的3D人脸识别系统》为主题，从3D人脸识别的应用前景、搭建3D人脸识别系统的考量因素，结合小钴科技基于Intel Movidius &amp; RealSense的3D人脸识别系统方案及其在智能门锁、支付、安防等方面的应用，详解3D人脸识别系统的应用及开发实现。</p>
<p><strong>课程时间</strong></p>
<p>直播时间：11月12日晚7点</p>
<p>直播地点：智东西公开课小程序</p>
<p><strong>专场详情</strong></p>            <div class="lookall-box">
<div class="lookall-shadow"></div>
<section class="lookall">
<a href="javascript:;" class="show-all" id="showMore">
<em>展开全文</em>
</a>
</section>
</div>
<div class="hidden-content control-hide">
<p>主题一：边缘AI计算在牧场生物安全防控中的应用</p>
<p>讲师：小龙潜行产业数据中心总监孙胜男</p>
<p>提纲：</p>
<p>1、牧场生物安全防控的现状</p>
<p>2、基于边缘AI计算的牧场生物安全智能防控系统</p>
<p>3、利用OpenVINO加速系统的图像识别效率</p>
<p>4、牧场数字化生物安全的未来</p>
<p>主题二：基于Intel Movidius &amp; RealSense的3D人脸识别系统</p>
<p>讲师：小钴科技CTO Richard Li</p>
<p>提纲：</p>
<p>1、3D人脸识别的应用前景</p>
<p>2、搭建3D人脸识别系统的考量因素</p>
<p>3、利用Intel Movidius &amp; RealSense快速搭建3D人脸识别系统</p>
<p>4、应用案例分享</p>
<p>讲师：</p>
<p>孙胜男，小龙潜行产业数据中心总监，生物安全智能防控系统产品负责人，资深人工智能产品设计师，擅长结合技术及场景的产品打造，在机器视觉、语音识别、语义理解、知识图谱类产品都有丰富的产品研发经验，参与产品包括服务机器人、智能家居、智能音箱等。</p>
<p>Richard Li博士，小钴科技CTO，主要研究方向为3D视觉、边缘计算。在IJCAI、ACM MM、JSA等国际顶级期刊会议上发表论文40余篇，申请发明专利20余项。</p>
<p><strong>报名方式</strong></p>
<p>添加智东西公开课小助手甜甜（ID：hitian20）报名，添加时请备注“姓名-公司/学校-职位/专业”，因报名人数过多，优先通过备注者。</p>
<p><strong>四期招募</strong></p>
<p>“英特尔AI百佳创新激励计划”为入选企业提供技术、产业、生态的多重加速。目前，第四期正在招募当中，点击「链接」（https://4m.cn/8Lf5u）免费报名申请。</p>
➜基于视觉的机器人抓取-从物体定位、位姿估计到抓取位姿估计 | 公开课预
http://www.sohu.com/a/430021902_115978	46713
<p>CV前沿讲座，是智东西公开课针对计算机视觉推出的一档讲座，聚焦于计算机视觉前沿领域研究成果与进展。我们将持续邀请研究者、专家与资深开发者，为大家带来直播讲解。</p>
<p>抓取是机器人的基本和重要的任务之一。机器人抓取所必须的信息是相机坐标系下抓取器的6DoF位姿，包括抓取器的3D位置和抓取器的3D空间朝向，通过控制机械臂的移动使抓取器到该位置和旋转，然后执行抓取操作。而基于视觉的机器人抓取，是通过给机器人安装RGB-D相机，利用人工智能算法，获取抓取器的目标抓取位姿，按照抓取方式的不同，可以分为2D平面抓取和6D空间抓取。 </p>
<p>2D平面抓取是指目标物体放置在水平工作台上，抓取器只能从一个方向进行抓取。而6D空间抓取是指抓取器可以在3D空间从各个角度抓取物体。两种抓取方式，自然有不同的实现方法。</p>
<p>2D平面抓取因为存在一些限制，抓取器的6D位姿可简化为3D，包括平面内的2D位置和平面内的1D旋转角度，主要分为评估抓取接触点质量和评估带朝向的抓取四边形两种方法。</p>
<p>6D空间抓取按照依赖物体的完整形状还是物体的部分点云，又可以分为基于部分点云的方法和基于完整形状的方法。当前大多数6D空间抓取都是针对已知3D模型的物体，这些物体的最优抓取位置可以通过人工指定货仿真预先得到，此时，6D空间抓取就转化为了估计物体的6D位姿。</p>
<p>同时，由于大部分机器人抓取的方法都需要先输入数据然后才能获得目标物体的位置，因此又可以分为三个阶段：物体定位、位姿估计和抓取位姿估计。那么基于视觉的机器人抓取到底需要什么样的技术呢？又有什么样的方法呢？不同的方法之间又有哪些优劣势呢？<strong>11月6日晚8点</strong>，智东西公开课邀请到达闼科技3D研发负责人、北京师范大学博士杜国光参与到「CV前沿讲座」第22讲，带来主题为《基于视觉的机器人抓取-从物体定位、位姿估计到抓取位姿估计》的直播讲解。</p>
<p>杜国光博士将深度解析基于视觉进行机器人抓取中所涉及的三大模块，包括物体定位、物体位姿估计和抓取位姿估计。其中，物体定位包括定位不识别、目标检测以及目标实例分割；物体位姿估计包括基于对应的方法、基于模板的方法以及基于投票的方法；抓取位姿估计分为2D平面抓取和6D抓取。在最后，杜博也会详解传统的方法和基于深度学习的方法，并对相关方法进行对比，指出未来的研究方向与挑战。</p>
<p>杜国光，北京师范大学博士，目前是达闼科技3D研发负责人。他的研究方向为3D视觉感知，包括3D检测/分割、物体6D位姿估计、机器人抓取等，并在相关期刊和会议上发表论文二十余篇。</p>
<p><strong>课程内容</strong></p>
<p><strong>课程主题</strong></p>
<p>《基于视觉的机器人抓取-从物体定位、位姿估计到抓取位姿估计》</p>
<p><strong>课程提纲</strong></p>
<p>1、视觉机器人抓取的流程与关键技术</p>
<p>2、物体定位技术的研究</p>            <div class="lookall-box">
<div class="lookall-shadow"></div>
<section class="lookall">
<a href="javascript:;" class="show-all" id="showMore">
<em>展开全文</em>
</a>
</section>
</div>
<div class="hidden-content control-hide">
<p>3、物体位姿估计的方法解析</p>
<p>4、2D平面与6D空间机器人抓取位姿估计</p>
<p>5、方法对比与未来的研究方向和挑战</p>
<p><strong>讲师介绍</strong></p>
<p>杜国光，达闼科技3D研发负责人，北京师范大学博士，研究方向为3D视觉感知，包括3D检测/分割、物体6D位姿估计、机器人抓取等，在相关期刊和会议上发表论文二十余篇。</p>
<p><strong>直播信息</strong></p>
<p>直播时间：11月6日20:00</p>
<p>直播地点：智东西公开课小程序</p>
<p>答疑地址：智东西公开课讨论群</p>
<p><strong>加入讨论群</strong></p>
<p>本次课程的讲解分为主讲和答疑两部分，主讲以视频直播形式，答疑将在「智东西公开课讨论群」进行。</p>
<p>加入讨论群，除了可以免费收看直播之外，还能认识讲师，与更多同行和同学一起学习，并进行深度讨论。</p>
<p>添加小助手糖糖（ID：hitang20）即可申请，备注“姓名-公司/学校/单位-职位/专业”的朋友将会优先审核通过哦~</p>
➜Tengine开发者专场下周直播，开源大牛圈圈虫主讲Tengine快速入门与NPU开发实践 | 直播预告
http://www.sohu.com/a/430022450_115978	46934
<p><img src="http://p3.itc.cn/q_70/images03/20201106/e99ac1e8a6ae47df927ce75da44ab92d.jpeg" /></p>
<p>今年4月8日，智东西公开课联合OPEN AI LAB(开放智能)策划推出Tengine开发者专场。第1讲由OPEN AI LAB联合创始人&amp;Tengine首席架构师王海涛主讲，主题为《Tengine – 嵌入式AI框架的挑战和实践》。王海涛老师从嵌入式AI面临的挑战出发，深度解析了Tengine的框架结构以及推理API的组成，并针对个性化算子的定制和在CPU/GPU/DSP/NPU上Run一个Graph进行了实际演示。</p>
<p>11月10日晚7点，OPEN AI LAB的AI推理框架资深架构师唐琦将参与Tengine开发者专场第2讲，围绕《Tengine快速入门与NPU开发实践》这一主题进行直播讲解。唐琦是开源圈知名大牛，圈圈虫是他在开源社区被更多人所知晓的名字。唐琦拥有9年嵌入式AI芯片全栈工作经验，致力于AI技术端侧技术的工业落地，在网络模型压缩、低比特量化上有丰富的工程经验。他同时也是NCNN开源框架开源社群核心维护者、Tengine开源框架负责人。</p>
<p>Tengine，是由OPEN AI LAB公司推出的一款专为AIoT场景设计，同时具有跨平台、异构调度、芯片底层加速、超轻量无依赖、完整开发移植部署工具链等特点的商用级AIoT智能开发平台，致力于解决AIoT产业链碎片化问题，加速AI产业化落地。</p>
<p>从今年7月开始，OPEN AI LAB对Tengine的性能进行了全面升级。作为对原Tengine整体软件架构重构的全新下一代产品，新一代Tengine基于纯C打造，将轻量化无依赖做到极致，适合在各种软硬件资源受限的嵌入式环境下使用部署轻量的AI算法模型用于语音、视觉等应用。</p>
<p>在本次专场中，唐琦将先后对Tengine的前世今生、Tengine的整体架构以及框架重构后的优势与特性进行讲解。同时，他将带来代码实践，教大家实现基于Tegninge框架和开源卡片电脑Khadas VIM3的人脸检测，从而快速上手Tengine进行开发。从事AIoT开发或者对AIoT开发感兴趣的开发者们一定不要错过！</p>
<p><strong>课程介绍</strong></p>
<p><strong>课程主题</strong></p>
<p>《Tengine快速入门与NPU开发实践》</p>
<p><strong>课程提纲</strong></p>
<p>1、Tengine的前世今生</p>
<p>2、整体架构介绍</p>
<p>3、Tengine框架的优势与特性</p>
<p>4、代码实践：基于Khadas VIM3（CPU/NPU）+ Tengine实现人脸检测</p>
<p><strong>讲师介绍</strong></p>
<p>唐琦（圈圈虫），OPEN AI LAB（开放智能）AI推理框架资深架构师；9年嵌入式AI芯片全栈工作经验，致力于AI技术端侧技术的工业落地，在网络模型压缩、低比特量化上有丰富的工程经验；同时也是AI开源社区资深专家，NCNN开源框架开源社群核心维护者、Tengine开源框架负责人。</p>
<p><strong>直播信息</strong></p>
<p>直播时间：11月10日晚7点</p>
<p>直播地点：智东西公开课小程序</p>
➜AI侵入艺术天堂！艺术也可以“量产”了吗？
http://www.sohu.com/a/430027544_115978	48268
<p><img src="http://p7.itc.cn/q_70/images03/20201106/168a46c82a844c3ca4e9b877b9eb453d.png" /></p>
<p><strong>智东西（公众号：zhidxcom）</strong></p>
<p><strong>编 | 子佩</strong></p>
<p>智东西11月6日消息，机器人运输、机器人对我们来说都已不再陌生，但你看过机器人跳舞吗？AI翻译、AI语音已经成为我们日常生活必不可少的一部分，但你看过AI编排的舞蹈吗？</p>
<p>而AI不仅为舞蹈带来了新的活力，也引起了不小争论，今天就随着智东西一起，看看舞蹈世界里的AI故事。</p>
<p>一、与机器人共舞：打破编舞“旧”界限 </p>
<p>在一个杂乱的仓库中，舞者慢慢弓起身子，伸出双臂，不远处的聚光灯冷冷地照在她身上，一切都没有什么不同，不过是一场聚光灯下曼妙的舞蹈。</p>
<p>但随后一件怪事却发生了，聚光灯开始自己移动，并跟着音乐的节奏左右摇摆，似乎是在回应舞者。舞者和聚光灯像在跳着双人舞，很快就分不清是谁在引导着谁，但很清楚的是正在跳舞的是一个高9英尺、重500磅的机器人，它被称为ABB IRB 6700，是世界上最大的工业机器人之一。</p>
<p><img src="http://p8.itc.cn/q_70/images03/20201106/068c64d9ea91488884cb5f338cb130a9.png" width="1000" height="1394" /></p>            <div class="lookall-box">
<div class="lookall-shadow"></div>
<section class="lookall">
<a href="javascript:;" class="show-all" id="showMore">
<em>展开全文</em>
</a>
</section>
</div>
<div class="hidden-content control-hide">
<p>▲Catie Cuan的表演（图源：Sam Berube）</p>
<p>这个舞蹈是编舞兼舞者Catie Cuan为普拉特学院一个项目准备的节目。</p>
<p>虽然与机器人共舞听起来像是科幻小说，但对于正在斯坦福大学修读机械工程博士学位的Catie Cuan来说，这更像是一部分的生命延伸到机器人身上。</p>
<p>在历史上，我们通常都自然而然地认为舞蹈是一种舞者为观众准备的表演，并且潜意识地假设双方都应该是人类。</p>
<p>所以当机器人为人类表演舞蹈时，很多人都感到不可思议，特别是当Cuan通过与机器人共舞来探索艺术形式的外部界限时。</p>
<p>Cuan的研究项目之一就是将爵士乐和芭蕾舞的基本节奏、动作转化为机器人关节的角度，并创造出她所谓的“一群机器人的芭蕾舞”，即将他们的固有特性应用到机器人舞蹈。</p>
<p>这种固有特性指的是：机器人没有收缩、放松的肌肉，可以精准设置关节的扭矩——这与普通人类的舞蹈完全不同。</p>
<p>这也是为什么很多舞蹈学家认为在机器人身上实现舞蹈美感是不可能的，因为机器人的机械结构完全不能适应传统舞蹈中身体松弛和发力的方式。但Cuan认为：“我们可以把AI当成一种编舞工具，它可以破坏我们惯性的舞蹈方式。”</p>
<p>二、Living Archive动作图库：编舞不用想 </p>
<p>在机器人舞蹈领域，Sydney Skybetter是其中的引领者，他是前舞蹈家，也是布朗大学的舞蹈学教授。在布朗大学，他的学生以科学的方式走进舞蹈，基于机器学习创造可以和舞者互动的机器人。</p>
<p>Skybetter、Cuan和一群艺术家一起，尝试通过技术开创舞蹈的新天地。其中，编舞家Merce Cunningham与电子艺术家Thecla Schiphorst一起，用一个名为LifeForms的软件程序创造舞蹈动作。</p>
<p>“ Trackers（1991）”是Cunningham用LifeForms制作的第一支舞蹈，其中大约三分之一的动作是计算机提供的。当时他说，该软件拓宽了编舞的想象。</p>
<p>20世纪末，动作捕捉、可穿戴技术和虚拟现实技术已经出现，但最早将AI应用到舞蹈的是编舞家Trisha Brown，她在2005年通过一个程序控制在舞台幕布上的投影，以配合舞者的动作。</p>
<p>在过去的五年中，谷歌的艺术、文化部门一直与包括Bill T. Jones/Arnie Zane Company和Martha Graham Dance Company在内的舞蹈艺术家合作，进行舞蹈领域的AI应用。</p>
<p>去年，谷歌与编舞家Wayne McGregor合作发布了Living Archive：一个包含500万个动作的互动图集。</p>
<p>Living Archive允许用户选择一些动作并构建整支舞蹈，或者用户也可以在镜头前跳舞，在数据库里找到最接近的视觉匹配，以此作为基础编完一整支舞。</p>
<p>谷歌的该项目负责人Damien Henry也为McGregor开发了更先进的机器学习算法。</p>
<p>将Living Archive中已有的数据库和McGregor100个小时的舞蹈录像作为训练数据，该算法可以通过摄像头捕获McGregor的动作，然后立刻提供30种“McGregor”式的编舞方案。McGregor和他的团队可以基于算法的推荐，更轻松地进行编舞。</p>
<p>Henry说：“有时算法会提出舞者不愿做的建议。但是McGregor也意识到这种建议有时候非常有用，因为它会迫使舞者去探索不熟悉的领域。”</p>
<p>2019年7月，McGregor的团队在洛杉矶音乐中心首演了基于该项合作的长达30分钟的作品“生活档案：人工智能实验（Living Archive: An AI Performance Experiment）”。</p>
<p><img src="http://p6.itc.cn/q_70/images03/20201106/db5dd631c48b4455818b49e438ded5d5.png" width="1000" height="667" /></p>
<p>▲iving Archive: An AI Performance Experiment（图源Cheryl Mann）</p>
<p>三、半人马座的奇妙冒险：从行星到希腊悲剧 </p>
<p>但一些舞蹈艺术家也认为AI超出了它作为工具的用途，反而影响了舞蹈“本源”的艺术性。</p>
<p>丹麦舞蹈剧院的艺术总监Pontus Lidberg开始使用AI作为他的舞蹈编排中不可或缺的一部分，表现人与机器之间紧张关系。</p>
<p>Lidberg于2019年与计算机艺术家Cecilie Waagner Falkenstrom合作，他们表示：“不想要那些可以找到模式的东西，那很无聊，我们想创造一些能真正触动我们的东西。”</p>
<p>为了实现这一目标，他们设计一种获取大量信息的AI（名为大卫）：从行星运动到希腊悲剧的结构和符号学。</p>
<p>Lidberg说：“大卫理解了更多不同形式的动作，也学会了我的舞蹈风格。在对这些知识解构后，再与人类舞者一起磨合，我们就可以创造了全新的事物。”</p>
<p>丹麦舞蹈剧院基于该AI模型设计的舞蹈剧目正在欧洲巡演，由于AI编舞的不可知性，每次的舞蹈剧目也被称为“半人马座”（Centaur），是独特而又不可预测的事件。Lidberg认为这充分说明了人类与技术的关系：未知而又相互依存。<span></span></p>
<p><img src="http://p4.itc.cn/q_70/images03/20201106/7e5dfa9eb42e414b9376c2408e946634.png" width="1000" height="669" /></p>
<p>▲丹麦舞蹈剧院Pontus Lidberg的“半人马座”表演（图源：Per Morten Abrahamsen）</p>
<p>随着越来越多的编舞者在AI的帮助下解构和重新定义他们的手艺，他们经常面临这样一个问题：人类的创造会在什么时候被机器接管？</p>
<p>反对AI创造艺术的观点与AI本身一样古老：从道德上讲，AI是可憎的，它使艺术创作变得廉价。</p>
<p>着有《人工智能》一书的哈佛大学哲学教授Sean D.Kelly在2019年的MIT的《技术评论》写了一篇令他担忧的事情：“我们将人工智能视作比我们优越得多的机器，我们自然会将所有的创造归功于它们。如果发生这种情况，那不是因为机器已经超越了我们，而是我们在贬低自己。”</p>
<p>但是对于那些从事舞蹈和人工智能的人来说，这种观点似乎是宿命。</p>
<p>Lidberg说：“有意识的AI是不存在的，那只是科幻电影。无论机器和算法如何智能化，人类和心灵仍然是舞蹈的灵魂。”</p>
<p>结语：舞蹈的灵魂，AI不可替代 </p>
<p>用AI编舞的Skybetter同样坚信：“没有人的存在，这些技术都无法真正存在。AI编舞的每个阶段都需要人的存在：编程、喂数据并设计算法以实现目标。AI还没智能到可以自己编排自己的地步，人类学习舞蹈都很不容易了，更别说计算机了。”</p>
<p>Waagner Falkenstrom说：“艺术需要人类的头脑，来识别出那些令人兴奋的地方。”</p>
<p>Lidberg同意：“AI可以取代所有人。但是，一位真正的艺术家是无法替代的。”</p>
<p>利用AI编舞的McGregor一方面肯定了人工智能的潜力，一方面也表示“没有什么可以取代人类。”</p>
<p>怀疑者或仍有一种本能的偏见，即人类对艺术的全部所有权。但不可置疑的是，即使AI或机器人可以帮助人类编舞或者伴舞，但AI和机器人都难以复刻艺术家和观众之间的精神连接，就像机器人难以感受或模仿舞者身体和情绪上的变化一样。</p>
<p>参考信源：The New York Times</p>