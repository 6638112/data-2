➜如果中国要做自己的GPT-3，一定离不开这家公司的算力
http://www.sohu.com/a/421170398_610300	14449
<p>边策 发自 凹非寺 </p>
<p>量子位 报道 | 公众号 QbitAI </p>
<p style="text-align: left;">今年AI领域最火的是什么？ </p>
<p style="text-align: left;">毫无疑问是GPT-3，它能写小说、能与人聊天、能设计网页、还能下象棋，堪称迄今为止最“全能”的AI模型。</p>
<p style="text-align: center;"><img src="http://p3.itc.cn/q_70/images03/20200927/605211a1cd154cef9c4ab694f434b018.png" /></p>
<p style="text-align: left;">但是这个强大的AI模型却不被看做算法的胜利，而是“暴力美学”、一场“富人的游戏”。</p>
<p style="text-align: left;">有人估算过，GPT-3光是训练成本就在460万美元以上，还不包括微软为训练它建设了一个5亿美元的超算中心。</p>
<p style="text-align: left;">微软这个超算中心装载了一万张英伟达GPU，训练GPT-3消耗了它355个GPU年的算力。</p>
<p style="text-align: center;"><img src="http://p3.itc.cn/q_70/images03/20200927/50ccd580006f4303817e43e6ba02ed7d.jpeg" /></p>
<p style="text-align: left;">如果中国也要开发自己的GPT-3，凭借现在的技术能做出来？</p>            <div class="lookall-box">
<div class="lookall-shadow"></div>
<section class="lookall">
<a href="javascript:;" class="show-all" id="showMore">
<em>展开全文</em>
</a>
</section>
</div>
<div class="hidden-content control-hide">
<p style="text-align: left;">答案是：我们已经具备一定的条件了。</p>
<p style="text-align: left;">AI软件方面，国内有百度、阿里等开源框架，中国的NLP（自然语言处理）技术起步不算晚，甚至搜狗、第四范式、百度NLP算法已经多次占据测试榜首，且成功商业化。</p>
<p style="text-align: left;">训练AI的硬件中国也不缺乏，甚至在国际上还略有优势。据2020年6月最新数据，中国拥有全球超算Top500中的226台，占比达45.2%，超过其他任何国家。</p>
<p style="text-align: center;"><img src="http://p2.itc.cn/q_70/images03/20200927/d011adc974144d2b9cfaf82f8d8c7e0f.png" /></p>
<p style="text-align: left;">有算法、有硬件，那么要做出GPT-3最大的障碍就是经济成本了。</p>
<p style="text-align: left;">因为中国少有能像微软那般“财大气粗”组建一个超级算力中心，国内AI硬件又不够开放，算力得不到有效的调配和释放。</p>
<p style="text-align: left;">其实不仅是GPT-3，即使是规模更小的AI模型，动辄耗费几十乃至上百张AI加速卡，对很多企业来说也是“不能承受之重”。</p>
<p style="text-align: left;">尤其是比开发GPT-3更现实的问题——AI产业化——方兴未艾，大量使用AI硬件的场景只会更多。</p>
<p style="text-align: left;">对此问题的解决之道，国内最大的AI服务器提供商浪潮给出的方法是：开放硬件，降低成本。</p>
<p style="text-align: center;"><img src="http://p7.itc.cn/q_70/images03/20200927/efaf4aa809a34c54975ec926576e19fd.jpeg" /></p>
<p style="text-align: left;">据估计，未来人工智能将占据80%以上的计算需求，需要有开放的AI算力中心承载这种需求，即 <strong>智算中心</strong>。 </p>
<p>智算中心：做最开放AI基础设施 </p>
<p style="text-align: left;">开源这件事，在软件行业已经取得了巨大成功。</p>
<p style="text-align: left;">开源软件近二十年来为IT行业带来了革命性的变化，比如Linux、Android一举占领市场，而很多闭源操作系统日渐式微乃至消亡。</p>
<p style="text-align: left;">而硬件开源在国际上才刚刚起步。</p>
<p style="text-align: left;">2011年，由于业务的飞速发展，国外社交网络巨头Facebook牵头发起了OCP（开放计算项目）。</p>
<p style="text-align: left;">仅仅4年时间，OCP就为Facebook节省了20亿美元的成本，数据中心电费降低了20%。谷歌、微软、IBM、阿里、浪潮都加入了该社区。</p>
<p style="text-align: center;"><img src="http://p2.itc.cn/q_70/images03/20200927/fe3d721ddbce4daaa2243a5e9c6e618c.png" /></p>
<p style="text-align: left;">开放计算的优势不仅仅是降低成本、节省电费、提高投资回报率，更重要的是，它作为一种新的协作模式，可以推动AI等前沿技术的标准化与产业化。</p>
<p style="text-align: left;">在GPT-3诞生前的几个月，浪潮已经有了这样改造AI产业的想法。4月9日，IPF2020浪潮云数据中心合作伙伴大会上，浪潮首次提出了“智算中心”的概念。</p>
<p style="text-align: left;">浪潮认为，智算中心应该满足三大条件： <strong>开放标准、集约高效、普适普惠</strong>。就是每家企业都能以更低门槛用上高性能计算资源。 </p>
<p style="text-align: center;"><img src="http://p5.itc.cn/q_70/images03/20200927/1f9f48dd11594c419de85be5f415a010.png" /></p>
<p style="text-align: left;">当前AI硬件加速器处于各自为政的局面，不同厂商的产品接口、协议都不尽相同。</p>
<p style="text-align: left;">为了解决AI加速芯片的统一标准问题，让不同加速器在同一块服务器上运行。浪潮4月推出了第一款符合OAM（OCP加速模块）标准的AI开放计算系统MX1，致力于推动开放计算与AI的融合。</p>
<p style="text-align: center;"><img src="http://p4.itc.cn/q_70/images03/20200927/3fc613b5bd6f4ee5ad270aacfa5a89ba.png" /></p>
<p style="text-align: left;">第二点集约高效，则是在开放标准基础上的更高要求。开放标准会带来规模空前的集约效应与高效的融合架构。</p>
<p style="text-align: left;">融合架构的最终目的是实现“智算中心即计算机”，CPU、内存、AI加速器、I/O等硬件资源完全池化，让它们在软件的统一调配下，实现超大规模的扩展。</p>
<p style="text-align: left;">这方面，国外的AI巨头英伟达已经有相当丰富的经验，甚至今年还开源了大规模并行计算模型“威震天”。</p>
<p style="text-align: center;"><img src="http://p6.itc.cn/q_70/images03/20200927/209cbdac8d794b9e8a1424dc59d1d67d.jpeg" /></p>
<p style="text-align: left;">作为AI时代最重要的芯片公司，英伟达显然已经意识到，开源不仅不会损害自身利益，反而会形成规模效应，实现整个产业的共赢。开放标准后，普适普惠是必然的结果。</p>
<p style="text-align: left;">过去十年，手机行业正是凭借软件开放、硬件整合的能力，让普通消费者享受到了智能手机普及的福利。</p>
<p style="text-align: left;">AI产业也在经历类似的过程，软件与硬件的开源一定会让每家意在用上AI的企业享受到实惠。</p>
<p>打造算力“免费午餐” </p>
<p style="text-align: left;">软件开源最大的实惠即“免费”，这意味着任何人都可以免费查看、修改、使用代码，而硬件开放的实惠，是小企业也可以免费使用昂贵的计算设备运行其业务。</p>
<p style="text-align: left;">浪潮AI&amp;HPC产品线总经理刘军曾说过，算力是AI时代“免费的午餐”。</p>
<p style="text-align: center;"><img src="http://p6.itc.cn/q_70/images03/20200927/4b8216addfc14daca0eedf21e8293ca2.jpeg" /></p>
<p style="text-align: left;">回顾GPT-3的诞生，它只比前辈GPT-2晚一年，比前代的参数量增加了100倍，就能取得如此惊人的成就，靠的不是算法的提升，而是算力的加成。</p>
<p style="text-align: left;">如果改进算法，一定会投入大量的研发，相比之前，算力不就是简单直接的“免费午餐”吗？</p>
<p style="text-align: left;">之所以企业不觉得免费，那是因为算力的成本还不够低。所以有些企业选择了市场上成熟的AI解决方案，无需AI开发经验就能快速部署AI模型。</p>
<p style="text-align: left;">刘军表示，对于产业用户来说，用上性价比更高的AI算力，开放的网络架构及服务是必须的，同时保证了未来的可扩展性。</p>
<p style="text-align: left;">就如同PC时代的组装机，每个组件都掌握在用户自己手中，在技术上可控，定制化程度高，成本低廉。</p>
<p style="text-align: left;">只有硬件成本低了，算力才会成为“免费的午餐”。</p>
<p>浪潮智算中心已崭露头角 </p>
<p style="text-align: left;">智算中心推出半年，浪潮智算中心的算力得到权威标准认可，同时在各行各业发挥出重要作用。</p>
<p style="text-align: left;">面向智算中心，浪潮提出要生产算力、聚合算力、调度算力、释放算力。</p>
<p style="text-align: left;">通过自研的AI框架LMS，浪潮训练的NLP模型参数突破70亿，超过了GPT-2三倍多。</p>
<p style="text-align: center;"><img src="http://p5.itc.cn/q_70/images03/20200927/aa54568b14b541f6b7b35b711aae9b7d.jpeg" /></p>
<p style="text-align: left;">在今年7月29日公布的全球权威AI测试基准，MLPerf v0.7训练榜单上，浪潮NF5488A5服务器创下了单服务器最快性能记录，高居榜首。</p>
<p style="text-align: left;">浪潮还东南大学合作，据张竞慧教授介绍，东南大学依靠算力中心推动前沿科学研究，依托(CPU+Openstack+GPU)架构，提供高性能计算、云计算以及人工智能计算等共享服务，处理太空观测高分辨率影像，已经在物理学顶级期刊PRL上发表了多篇论文。</p>
<p style="text-align: center;"><img src="http://p3.itc.cn/q_70/images03/20200927/d31c9b6bb70d48668eae8ec1729e1188.jpeg" /></p>
<p style="text-align: left;">此外浪潮的智算中心与5G结合，提供了云端训练、边缘推理的新应用场景。</p>
<p style="text-align: left;">浪潮智算中心建设的脚步没有停歇，目前正在济南建设的“中国算谷”，致力于成为全球算力产业新高地，带动山东传统企业智能化改造和升级，计划建成E级计算系统。</p>
<p>AI时代的“发电厂” </p>
<p style="text-align: left;">AI模型发展一日千里，模型越来越大，对算力要求也越高，硬件进步给算法带来福利。</p>
<p style="text-align: left;">OpenAI去年的报告指出，AI计算量每年增长10倍。从2012年至今，最先进AI模型对计算量的需求已经增长了30万倍，若按照摩尔定理，与此同时芯片算力只增长了7倍。</p>
<p style="text-align: left;"><img height="auto" width="2052" src="http://p1.itc.cn/q_70/images03/20200927/13353a119bbc4038a016e62e8c800d7d.jpeg" /></p>
<p style="text-align: left;">对算力的爆炸式一方面靠AI加速芯片的改进，另一方面靠硬件的“暴力”堆砌。</p>
<p style="text-align: left;">然而单个用户难以自建强大算力，则需要智算中心来帮忙。未来，智算中心会像发电厂一样，产生大量的算力输送到“千家万户”。</p>
<p style="text-align: left;">电力时代有充足的发电量，就能驱动更多、更强的电气设施。AI时代有更多低廉的算力资源，才能催生出更多像GPT-3一样“暴力”AI模型，推动AI的产业化。</p>
<p style="text-align: left;">如果中国也要研发像GPT-3一样的AI模型，用这样的AI模型驱动产业变革，那么一定要降低算力资源的TCO。</p>
<p style="text-align: center;"><img src="http://p9.itc.cn/q_70/images03/20200927/750a5b2ba3214b788b82ebda7b5710a2.jpeg" /></p>
<p style="text-align: left;">浪潮希望在这个中发挥主导作用，所以推出智算中心。浪潮也具有这样的底气，因为他们已经占据了中国50%的AI计算中心算力，未来一定会是“新基建”的AI基石。</p>
<p style="text-align: left;">在这方面，国外已经有许多先进的经验，英特尔、微软、谷歌都在以开放的姿态融合更多新的AI硬件，把更强大的算力贡献给产业。</p>
<p style="text-align: left;">回到国内，如果浪潮能把智算中心的算力供给全行业使用，以国内庞大市场，一定能催生更强大AI模型的诞生。</p>
<p style="text-align: left;">到时候，不仅能产生与GPT-3类似的AI模型，我们还会看到过更多AI技术的商业化，让我们的生活处处充满AI。</p>
<p>— <strong>完</strong>— </p>
<p><span>本文系网易新闻•网易号特色内容激励计划签约账号【量子位】原创内容，未经账号授权，禁止随意转载。</span></p>
<p><strong>CNCC2020 | 图灵奖得主、院士、名企专家将做特邀报告</strong></p>
<p><strong>CNCC2020</strong>将于 <strong>10月22-24日</strong>在 <strong>北京新世纪日航饭店</strong>（主会场）、多个城市分会场以及 <strong>线上</strong>举行。首批特邀讲者官宣确认，图灵奖得主、院士、名企专家将在CNCC2020做特邀报告。 </p>
<p>早鸟票即将售罄，欢迎报名参与~ </p>
<p><span style="font-size: 16px;"><strong>量子位 </strong></span><span style="font-size: 16px;">QbitAI · 头条号签约作者</span></p>
<p>վ'ᴗ' ի 追踪AI技术和产品新动态</p>
<p><span>一键三连「分享」、「点赞」和「在看」</span></p>
<p><span>科技前沿进展日日相见~</span></p>
➜Windows XP源代码泄露，外媒从中发现隐藏Mac主题
http://www.sohu.com/a/421170815_610300	14449
<p>晓查 发自 凹非寺 </p>
<p>量子位 报道 | 公众号 QbitAI </p>
<p><img height="auto" width="780" src="http://p6.itc.cn/q_70/images03/20200927/06c554ee869a4fceb848f396b53589a7.png" /></p>
<p><strong>△</strong>Windows XP系统默认壁纸 </p>
<p style="text-align: left;">本周，微软的Windows XP和Windows Server 2003系统源代码在网上泄漏。这两大操作系统源代码的种子文件已在 <strong>4chan</strong>论坛上被传开，泄露文件大小为 <strong>42.9GB</strong>。 </p>
<p style="text-align: left;">该帖出现4小时后即被封存。</p>
<p><img height="auto" width="1188" src="http://p4.itc.cn/q_70/images03/20200927/fbd3f2a6bc3e46a38a2870b6fbbf5f96.png" /></p>
<p><strong>△</strong>泄露的Windows代码，图片来自Twitter用户@RoninDey </p>
<p style="text-align: left;">这是Windows XP代码第一次公开泄漏，泄漏文件声称，这些代码其实已秘密共享多年。</p>
<p style="text-align: left;">外媒The Verge确认了这份代码的真实性，微软表示正在调查此事。</p>            <div class="lookall-box">
<div class="lookall-shadow"></div>
<section class="lookall">
<a href="javascript:;" class="show-all" id="showMore">
<em>展开全文</em>
</a>
</section>
</div>
<div class="hidden-content control-hide">
<p style="text-align: left;">源代码泄漏不太可能对Windows XP构成任何重大威胁，因为微软已经在2014年终止了对Windows XP的支持。但由于XP系统过于经典，至今仍占有1.26%的市场份额。</p>
<p><img height="auto" width="1362" src="http://p1.itc.cn/q_70/images03/20200927/acacf8dc1ef34d8eb19fe5ebc86a4a89.png" /></p>
<p style="text-align: left;">虽然已停止支持，但在2017年，由于勒索病毒WannaCry爆发，微软破例为Windows XP系统紧急发布了安全漏洞补丁。</p>
<p style="text-align: left;">这次XP系统代码泄漏并不是微软第一次操作系统源代码遭公开。</p>
<p style="text-align: left;">几年前，有至少1GB的Windows 10相关源代码泄漏。几周前，微软最新游戏机Xbox Series X图形源代码被盗，并在网上公开。</p>
<p>泄露的Mac主题 </p>
<p style="text-align: left;">本次源代码还泄露一个被尘封近20年的“秘密”。</p>
<p style="text-align: left;">The Verge还发现，代码中有一个标签为“ Candy”的主题，尽管该主题不完整，但其“开始”按钮以及其他各种按钮等UI元素与苹果当年Mac OS X的Aqua主题界面高度相似。</p>
<p><img height="auto" width="1820" src="http://p4.itc.cn/q_70/images03/20200927/14f2cdf8f63c47cc8ed06ace544074cb.png" /></p>
<p><strong>△</strong>Windows XP上的类Mac主题 </p>
<p style="text-align: left;">该主题在代码中被描述为“Whistler skin with eye candy” ，并标记为“仅供内部使用”。Whistler是Windows XP的开发代号。</p>
<p style="text-align: left;">最终，微软确定在XP使用了经典蓝色绿色为主的Luna主题。</p>
<p><img height="auto" width="365" src="http://p8.itc.cn/q_70/images03/20200927/d35ad52dac344b3081f73ede042ec568.png" /></p>
<p style="text-align: left;">上世纪90年代，苹果层在其开发者大会上用标语嘲讽微软，称“Redmond，启动你的复印机”，Redmond是微软美国总部所在地。苹果公司还针对Windows Vista的缺陷开展了“获取Mac”广告活动。</p>
<p style="text-align: left;">其实两家公司都有相互借鉴的方面，Windows受经典Mac OS的影响很大，苹果也借用了Windows的某些功能，尤其是在窗口、导航、控制面板以及浏览文件和文件夹等方面。</p>
<p>— <strong>完</strong>— </p>
<p><span>本文系网易新闻•网易号特色内容激励计划签约账号【量子位】原创内容，未经账号授权，禁止随意转载。</span></p>
<p><strong>CNCC2020 | 图灵奖得主、院士、名企专家将做特邀报告</strong></p>
<p><strong>CNCC2020</strong>将于 <strong>10月22-24日</strong>在 <strong>北京新世纪日航饭店</strong>（主会场）、多个城市分会场以及 <strong>线上</strong>举行。首批特邀讲者官宣确认，图灵奖得主、院士、名企专家将在CNCC2020做特邀报告。 </p>
<p>早鸟票即将售罄，欢迎报名参与~ </p>
<p><span style="font-size: 16px;"><strong>量子位 </strong></span><span style="font-size: 16px;">QbitAI · 头条号签约作者</span></p>
<p>վ'ᴗ' ի 追踪AI技术和产品新动态</p>
<p><span>一键三连「分享」、「点赞」和「在看」</span></p>
<p><span>科技前沿进展日日相见~</span></p>
➜高通，看见了AI芯片的“多面”
http://www.sohu.com/a/421176456_610300	14449
<p>萧箫 发自 凹非寺 </p>
<p>量子位 报道 | 公众号 QbitAI </p>
<p style="text-align: left;">AI芯片行业，正面临着层出不穷的需求。</p>
<p style="text-align: center;"><img src="http://p4.itc.cn/q_70/images03/20200927/7007414ff71b4f4e97ccdddb1dcc1de7.gif" /></p>
<p style="text-align: left;">据Research and Markets预测，数据中心的AI芯片 <span>（即AI加速器）</span>市场规模将从2018年的28.4亿美元，增长到2023年的211.9亿美元。 </p>
<p style="text-align: left;">AI芯片，分为训练和推理，前者用来“做模型” <span>（跑大量数据、调整参数）</span>，后者则用来“出结果” <span>（实时检测、目标跟踪）</span>。 </p>
<p style="text-align: left;">“做模型”就像是产品加工，在“工厂”里完成，但模型出来后，就不局限在“工厂”中了，还能部署到手机、汽车等设备上使用。</p>
<p style="text-align: center;"><img src="http://p6.itc.cn/q_70/images03/20200927/eb2fbb82e561463ab9b80579661d43fb.png" /></p>
<p style="text-align: left;">这里的“工厂”，通常是 <strong>云端</strong>，那里有大量服务器部署；而手机、汽车等设备，被称为 <strong>边缘</strong><span>（终端）</span>，也是AI模型真正需要用到的地方。 </p>
<p style="text-align: left;">可以看出，AI训练芯片只靠绝对算力——只要算力越高，模型训练得就越快。</p>            <div class="lookall-box">
<div class="lookall-shadow"></div>
<section class="lookall">
<a href="javascript:;" class="show-all" id="showMore">
<em>展开全文</em>
</a>
</section>
</div>
<div class="hidden-content control-hide">
<p style="text-align: left;">但手机和汽车等设备，受体积、储能、实时等诸多限制和要求，算力已不再是单一的考虑条件。</p>
<p style="text-align: left;">AI推理芯片不仅看算力，还要讲究时延、功耗和成本。</p>
<p style="text-align: left;">相对于AI训练芯片，AI推理芯片需求量更高，使用场景也更广泛。</p>
<p style="text-align: left;">市调机构Tractica称，预计从2018到2025年的7年时间里，AI推理芯片将有10倍的增长，至2025年可达170亿美元。</p>
<p style="text-align: center;"><img src="http://p9.itc.cn/q_70/images03/20200927/752454edfd08402d828f0102cb6df70f.png" /></p>
<p style="text-align: left;">事实上，无论是算力、还是硬件要求，边缘推理芯片的设计都要比云端更复杂。</p>
<p style="text-align: left;">处在野蛮生长阶段的AI芯片市场，做好云端推理芯片已非易事，入局边缘芯片还会更难。</p>
<p style="text-align: left;">但高通却做出了尝试。</p>
<p>18个月，性能领跑行业 </p>
<p style="text-align: left;">2019年4月，高通宣布推出Cloud AI 100芯片，称它是“为满足急剧增长的云端AI推理处理的需求而设计”、“让分布式智能可以从云端遍布至用户的边缘终端，以及云端和边缘终端之间的全部节点。”</p>
<p style="text-align: left;">那时候，市场上也有部分人士持并不看好的态度。一些观点认为，2019年再入局云端AI芯片、并赶超最先进的云端AI推理芯片，似乎为时已晚。</p>
<p style="text-align: left;">而18个月过后，Cloud AI 100芯片在ResNet-50上的测试效果流出，引爆了行业内的深水炸弹。</p>
<p style="text-align: left;">从图中来看，横轴是功耗 <span>（越小越好，图中右边更小）</span>；纵轴是吞吐量 <span>（越高越好）</span>。 </p>
<p style="text-align: center;"><img src="http://p6.itc.cn/q_70/images03/20200927/e40fd57917814da08c8cbb6cd4b45f82.png" /></p>
<p style="text-align: left;">即使是英伟达最新Ampere架构的A100芯片，吞吐量也不到25000，耗能却超过了300W。</p>
<p style="text-align: left;">从功耗来看，英特尔的Goya可低达100W，但吞吐量只能达到15000左右。</p>
<p style="text-align: left;">相比之下，高通的Cloud AI 100 PCle， <strong>吞吐量超过25000，却只需要75W</strong>。 </p>
<p style="text-align: left;">这样的芯片性能，听起来让人难以置信。</p>
<p style="text-align: left;">而且，这个75W的芯片，支持最高每秒400万亿次 <span>（400TOPS）</span>的算力。 </p>
<p style="text-align: left;">高通到底在云端AI推理芯片上“施了什么魔法”？</p>
<p style="text-align: left;">先来看看它的 <strong>内部结构</strong>： </p>
<blockquote>
<p style="text-align: left;">16个AI内核（AIC）</p>
<p style="text-align: left;">支持INT8，INT16，FP16和FP32</p>
<p style="text-align: left;">4个64位内存控制器（LPDDR4×）</p>
<p style="text-align: left;">144MB的片上SRAM高速缓存</p>
</blockquote>
<p style="text-align: left;">16个AI内核（AIC）</p>
<p style="text-align: left;">支持INT8，INT16，FP16和FP32</p>
<p style="text-align: left;">4个64位内存控制器（LPDDR4×）</p>
<p style="text-align: left;">144MB的片上SRAM高速缓存</p>
<p style="text-align: left;">也就是说，通道的总系统带宽为134GB/s，但144MB的片上SRAM高速缓存设计，在片上保存了尽可能多的存储器流量。</p>
<p style="text-align: left;">此外，7nm的工艺节点，也有助于降低功耗。</p>
<p style="text-align: left;">而在 <strong>封装</strong>上，高通采取了三种不同的形式： </p>
<blockquote>
<p style="text-align: left;">DM.2e，15W，超过50 TOPS</p>
<p style="text-align: left;">DM.2，25W，超过200 TOPS</p>
<p style="text-align: left;">PCle，75W，约400 TOPS</p>
</blockquote>
<p style="text-align: left;">DM.2e，15W，超过50 TOPS</p>
<p style="text-align: left;">DM.2，25W，超过200 TOPS</p>
<p style="text-align: left;">PCle，75W，约400 TOPS</p>
<p style="text-align: left;">其中，DM.2从外形来看，有点像两个相邻的M.2连接器，其中，M.2以尺寸小、传输性能高广受欢迎。</p>
<p style="text-align: center;"><img src="http://p3.itc.cn/q_70/images03/20200927/2c53f21820494de58769492f12209526.png" /></p>
<p style="text-align: left;">而DM.2e是dual M.2 edge的缩写，意为“两个边缘的M.2连接器”，是一种更小、功耗更低的热封壳外形。</p>
<p style="text-align: left;">从DM.2e的芯片设计来看，高通的目标似乎并不仅局限于云端。</p>
<p>将云端芯片“边缘”化 </p>
<p style="text-align: left;">事实上，从行业消息来看，云端的确不是高通的终点。</p>
<p style="text-align: left;">这次的Cloud AI 100，也将目光放在了更长远、更现实的位置——边缘人工智能 <span>（Edge AI）</span>。 </p>
<p style="text-align: left;">国际数据公司IDC的半导体研究总监Michael J. Palma曾表示：“人工智能的成功，在于部署到边缘的系统，在边缘系统中，神经网络做出的即时决策实际上可以创造价值，不受延迟和连接问题的约束——而这些问题对云解决方案来说是个挑战。”</p>
<p style="text-align: left;">据市场调研机构MarketsandMarkets预测，全球边缘人工智能软件市场规模，将从2018年的3.56亿美元，增长到2023年的11.52亿美元。</p>
<p style="text-align: left;">在2018年到2023年的预测期内，年复合增长率 <span>(CAGR)</span>为26.5%。 </p>
<p style="text-align: left;">在Cloud AI 100芯片开始应用的同时，高通也同时发布了对应的边缘人工智能开发工具包—— <strong>Cloud AI 100 Edge AI SDK</strong>。 </p>
<p style="text-align: left;">这一工具包，主要由以下3大模型构成：</p>
<blockquote>
<p style="text-align: left;">Cloud AI 100芯片（低功耗、高性能AI芯片）</p>
<p style="text-align: left;">骁龙865模块化平台（负责应用&amp;视频处理）</p>
<p style="text-align: left;">骁龙X55调制解调器及射频系统（5G连接）</p>
</blockquote>
<p style="text-align: left;">Cloud AI 100芯片（低功耗、高性能AI芯片）</p>
<p style="text-align: left;">骁龙865模块化平台（负责应用&amp;视频处理）</p>
<p style="text-align: left;">骁龙X55调制解调器及射频系统（5G连接）</p>
<p style="text-align: left;">这一工具包，除了上述芯片所包含的5G特性、能耗低等特点以外，目前透露的功能还有不少。</p>
<p style="text-align: left;">其中，支持24个相机同时拍摄分辨率达1920×1080的视频流、每秒25帧的高清视频。</p>
<p style="text-align: center;"><img src="http://p9.itc.cn/q_70/images03/20200927/a6876e23cd654e499220d56edd06e0eb.gif" /></p>
<p style="text-align: left;">不仅支持远程访问、可升级空中下载软件、可部署到户外，而且在PyTorch、ONNX、Tensorflow上都能运行。</p>
<p style="text-align: left;">此外，这一SDK还支持Keras、Caffe、PaddlePaddle等主流框架。</p>
<p style="text-align: left;">至于应用方向，包括新闻推送、广告、个性化视频、搜索、XR和游戏等，可以说是边缘的应用场景，它都能满足。</p>
<p style="text-align: left;">据高通近日公布的消息，Cloud AI 100正面向其全球部分客户出货，预计采用该产品的商用设备将于2021年上半年面市。</p>
<p>回看高通AI探索节点后的发现 </p>
<p style="text-align: left;">“高通在AI研发方面拥有悠久的历史。”</p>
<p style="text-align: left;">高通人工智能及边缘计算资深总监John Kehrli表示：“高通正处于第五代移动端解决方案中，拥有超过11年的研发经验，因此，高通正在利用行业专业知识（进行研发）。虽然这是AI内核，它与移动技术并不相同，但我们可以利用那个领域的经验。”</p>
<p style="text-align: left;">实际上，早在2007年，高通旗下的Qualcomm Research就启动了首个人工智能项目，并于2018年成立Qualcomm AI Research。</p>
<p style="text-align: left;">2015年，搭载第一代AI Engine <span>（人工智能引擎）</span>的高通骁龙820发布，第二年，高通发布了神经处理引擎SDK。 </p>
<p style="text-align: left;">在骁龙835、845和855发布后，2019年，高通正式发布第五代AI Engine骁龙865移动平台。</p>
<p style="text-align: left;">今年，高通也同样在AI赛道上飞速奔驰。</p>
<p style="text-align: left;">6月18日，高通推出全球首款支持5G和AI的机器人平台RB5。</p>
<p style="text-align: left;">此后推出了骁龙690 5G移动平台、骁龙750G 5G移动平台等，同样支持第五代AI Engine。</p>
<p style="text-align: left;">9月初，骁龙8cx第二代5G计算平台发布，支持AI Engine。</p>
<p style="text-align: left;">同样在近期，Facebook发布的Oculus Quest 2首次搭载了骁龙XR2平台，与前代平台相比，骁龙XR2平台的AI处理能力提升高达11倍，能够支持更多感知算法。</p>
<p style="text-align: left;">9月中旬，高通的云端推理芯片Cloud AI 100已经出货，同时，高通开始探索Cloud AI 100边缘方案开发套件，并已实际交付。</p>
<p style="text-align: left;">这是它在AI芯片行业、边缘人工智能迈出的新一步。</p>
<p style="text-align: left;">在全球人工智能产业的生态系统逐步成型的当下，AI已然成为各行各业加速发展的助推器。</p>
<p style="text-align: left;">高通也不例外，从手机、PC、XR到机器人等等，它在飞速推动各领域的AI升级。</p>
<p style="text-align: left;">目前，高通的所有系统级芯片都支持AI、或集成AI Engine。</p>
<p style="text-align: left;">对于AI芯片而言，就像产品的最终目的是落地一样，从“云端”到“边缘”也是一种必然的趋势。</p>
<p style="text-align: left;">如果只将目光放在眼下单一领域的利益发展、而非多角度进行探索，将难以在竞争愈渐激烈的行业中谋得生存。高通的全方位投入所取得的成果，让AI行业看见了新的范例。</p>
<p>— <strong>完</strong>— </p>
<p><span>本文系网易新闻•网易号特色内容激励计划签约账号【量子位】原创内容，未经账号授权，禁止随意转载。</span></p>
<p><strong>CNCC2020 | 图灵奖得主、院士、名企专家将做特邀报告</strong></p>
<p><strong>CNCC2020</strong>将于 <strong>10月22-24日</strong>在 <strong>北京新世纪日航饭店</strong>（主会场）、多个城市分会场以及 <strong>线上</strong>举行。首批特邀讲者官宣确认，图灵奖得主、院士、名企专家将在CNCC2020做特邀报告。 </p>
<p>早鸟票即将售罄，欢迎报名参与~ </p>
<p><span style="font-size: 16px;"><strong>量子位 </strong></span><span style="font-size: 16px;">QbitAI · 头条号签约作者</span></p>
<p>վ'ᴗ' ի 追踪AI技术和产品新动态</p>
<p><span>一键三连「分享」、「点赞」和「在看」</span></p>
<p><span>科技前沿进展日日相见~</span></p>