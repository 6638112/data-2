➜技术专场议程公布！2020 Qualcomm XR生态合作伙伴大会火热报名中
http://www.sohu.com/a/412063198_213766	834
<p class="ql-align-justify">（<strong>映维网 2020年08月07日</strong>）2020 Qualcomm XR生态合作伙伴大会暨第二届XR创新应用挑战赛颁奖典礼将于2020年9月5日在江西南昌举行。Qualcomm将携手中国电信、Pico、影创科技、爱奇艺智能、3Glasses、大朋VR、Nreal、七鑫易维、瑞欧威尔、创通联达、Unity、燧光等众多生态系统合作伙伴，共同打造此次盛会。</p>
<p class="ql-align-center"><img src="http://p2.itc.cn/images01/20200808/b3824c5d15994f11b2eed76dd041bf9c.png" max-width="600" /></p>
<p class="ql-align-justify">届时，来自XR（扩展现实）领域的领先企业以及业界专家将就当前XR技术和应用进行交流，分享成功应用经验，探讨XR产业发展趋势。大会还将设立开发者技术专场、创投专场和Qualcomm XEP项目专场，以下是技术分会场的具体议程内容：</p>
<p class="ql-align-center">演讲主题：Pico XR SDK技术分享</p>
<p class="ql-align-justify">演讲嘉宾：付延生，Pico，研发总监</p>
<p class="ql-align-justify">演讲概要：本次演讲包含Pico XR SDK介绍、技术分享、开发者政策及内容生态等内容。</p>
<p class="ql-align-justify">嘉宾简介：付延生（Will Fu），现任Pico研发总监。拥有10年以上研发及管理经验，先后任职于Lucent，Intel，Pico等公司，从事通信、移动互联网、VR/AR等领域研发工作。拥有哈尔滨工业大学-通信与信息处理专业-硕士学位。</p>
<p class="ql-align-center">演讲主题：AR输入系统的实现与使用</p>
<p class="ql-align-justify">演讲嘉宾：王超群，影创，SDK开发主管</p>
<p class="ql-align-justify">演讲概要：支持多种输入方式的输入系统设计思想，手势交互的设计理念，交互对象的属性。</p>
<p class="ql-align-justify">嘉宾简介：王超群，Unity3D资深开发工程师，专注于Unity3D开发5年，负责影创项目SDK的开发。</p>
<p class="ql-align-center">演讲主题：如何在VR一体机上构建无缝加载的高画质游戏</p>
<p class="ql-align-justify">参赛作品：《命运抉择》</p>            <div class="lookall-box">
<div class="lookall-shadow"></div>
<section class="lookall">
<a href="javascript:;" class="show-all" id="showMore">
<em>展开全文</em>
</a>
</section>
</div>
<div class="hidden-content control-hide">
<p class="ql-align-justify">演讲嘉宾：薛萌，彼真科技，CTO</p>
<p class="ql-align-justify">演讲概要：以本次参赛作品《命运抉择》的开发历程为线索，以技术视角讲述一款VR游戏产品从无到有诞生的过程，围绕项目开发过程中遇到的高画质与高流畅度之间的矛盾，分享构建无缝VR世界的方法，并复盘填坑之旅。</p>
<p class="ql-align-justify">嘉宾简介：薛萌，复旦大学信息工程硕士，前JCE和腾讯北极光工作室高级工程师，风靡全球的手游《爱丽丝快跑》的创作者。现任彼真科技CTO，潜心于计算视觉和虚拟现实技术研究，主导了多款VR项目的研发工作，产品涉及PCVR，大空间VR，一体机等各类主流VR硬件平台。</p>
<p class="ql-align-center">演讲主题：VR一体机上卡通人物模型的显示与优化</p>
<p class="ql-align-justify">参赛作品：《Dance Dance Maker!》</p>
<p class="ql-align-justify">演讲嘉宾：吕阳鹏，独立VR开发者</p>
<p class="ql-align-justify">演讲概要：1. 作为VR游戏独立开发者的心路历程；2.DDM的视觉效果实现原理–如何在一体机中实现复杂的特效；3.基于VR一体机的VRM格式3d模型优化–如何降低Drawcall和内存占用等；4.一些目前正在开发中的游戏展示还有脑洞等。</p>
<p class="ql-align-justify">嘉宾简介：吕阳鹏，独立VR游戏开发者，前小米VR主程，在小米期间参与了两代小米VR软件系统的研发，其中包括与Oculus合作开发的小米VR一体机(Oculus Go中国版)。在小米期间曾经开发过的VR游戏软件有：“小米VR OS”（小米VR内置系统）、“小米VR浏览器”（小米VR内置浏览器）、“小米VR多人影院”、“Dance.VR”（小米VR平台的舞蹈类游戏）。作为独立VR游戏开发者，目前创作中的VR软件游戏有：“Dance Dance Maker!”（VR二次元舞蹈）、“Music Tube”（VR音乐可视化）、“Defeat Virus”（消灭冠状病毒）。</p>
<p class="ql-align-center">演讲主题：Unreal 移动端VR画面表现效果优化分享</p>
<p class="ql-align-justify">参赛作品：《鬼怪猎人》</p>
<p class="ql-align-justify">演讲嘉宾：朱稼萌，伊酷网络，技术合伙人</p>
<p class="ql-align-justify">演讲概要：基于Unreal 移动端VR的画面表现，就模型结构，材质贴图，光影氛围，程序算法，四个面向介绍一些优化经验。通过合理的资源优化操作，在稳定帧数的基础上尽可能的提高游戏视觉表现效果。</p>
<p class="ql-align-justify">嘉宾简介：朱稼萌，资深Unreal开发，擅长Unreal 蓝图、C++开发和美术设计，动画特效等模块，拥有丰富的UE4 TA相关工作经验，熟悉VR游戏及行业应用的开发流程。</p>
<p class="ql-align-center">演讲主题：“雇佣兵：智能危机”从PC端到一体机</p>
<p class="ql-align-justify">参赛作品：《雇佣兵2：智能危机》</p>
<p class="ql-align-justify">演讲嘉宾：王雪芝，酷咔数字，联合创始人</p>
<p class="ql-align-justify">演讲概要：分享“雇佣兵：智能危机”从PC端到VR一体机的研发过程中所遇到的问题以及解决方案。</p>
<p class="ql-align-justify">嘉宾简介：王雪芝，11年游戏行业从业经验，曾参与及主导《Knight Odyssey iPhone》、《Let’s golf3》、《Spiderman》、《Puzzle Arena》等多款3D游戏研发。之后，带领团队研发游戏分享社交软件GAMEPI，现任酷咔数字COO。</p>
<p class="ql-align-center">演讲主题：VR一体机多人FPS游戏开发跳坑心得</p>
<p class="ql-align-justify">参赛作品：《绝地战魂》</p>
<p class="ql-align-justify">演讲嘉宾：廖怀富，BeeManStudio，CTO</p>
<p class="ql-align-justify">演讲概要：机能策略：一体机下如何尽量控制机能消耗，让多人游戏更加流畅；语音社交：一体机普及当下，让玩家方便搜索、匹配、关注好友，语音留言更增强好友粘性；艺术风格：手绘风设计，画面平稳不易眩晕，让玩家更注重战斗；移动方式：车载移动方式，坐立式自由移动，有效降低晕感；武器手感：虚拟身体连接武器，加强代入感，简洁武器操作，优化音效与震动，增强打击感；战场节奏：一体机电量消耗大，随机武器、小型毒圈，加快战场节奏，享更多对战乐趣。</p>
<p class="ql-align-justify">嘉宾简介：廖怀富，2007-2011任职于 久之游（上海）、联游网络，参与开发过《劲爆篮球ol》、《战国ol》，2011-至今 联合创办 BeeManStudio 并担任CTO</p>
<p class="ql-align-justify">大会主页：https://xr.qualcomm-challenge.com/2020-qualcomm-xr-conference</p>
<p class="ql-align-center">参会信息及报名请扫码</p>
➜提升AR效果，谷歌发布精确虹膜估计全新机器学习模型MediaPipe Iris
http://www.sohu.com/a/412063770_213766	1065
<p class="ql-align-justify">（<strong>映维网 2020年08月08日</strong>）包括计算摄影（如人像模式）和增强现实效果（如虚拟化身）在内的大量应用都依赖于通过虹膜追踪来估计眼睛位置。一旦获得精确的虹膜追踪数据，我们无需专用的深度传感器就可以确定从摄像头到用户的距离。反过来说，虹膜追踪可以改善从计算摄影到虚拟眼镜或帽子穿戴等一系列的用例。</p>
<p class="ql-align-justify">由于有限的计算资源，可变的光照条件，以及遮挡物的存在（如头发或因眯眼造成的眼脸），移动设备实现虹膜追踪是一项艰巨的任务。一般而言，这项技术会采用复杂的专用硬件，而这限制了相关解决方案的支持设备范围。</p>
<p class="ql-align-center">左边：在Pixel 2运行的MediaPipe Iris正在以cm为单位估计度量距离，没有采用任何深度摄像头；右边：groud-truth深度</p>
<p class="ql-align-justify">为了量化所述方法的精确性，研究人员收集了200多位被试的正向同步视频和深度图像，并将其与iPhone 11的深度传感器进行比较。团队使用激光测距设备，通过实验确定iPhone 11的深度传感器在2米以内的误差小于2％。对于使用虹膜大小进行深度估算的方法，平均相对误差为4.3％，标准偏差是2.4％。谷歌对有眼镜被试和正常视力被试（不计入隐形眼镜情况）测试了所述方法，并发现眼镜会将平均相对误差略微提高到4.8％（标准偏差是3.1％）。另外，实验没有测试存在任何眼睛疾病的被试。考虑到MediaPipe Iris不需要专门的硬件，所述结果表明系统能够支持一系列成本范围的设备根据单张图像获取度量深度。</p>
<p class="ql-align-center"><img src="http://p0.itc.cn/images01/20200808/fb39453f002e43acb9399f1a6e9be06b.png" max-width="600" /></p>
<p class="ql-align-center">估计误差的直方图（左边），以及实际和估计距离的比较（右边）</p>
<p class="ql-align-justify"><strong>3. 发布MediaPipe Iris</strong></p>
<p class="ql-align-justify">这个虹膜和深度估计模型将作为支持PC，移动设备和Web的跨平台MediaPipe管道发布。正如谷歌在最近一篇关于MediaPipe的博文所述，团队利用WebAssembly和XNNPACK在浏览器中本地运行Iris ML管道，无需将任何数据发送到云端。</p>
<p class="ql-align-center"><img src="http://p2.itc.cn/images01/20200808/6416db6478ac49d39b7b4c49a5bc7377.gif" max-width="600" /></p>            <div class="lookall-box">
<div class="lookall-shadow"></div>
<section class="lookall">
<a href="javascript:;" class="show-all" id="showMore">
<em>展开全文</em>
</a>
</section>
</div>
<div class="hidden-content control-hide">
<p class="ql-align-center">使用MediaPipe的WASM堆栈。你可以在浏览器种运行模型</p>
<p class="ql-align-center"><img src="http://p6.itc.cn/images01/20200808/a360a2925b3441d68e65e95588339078.gif" max-width="600" /></p>
<p class="ql-align-center">仅使用包含EXIF数据的单张图片计算虹膜深度</p>
<p class="ql-align-justify">请点击这里以尝试虹膜追踪，请点击这里以尝试虹膜深度。</p>
<p class="ql-align-justify"><strong>4. 未来方向</strong></p>
<p class="ql-align-justify">谷歌计划进一步扩展MediaPipe Iris模型，实现更稳定的追踪性能以降低误差，并将其部署用于无障碍用例。谷歌在相关文档和随附的Model Card中详细说明了预期的用途，限制和模型的公平性，从而确保模型的使用符合谷歌的AI原则。请注意，任何形式的监视监控都明显超出应用范围，故不予支持。团队表示：“我们希望的是，通过向广泛的研究与开发社区提供这种虹膜感知功能，从而促使创造性用例的出现，激发负责任的新应用和新研究途径。”</p>
<p>原文链接：https://yivian.com/news/76906.html</p>