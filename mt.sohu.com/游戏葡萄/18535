➜系列发展20年后，网易把《全面战争》第一款网游带入了国内市场
http://www.sohu.com/a/421971413_204824	43862
<p>
<table>
<tbody>
<tr>
<td><span style="font-size: 16px;">《全面战争》以一种更接地气的方式进入国内了。</span></td>
</tr>
</tbody>
</table></p>
<p><span style="font-size: 16px;">文/安德鲁</span></p>
<p><span style="font-size: 16px;">一个经典系列的破圈，往往可能就在一些不经意的节点上。</span></p>
<p><span style="font-size: 16px;">对于国内玩家而言，《全面战争》系列一直以来都是硬核策略游戏的代名词。</span></p>
<p><span style="font-size: 16px;">而如果没有《全面战争：三国》的出现，对于大众玩家而言，《全面战争》这个名字，可能一直都停留在“面向核心玩家的策略游戏 ”这个层面上。</span></p>
<p><span style="font-size: 16px;">不过去年，随着《全面战争：三国》上线后的火爆、在国内游戏圈的传播扩散，有更多人认识到了这个此前稍显低调的经典系列。网易也和《全面战争》系列的开发商Creative Assembly达成了合作，宣布会将《全面战争》系列引入国内，并且将于Creative Assembly共同开发面向中国市场的《全面战争》系列游戏。</span></p>
<p style="text-align: center;"><img src="http://p0.itc.cn/q_70/images03/20200930/1a0a6b0599b240a7910490c495a74fa7.png" /></p>
<p><span style="font-size: 16px;">而就在最近，双方达成合作后的第一款产品《全面战争：竞技场》开始了不删档测试。</span></p>
<p><span style="font-size: 16px;">这也是近20年来，全战系列第一次以网游的面貌示人，这个诞生多年的经典策略游戏，终于正式进入了国内市场，向更大众的玩家敞开了。</span></p>
<p><span style="font-size: 16px;">第一款再现《全面战争》氛围的网游</span></p>
<p><span style="font-size: 16px;">《全面战争》这个系列代表了什么？</span></p>
<p><img src="http://p3.itc.cn/q_70/images03/20200930/e3b33d1d42a44d5bb6da1c3ebed1b4a5.png" /></p>            <div class="lookall-box">
<div class="lookall-shadow"></div>
<section class="lookall">
<a href="javascript:;" class="show-all" id="showMore">
<em>展开全文</em>
</a>
</section>
</div>
<div class="hidden-content control-hide">
<p><span style="font-size: 16px;">对于那些有所了解的玩家而言，这个系列的游戏往往意味着两个要点：一是指挥大规模兵团作战的史诗感，和战争的临场感，以及多方联机交战时复杂战况带来的策略性；二是结合真实历史的人物背景和细节设定，对于部分世界战争历史的还原，所营造出的游戏代入感</span></p>
<p style="text-align: center;"><img src="http://p7.itc.cn/q_70/images03/20200930/d2ddb30468d04505b7c5b5f19d4243cc.png" /></p>
<p><span style="font-size: 16px;">这是《全面战争》系列最直观的调性，哪怕只是对《全面战争》系列略有耳闻的人也都有所感知。这两点也是外围玩家通过图片、视频等各种传播素材能有所认知的。</span></p>
<p><span style="font-size: 16px;">不过，此前受语言版本、获取渠道几个方面的限制，国内玩家接触全战系列的机会有限。再加上《全面战争》以往的历代产品，玩法内容的确比较偏硬核一些，为了营造宏大的战争代入感，做了诸多细致入微的设定、规则，这样的复杂性也很容易让人望而生畏，多少挡住了一些想要试着入门的玩家。</span></p>
<p><span style="font-size: 16px;">因此，讲到《全面战争》，大众层面的玩家应该都知道，但很多人没有深入体验过。</span></p>
<p style="text-align: center;"><img src="http://p6.itc.cn/q_70/images03/20200930/7c177828b11f4158a0b60d8de1bb8f8a.png" /></p>
<p><span style="font-size: 16px;">不过作为全战系列进入国内的第一款网游，《全面战争：竞技场》就是在弥补这种遗憾。也就是在还原上述观感和调性的同时，试着降低上手门槛，把全战的精髓呈现给更多战争题材、策略玩法的受众 。</span></p>
<p><span style="font-size: 16px;">相比全战系列的历代主要作品，《全面战争：竞技场》上手要简单很多，PVP模式中，玩家主要是操纵一名指挥官和三个编队</span><span style="font-size: 16px;">（每个编队由单一兵种的军队构成）</span><span style="font-size: 16px;">的单位，参与到10V10的战斗中。</span></p>
<p style="text-align: center;"><img src="http://p2.itc.cn/q_70/images03/20200930/d05a732e97c74bb19fad9e33bbac0d85.png" /></p>
<p><span style="font-size: 16px;">1个指挥官带领3个编队，只从单个玩家的视角看，这听起来似乎并不宏大、也不怎么史诗。不过当10个玩家的部队集结在一侧、骑兵列成方阵发起冲锋，弓箭手向远处倾泻箭雨、枪兵举起长矛整齐推进的时候——或者单纯就是不同玩家，几支不同兵种的部队一起行军前进的时候，相信我不用多描述什么，只看几张游戏内的截图，你也能感受到策略游戏呈现出的这种大兵团作战的宏观场面。</span></p>
<p><span style="font-size: 16px;">同时，虽然和近一两年的顶级3A游戏的表现力有一点差距，但是《全面战争：竞技场》依然有PC网游中不错的画面表现。</span></p>
<p><span style="font-size: 16px;">《全面战争：竞技场》的游戏配置要求的下限放得也足够宽。最低配置只要保证3GB内存、GTX620以上的显卡就能跑得动游戏。这比不少主流网游的配置要求都要低。</span></p>
<p style="text-align: center;"><img src="http://p6.itc.cn/q_70/images03/20200930/741b7170926e46d795f7e350e220c400.png" /></p>
<p><span style="font-size: 16px;">战场表现上，游戏设置了多张结合了历史上的真实战场的地图，这些地图可能是结合了史实记载的城邦巷道，或是大片树林和灌木等植被覆盖的开阔原野。</span></p>
<p style="text-align: center;"><img src="http://p6.itc.cn/q_70/images03/20200930/5fd8787ad3954c8b880748682023d3a5.png" /></p>
<p><span style="font-size: 16px;">对参战部队的刻画，也细致到了单个士兵的面貌、武器细节、装备铠甲等。尽管实际游戏过程中，玩家大多数时候是将视角拉高，从更高出来俯瞰整个战场的。但如果将视角拉近，也能看清楚单个士兵单位的动作。</span></p>
<p><span style="font-size: 16px;">《全面战争：竞技场》对战场的宏大和细微塑造，就体现在这些地方。</span></p>
<p><span style="font-size: 16px;">一个更“亲民”的《全面战争》</span></p>
<p><span style="font-size: 16px;">作为一款PC平台的网游，《全面战争：竞技场》是以一种国内玩家更熟悉的形态出现的。</span></p>
<p><span style="font-size: 16px;">就当前的玩法设定而言，游戏多少带有一些MOBA的要素。比如对局当中，对战的地图像MOBA一样分成三路，这三路的沿途有数个据点 <span>（中路正中间有一个，上下两路每条路上有两个）</span>，两侧终端是双方的大本营。 </span></p>
<p style="text-align: center;"><img src="http://p5.itc.cn/q_70/images03/20200930/69ac266e21144219bff24f068e034843.png" /></p>
<p><span style="font-size: 16px;">如果有一方占据了一条路上的两个据点，就可以进攻敌方的大本营。成功攻占敌方大本营后游戏自然就结束了。</span></p>
<p><span style="font-size: 16px;">另外，在对战中将击杀敌方部队、占领据点能获得对应的分数。即便没有攻占对方大本营，先达成目标分数的一方也能取胜。</span></p>
<p><span style="font-size: 16px;">因此，实际对局中双方大部分冲突，通常都围绕着争夺据点展开。据点有很重要的战略意义，涉及兵力投放、控制战局等。</span></p>
<p style="text-align: center;"><img src="http://p5.itc.cn/q_70/images03/20200930/d7a32057d0684a70966781d1a18b7115.png" /></p>
<p><span style="font-size: 16px;">如前文所述，玩家控制着三个编队的部队，每个编队有一定的数量，就像RTS游戏中一个单位的生命值，全部耗光之后这支部队就视同被消灭。而当3支部队全部覆灭后，玩家就只能观战队友的部队动向了</span></p>
<p><span style="font-size: 16px;">不过《全面战争：竞技场》中，战场上的阵亡并非永久性的。部队全部阵亡后，玩家会进入复活倒计时。一小段时间之后，可以从已经占领的据点中选择一个在此复活，重返战场。复活机制可以看作是游戏面向新手做出的调整。同时从这里你也能看到，占领更靠前的据点，就意味着部队重生后更快地投入战斗、对敌方形成威胁。</span></p>
<p><span style="font-size: 16px;">就我的上手体验而言，地图兵分三路的布局、以占点为主要目标的战斗收束了一些对局的焦点，让“我该干些什么”变得更集中了一些。而部队阵亡后的复活也明显降低了挫败感。打过两三局人机对战之后，就能了解到最基础的机制设定，这让全战这个以往印象当中一直以硬核形象示人的系列，变得易于理解。</span></p>
<p><span style="font-size: 16px;">浏览贴吧会发现，一些全战系列的老玩家对此有质疑，觉得引入复活设定让战争场面变得不够真实、不够硬核。但另一方面，即便有这样观点的老玩家也承认，复活设定的确降低了上手门槛，变得对新手更友好。</span></p>
<p><span style="font-size: 16px;">但尽管如此，《全面战争：竞技场》并没有在策略性上做出大幅度的妥协。</span></p>
<p><span style="font-size: 16px;">游戏内兵种之间存在着典型克制的关系，比如面对骑兵的冲锋，普通的步兵很难处理；面对站在远处、占据有利地形的弓箭手部队，要不要贸然发起冲锋，可能要再三考量。</span></p>
<p><span style="font-size: 16px;">目前为止，我印象最深的交战场面来自一次“巷战”：</span></p>
<p style="text-align: center;"><img src="http://p9.itc.cn/q_70/images03/20200930/c9dd11d9fc8345aa806782f06e24eb74.png" /></p>
<p><span style="font-size: 16px;">对方推进到了我方大本营前的左侧一个据点，但我方的兵力主要集中在右路，情况比较危急。不过由于是城邦内的交战，我的枪兵横成一排，架起防御姿势稳步推进，成功挡住了数量明显多于这两队枪兵的部队，硬生生地守了下来。也等来了队友的后续增援。</span></p>
<p><span style="font-size: 16px;">这是《全面战争：竞技场》中，各兵种搭配、克制一个典型的缩影。再加上队友之间的不同的部队种类搭配，步兵正面推进、骑兵侧翼穿插包抄、弓箭手远程支援，这样同时出现的复杂对战场面都是一个玩家在对局中可能会遇到的。</span></p>
<p style="text-align: center;"><img src="http://p1.itc.cn/q_70/images03/20200930/3b35c92aba7e41c49e48e16adcb3f8e4.png" /></p>
<p><span style="font-size: 16px;">当然，游戏目前的匹配机制，似乎没有给“玩家间的兵种搭配”过多的权重。我在前期游戏中，遇到过双方都是弓箭手部队占大多数，各自站在两个山头上互射的情形。</span></p>
<p><span style="font-size: 16px;">此外，游戏里还引入了士气相关的设定。指挥官跟随第一编队的部队一起出战，指挥官阵亡往往会影响到部队的士气。部队士气的高低很多时候都会和属性挂钩，从而影响到实时的战局。士气过低甚至有可能导致部队放弃战斗、崩溃逃命。</span></p>
<p><span style="font-size: 16px;">而在对局之外，《全面战争：竞技场》也设立了一整套策略养成机制。</span></p>
<p style="text-align: center;"><img src="http://p1.itc.cn/q_70/images03/20200930/0a74587b0ebd4d1ea88023271b6081af.png" /></p>
<p><span style="font-size: 16px;">全战系列一直以还原历史上真实存在过的文明而着称，《全面战争：竞技场》里主要体现了四大派系：罗马、希腊、蛮族和迦太基，每个文明派系都有专属的兵种，并且带有地域特色。比如希腊的初始兵种是弓箭手部队，蛮族有外观特征明显的蛮族骑兵等。</span></p>
<p><span style="font-size: 16px;">随着玩家等级提升，每个派系的初始兵种也可以逐步升级不同天赋、解锁更高级别的兵种。</span></p>
<p style="text-align: center;"><img src="http://p9.itc.cn/q_70/images03/20200930/249345f321184eb6ae36ddc423b45fdb.png" /></p>
<p><span style="font-size: 16px;">同时，全战系列里，来自不同文明的指挥官是游戏另一个体现历史改编的输出内容。罗马帝国的凯撒、希腊的亚历山大都是人们耳熟能详的角色，而这些指挥官也有各自擅长的方向，有些指挥官的技能可以用于强化骑兵，带队冲锋；或者是有冷却时间、较为强力的主动技，可以在战局中发挥重要的作用。</span></p>
<p><span style="font-size: 16px;">这些都是游戏在局外、战前的策略养成，同样能起到影响对战走向的效果。随着等级提升，玩家会依次解锁更多的部队种类、天赋技能，阵容搭配上也会有更多选择，逐步分层次地体验到全战系列在策略性上的深度。</span></p>
<p><span style="font-size: 16px;">首次正式进入国内市场的全战系列</span></p>
<p><span style="font-size: 16px;">PC端的策略游戏中，已经有20年历史《全面战争》系列在欧美游戏市场有着十分重要的品类地位，随手翻翻Metacritic的评分，《全面战争》系列的综合评分大多都在90分上下。是策略游戏里长期输出，且质量稳定的典型。</span></p>
<p style="text-align: center;"><img src="http://p6.itc.cn/q_70/images03/20200930/a7bfb145ed66436a8a7a446d47cfb4ce.png" /></p>
<p><span style="font-size: 16px;">同样的，全战系列在国内的硬核玩家群体中也有多年的口碑积累。只不过此前因为种种原因，国内大众玩家不太接触得到。或许是因为语言、获取渠道，或是上手门槛等。</span></p>
<p><span style="font-size: 16px;">而随着全战三国在去年走红，这个原本相对核心向的系列走向了大众层面，有更多玩家表现出了兴趣。这为游戏进入国内市场打下来良好的预先基础。</span></p>
<p><span style="font-size: 16px;">这之后我们看到网易和Creative Assembly、世嘉达成了合作，宣布将独家代理《全面战争》系列的产品。《全面战争：竞技场》由网易宝船引进，</span><span style="font-size: 16px;">这是20年来全战系列第一次以免费网游的形式出现，一些外媒的报道评测中也支出了这款产品在国内的特殊性，有些还很羡慕国内的玩家能更先一步玩到。</span></p>
<p style="text-align: center;"><img src="http://p8.itc.cn/q_70/images03/20200930/58d7329e4d3442aa83629f45e18b9234.png" /></p>
<p><span style="font-size: 16px;">去年《全面战争：三国》发售当月，就在PC端进入了全球</span><span style="font-size: 16px;">（数字游戏）</span><span style="font-size: 16px;">收入的Top 6，收入6200万美元。如今《全面战争：竞技场》除了采用免费网游的形式、放低硬件要求下限外，也加入了种种玩法设计上的调整，让一个原本核心向的游戏变得更容易入门，也让这个经典IP有了新的形式。此次进入国内市场时，这个20年历史的策略游戏，有机会在更多大众玩家群体内产生影响。</span></p>
➜谷歌下发最后通牒：将对商店应用内购强制抽成30%
http://www.sohu.com/a/421978075_204824	43862
<table>
<tbody>
<tr>
<td><span><span style="font-size: 16px;">规则就是规则。</span></span></td>
</tr>
</tbody>
</table>
<p><span style="font-size: 16px;">文/周明明</span></p>
<p><span style="font-size: 16px;">9月28日，据《纽约时报》等多家外媒报道，谷歌将从2021年9月30日开始，强制对Google Play中的APP内购抽成30%。</span></p>
<p><span style="font-size: 16px;">谷歌要求所有在Google Play上架的APP，必须使用谷歌内购支付系统，并支付30%的佣金。不过，该强制措施仅适用于小部分仍未使用该系统的开发商，比如，Netflix和Spotify就在应用中通过提示用户使用信用卡付款来绕过谷歌。</span></p>
<p style="text-align: center;"><img src="http://p5.itc.cn/q_70/images03/20200930/7982e294e57c4ebe8c6f7801a5097cae.png" /></p>
<p><span style="font-size: 16px;">谷歌产品管理副总裁还在官方博客中表示，他们尊重开发商选择其他安卓平台的权利，但如果想要继续在Google Play上架，就需要调整内购方式以适应谷歌的规则。</span></p>
<p style="text-align: center;"><img src="http://p8.itc.cn/q_70/images03/20200930/2691ad3f4e1f48699b3ab0394cec293c.png" /></p>
<p><span style="font-size: 16px;">近几个月来，关于谷歌和苹果应用商店抽取佣金的规则，有很多争议。例如，Epic Games就曾起诉称苹果和谷歌涉嫌垄断。起因是《堡垒之夜》在游戏中推出直接付款系统，绕开了应用商店对游戏内购抽成30%的规定，而苹果则于8月底终止了Epic在App Store的所有权限。</span></p>
<p style="text-align: center;"><img src="http://p3.itc.cn/q_70/images03/20200930/18cefeaf8de44adeb705012f16772b41.png" /></p>
<p><span style="font-size: 16px;">据《纽约时报》报道，目前有多家开发商对Google和苹果30%的抽成感到不满。Epic Games、Spotify、Tinder等多家开发商还成立了“应用公平性联盟”（Coalition for App Fairness），以此来抗议应用商店。</span></p>
<p style="text-align: center;"><span style="font-size: 16px;">｜ 对话马晓轶 ｜ 荒野乱斗 ｜ Epic </span></p>
➜145国iOS免费榜第一：「狼人杀」凭什么又火了？
http://www.sohu.com/a/421984959_204824	43862
<p>
<table>
<tbody>
<tr>
<td><span style="font-size: 16px;">命运逆转。</span></td>
</tr>
</tbody>
</table></p>
<p>文/菲斯喵</p>
<p><span style="font-size: 16px;">今年8月以来，一款两年前就已上线的「狼人杀」在海外突然爆红。</span></p>
<p><span style="font-size: 16px;">游戏名叫《Among Us》。据 App Annie 监测，它已在145个国家/地区中获得过 iOS 免费榜第一。</span></p>
<p><span style="font-size: 16px;">观察海外 iOS 榜单，我们会发现美国免费榜霸榜20天的是它，在韩国霸榜超过50天的，还是这款曾经毫不起眼的产品。</span></p>
<p style="text-align: center;"><img src="http://p5.itc.cn/q_70/images03/20200930/3a21af6b77bf4df2891fe1e0c32a7401.jpeg" /></p>
<p><span style="font-size: 16px;">具体的下载量，更能说明它的火热：据 Sensor Tower 数据揭示，截至9月14日，《Among Us》移动版的下载量超过8660万，近45天下载量占生涯下载量70%。</span></p>
<p style="text-align: center;"><img src="http://p5.itc.cn/q_70/images03/20200930/f6105aa68c3a4a7386da65967fa1dc91.jpeg" /></p>
<p><span style="font-size: 16px;">另外从手游数据公司 GameRefinery 的统计结果来看，9月还未到头，本作已经在 App Store 上创收超过190万美元。</span></p>            <div class="lookall-box">
<div class="lookall-shadow"></div>
<section class="lookall">
<a href="javascript:;" class="show-all" id="showMore">
<em>展开全文</em>
</a>
</section>
</div>
<div class="hidden-content control-hide">
<p style="text-align: center;"><img src="http://p1.itc.cn/q_70/images03/20200930/da2007491d774ac0ab09e35d2ddf9a3c.jpeg" /></p>
<p><span style="font-size: 16px;">毫无疑问，《Among Us》成为了2020年的一大爆款。但人们难免有此疑惑：这款以「狼人杀」为内核的游戏，怎么就在上线两年之后，实现了命运的大逆转？</span></p>
<p><span style="font-size: 16px;"><span>看似毫无新意的太空版狼人杀</span></span></p>
<p><span style="font-size: 16px;">2018年6月15日，《Among Us》移动版上线。</span></p>
<p><span style="font-size: 16px;">开发商 InnerSloth 为此发布了一条推文，如此介绍游戏：「在讨论之中，无辜的船员可能会遭到错误的指控。只有在你死后成为幽灵，才能发现谁才是冒牌货。但幽灵不能说话。所以，玩家还是得认真讨论，找出真正的伪装者。」</span></p>
<p><img src="http://p4.itc.cn/q_70/images03/20200930/1be226be8e514c46b94818e32ddd7caf.jpeg" /></p>
<p style="text-align: center;"><span style="font-size: 16px;">《Among Us》早期的宣传图</span></p>
<p><span style="font-size: 16px;">听起来，这套玩法很像「狼人杀」——玩家分为两大阵营，其中有多人隐藏了身份，在此情况下，双方通过语言、逻辑和演技的较量，完成一场非对称的生存游戏。</span></p>
<p><span style="font-size: 16px;">《Among Us》的内核就是如此，从2018年至今，从未变过。表现上看，它只是新瓶装旧酒，套上了太空题材的包装。</span></p>
<p style="text-align: center;"><img src="http://p0.itc.cn/q_70/images03/20200930/eec415e7784b43c6a2882660d5a8633e.gif" /></p>
<p><span style="font-size: 16px;">游戏的舞台设计于太空飞船之中</span><span style="font-size: 16px;">（另一张地图是太空基地）</span><span style="font-size: 16px;">，飞船搭载着10名宇航员。但船员之中存在着1-3名伪装者，他们混在其中，伺机搞破坏，甚至蓄意谋杀。</span></p>
<p><span style="font-size: 16px;">善良的船员则团结在一起，通过讨论和票选，找出伪装者，将其处决。</span><span style="font-size: 16px;"></span></p>
<p style="text-align: center;"><img src="http://p1.itc.cn/q_70/images03/20200930/6c54b989bed843c199a16500bd5ee3f0.gif" /></p>
<p style="text-align: center;"><span style="font-size: 16px;">被处决的伪装者</span></p>
<p><span style="font-size: 16px;">有趣的是，死去的船员将会成为亡灵，继续在太空船上游荡。如果</span><span style="font-size: 16px;">愿意的话，亡灵还能帮忙完成飞船上的任务。而在传统「狼人杀」里，玩家被杀后，通常只能留一句遗言，然后全程观战了。</span></p>
<p style="text-align: center;"><img src="http://p8.itc.cn/q_70/images03/20200930/7d5075cd9d254cf2a7844a039a21d1df.gif" /></p>
<p><span style="font-size: 16px;">不过，恐怖氛围下的伪装、杀戮与生存，其实是一些经典科幻惊悚电影玩剩下的情节。比如《怪形》、《异形》系列，或是《星河战队2》。</span></p>
<p><span style="font-size: 16px;">从葡萄君的理解来看，《Among Us》的基本形态就是过气的狼人杀玩法+已成俗套的科幻电影桥段。我很好奇，这样的组合难道就是其日后火爆的源头吗？</span></p>
<p><span style="font-size: 16px;">将已知的流程变成未知</span></p>
<p><span style="font-size: 16px;">事情似乎没那么简单。</span></p>
<p><span style="font-size: 16px;">2018年11月，这款由3个人开发的独立游戏登陆 Steam。上线初期，其平均在线人数不足50人。同年9月，还有一款名叫《我不是怪物》的太空题材「狼人杀」也在 Steam 上发售，本作在制作规格上远超前者，但当时市场表现也只是稍好。</span></p>
<p style="text-align: center;"><img src="http://p3.itc.cn/q_70/images03/20200930/1bb9231b949047eb91b72ef1095a2e58.jpeg" /></p>
<p style="text-align: center;"><span style="font-size: 16px;">《我不是怪物》宣传图</span></p>
<p><span style="font-size: 16px;">如今两年时光过去了。《我不是怪物》已经石沉大海，《Among Us》则重新焕发生机：根据 Steamchart 上的纪录显示，本作同时在线人数屡创新高，峰值接近40万人。</span></p>
<p style="text-align: center;"><img src="http://p0.itc.cn/q_70/images03/20200930/322f1a392f9349e781cc0eefc0bcd403.jpeg" /></p>
<p><span style="font-size: 16px;">从产品角度来看，题材创新并不是《Among Us》意外走红的重要因素。就我个人体验而言，将「狼人杀」游戏里一语带过的谋杀、查验等环节通通游戏化，才是它的魅力所在。</span></p>
<p><span style="font-size: 16px;">「天黑请闭眼，狼人请睁眼」——当主持人说出套话后，狼人身份的玩家在眼一闭一睁之间，完成指定对象的谋杀。也就是说，通过语言和选择来推进游戏，是典型狼人杀的机制。</span></p>
<p><span style="font-size: 16px;">但是在《Among Us》中，这些曾经被简化的、抽象的环节，却是玩家获得心流的重要来源。</span></p>
<p><span style="font-size: 16px;">还是以谋杀场景为例来做个说明。伪装者实施杀人绝不是轻而易举的，你要尾行落单的船员，让别人放下戒心，然后冷不防一击索命，接着快速逃离现场，避免被人当场目击，由此被列为嫌疑对象。</span></p>
<p style="text-align: center;"><img src="http://p8.itc.cn/q_70/images03/20200930/a9ad093e5ebc49eb8b848ea6fbb8ea73.gif" /></p>
<p><span style="font-size: 16px;">发现尸体后进入票选嫌疑犯的环节，也同样被具体化了。在《Among Us》中，没有人来主持投票。只有当善良的宇航员们发现尸体后，才能召开会议进行票选（还有一种方式是触发紧急按钮）。如果无人发现尸体，伪装者便可持续作恶。</span></p>
<p style="text-align: center;"><img src="http://p4.itc.cn/q_70/images03/20200930/743f014109d243269d6d7bec510c29c1.gif" /></p>
<p><span style="font-size: 16px;">尽管游戏的画面偏卡通，但玩家总会提心吊胆。这里空间封闭而幽暗，你希望能找到结伴而行的队友，但</span><span style="font-size: 16px;">你永远不知道他那搞怪滑稽的形象之下，是否藏着一只恶魔。</span></p>
<p style="text-align: center;"><img src="http://p7.itc.cn/q_70/images03/20200930/8a2aec1aa87c446eb90aa1f1f06f892a.jpeg" /></p>
<p><span style="font-size: 16px;">所以，开发商 InnerSloth 用更具体的玩法、机制、场景和操作来填充这些中间环节后，玩家得到的沉浸感和临场体验，完全是不一样的。他们把「狼人杀」游戏里已知的流程，变成了无数的未知与危险。</span></p>
<p><span style="font-size: 16px;">我举一个游戏里很有意思的变数：玩家目睹了伪装者行凶的过程，但对方快速逃遁，而此时其他船员路过，只看见一个无辜的人身处犯罪现场。</span></p>
<p><img src="http://p2.itc.cn/q_70/images03/20200930/dfbcc4965c6b411083fd159816934f7d.gif" /></p>
<p><span style="font-size: 16px;">这时候，真是黄泥巴煳裤裆——不是屎来也是屎了。</span></p>
<p><span style="font-size: 16px;">戏剧性让游戏走红于直播圈</span></p>
<p><span style="font-size: 16px;">更具象、更游戏化，是《Among Us》有别于传统狼人杀的特质之一。</span><span style="font-size: 16px;">这种特质，让它有了更出色、更戏剧性的直播效果。</span></p>
<p><span style="font-size: 16px;">虽然它曾经无人问津。但是在《糖豆人：终极淘汰赛》火爆之后，这款沉寂两年的多人聚会游戏，终于得到了众多主播们的发掘。</span></p>
<p><span style="font-size: 16px;">在 Youtube 上，《Among Us》相关视频与日俱增，其中播放量超过500万的，不少于15个。韩国游戏主播 Kevin Choi 较早播出了该游戏的节目。在这之后，西班牙主播 Rubius 等陆续跟进，一下子推高了《Among Us》的关注度。</span></p>
<p><img src="http://p6.itc.cn/q_70/images03/20200930/3be2e7bbe3c8411c8db0f6d03da85523.jpeg" /></p>
<p style="text-align: center;"><span style="font-size: 16px;"><span style="font-size: 16px;">相关视频播放量超过千万</span></span></p>
<p><span style="font-size: 16px;">根据 TwitchTracker 的数据显示，在9月14日至9月20日之间，《Among Us》的总观看时长超过了4000万小时，位列全站第一。</span></p>
<p><img src="http://p5.itc.cn/q_70/images03/20200930/daea59fe75f849e3889370cdea6dfb62.jpeg" /></p>
<p><span style="font-size: 16px;">在 Reddit 论坛里，《Among Us》专区的关注者对游戏的命运转机更有感触。他们见证了这个专区，从几万不到的关注量瞬间暴涨到30万。截稿前，它的关注量其实已在两天内涨到了35万。</span></p>
<p><img src="http://p1.itc.cn/q_70/images03/20200930/bc64c3c7bdbe403da8069f77acfd721c.jpeg" /></p>
<p><span style="font-size: 16px;">随后，越来越多人开始制作和传播《Among Us》的玩梗内容。</span></p>
<p style="text-align: center;"><img src="http://p5.itc.cn/q_70/images03/20200930/7c354baf277f461a9f8ad63a8618c08a.gif" /></p>
<p><span style="font-size: 16px;">所以直到今天，我仍未看到它有一丝热度消退的迹象。</span></p>
<p><span style="font-size: 16px;">狼人杀的未来或许在于打破框架</span></p>
<p><span style="font-size: 16px;">可以说，在2020年，「狼人杀」又火了一次。</span></p>
<p><span style="font-size: 16px;">这是个很反常的情况。单就国内市场而言，在2017年盛极一时的「狼人杀」，其实早已滑入大众视野的边缘地带。这个关键词的百度指数走势，很好的说明了这点。</span></p>
<p><img src="http://p9.itc.cn/q_70/images03/20200930/4cade042f7b34af5bda05d91720384be.jpeg" /></p>
<p><span style="font-size: 16px;">曾为熊猫 TV 提供直播间的 JYClub 狼人杀俱乐部，也已从风口中跌落，在过去几年里陆续关停了多家分店。</span></p>
<p><img src="http://p8.itc.cn/q_70/images03/20200930/7885b105c57f448aa4ec3b54e242d40a.jpeg" /></p>
<p><span style="font-size: 16px;">知乎上有个话题，名叫「你为什么不玩狼人杀？」。该话题迄今被浏览近700万次，并得到了2494个回答。</span></p>
<p><span style="font-size: 16px;">这其中大概有三类拒绝「狼人杀」的理由。其一是害怕发言；其二是难以跨过学习门槛；其三是难以融入圈子。</span></p>
<p><span style="font-size: 16px;">我觉得第三种情况，是限制「狼人杀」实现规模化的一大障碍。传统「狼人杀」讲究程式和规则，有许多「专有名词」。新人一窍不通，与老手组局，容易遭到排斥。</span></p>
<p><span style="font-size: 16px;">一句「你不懂还玩」，往往就会引起新老双方一通争吵。我留意了一些「狼人杀」游戏在 TapTap 上的评分，它们的分数大多在4-7分，其中有大量评论在控诉老玩家排挤新人。</span></p>
<p><img src="http://p1.itc.cn/q_70/images03/20200930/4acbb5819f71400e81299e3c651c18d1.jpeg" /></p>
<p><span style="font-size: 16px;">反观《Among Us》，它在 Steam 上获得了 94% 的好评率。</span></p>
<p><span style="font-size: 16px;">我觉得，具象化的狼人杀趣味，是其获得好评的一大原因。与此同时，它也突破了传统「狼人杀」的条条框框，让更多人可以轻松融入游戏，而不用战战兢兢地面对老玩家。</span></p>
<p><span style="font-size: 16px;">具体而言，《Among Us》的票选环节实现了简化。你不必再受限于语言表达，更不必拘泥于发言的范式。使用几个简单的单词，玩家就能沟通彼此。</span></p>
<p><span style="font-size: 16px;">这里没有模板，让玩家「倚老卖老」。而去模板的结果，便是让游戏呈现了多样性。Reddit 上有位用户分享了一张趣图很能说明这点：一个 ID 为 Red 的玩家，主张大家投红色船员，结果自己因此出局。</span></p>
<p style="text-align: center;"><img src="http://p8.itc.cn/q_70/images03/20200930/e8e3100da9e24fa68d14b96d0df33db5.jpeg" /></p>
<p><span style="font-size: 16px;">这名用户说：「《Among Us》真是太难了，这里有如此之多的聪明人。」</span></p>
<p><span style="font-size: 16px;">《Among Us》的火爆，或许不意味着「狼人杀」的春天来了。但我想，同样沉寂多年的「狼人杀」，是不是可以尝试融合创新、打破框架，来拥抱更多的「聪明人」呢？</span></p>
➜网易的黑科技：以前策划写三四周AI，现在放那儿自己跑就行了
http://www.sohu.com/a/421985160_204824	43862
<p>
<table>
<tbody>
<tr>
<td><span style="font-size: 16px;">摘要：有了这样的AI之后，《逆水寒》1V1的代练就找不到了。</span></td>
</tr>
</tbody>
</table></p>
<p><span style="font-size: 16px;">整理/安德鲁</span></p>
<p><span style="font-size: 20px;">“</span></p>
<p><span style="font-size: 16px;">强化学习不需要你去写规则。</span><span style="font-size: 16px;">很多场景，以前可能策划需要写三四周的AI，交给强化学习，策划不用管这个事情，让这个机器跑着就好了。</span><span style="font-size: 16px;"></span></p>
<p><span style="font-size: 20px;">”</span></p>
<p><span style="font-size: 16px;">强化学习不需要你去写规则。很多场景，以前可能策划需要写三四周的AI，交给强化学习，策划不用管这个事情，让这个机器跑着就好了。</span></p>
<p><span style="font-size: 16px;">前几天的北京国际游戏创新大会 <span>（BIGC）</span>上，网易伏羲实验室的吕唐杰分享了他们对于应用强化学习的研究、理解和应用。 </span></p>
<p><span style="font-size: 16px;">他重点讲述了强化学习的应用意义，以及怎样与以往游戏中传统AI开发方式结合，形成1+1大于2的效果。他也谈到了强化学习在游戏中的一些落地方式。比如《逆水寒》中，更多样化的AI应用，就让玩家的PVP内容有了极其丰富的层次——“有了这样的AI之后，《逆水寒》1V1的代练就找不到了。”</span></p>
<p><span style="font-size: 16px;">以下是葡萄君整理的演讲内容。</span></p>
<p><span style="font-size: 16px;">大家下午好，我叫吕唐杰，我今天的题目是《应用强化学习来开发游戏AI》。我们从2017年年底开始做强化学习，到现在做了快三年的时间，这方面积累了一些经验，今天给大家分享一下工作的一些成果。</span></p>
<p style="text-align: center;"><img src="http://p6.itc.cn/q_70/images03/20200930/034c8e4334f34a2ea816325f7c34f405.jpeg" /></p>
<p><span style="font-size: 16px;">今天整个分享内容分成四个部分：</span></p>
<p><span style="font-size: 16px;">第一部分简单介绍一下强化学习和游戏AI，强化学习刚才有几位老总都讲过了，我就不太细讲技术细节了。</span></p>
<p><span style="font-size: 16px;">第二部分介绍一下我们自研的一套强化学习框架，RLEase。</span></p>            <div class="lookall-box">
<div class="lookall-shadow"></div>
<section class="lookall">
<a href="javascript:;" class="show-all" id="showMore">
<em>展开全文</em>
</a>
</section>
</div>
<div class="hidden-content control-hide">
<p><span style="font-size: 16px;">第三部分是我们真正通过强化学习的落地效果。</span></p>
<p><span style="font-size: 16px;">第四部分，强化学习多个场景下遇到了很多问题，我觉得还有很多需要解决的。</span></p>
<p style="text-align: center;"><span><strong><span style="font-size: 16px;">一</span></strong></span><span style="font-size: 16px;"></span></p>
<p><span style="font-size: 16px;">第一部分，先介绍一下什么是强化学习以及游戏AI。强化学习跟深度学习、监督学习不太一样，</span><span style="font-size: 16px;">强化学习更像是人类学习的过程</span><span style="font-size: 16px;">。它的目标是最大化累计的reward，我们感知到环境做一些行为，这个行为会让外部环境发生改变，外部环境对我们反馈，根据这个反馈我们学习这个行为到底好还是不好，这个目标是长期的目标，我可以承受一些短期的负惩罚。</span></p>
<p><span style="font-size: 16px;">强化学习不是看短期目标，而是看非常长期的目标，只要奔着长期目标好的事情就会做。强化学习这几年有了巨大的发展，包括这一波人工智能的技术，我觉得其实也是由强化学习来推动这个潮流。最早从谷歌用AI来玩游戏，八十年代的游戏非常简单。相对于最有名的、做得最好的两个公司，一个是DeepMind，一个是OpenAI。他们现在已经有新的OpenAI的应用，在《星际争霸2》游戏项目上做到了顶尖人类选手的水平，是以前我们做传统AI几乎无法想象的效果。</span></p>
<p><span style="font-size: 16px;">强化学习这几年取得了非常大的进展，对于游戏开发者来说，强化学习到底怎么用？你肯定很懵，这个强化学习怎么用到我们实际游戏开发里面？</span></p>
<p style="text-align: center;"><img src="http://p8.itc.cn/q_70/images03/20200930/0edc5cc9a76f4b89aa20ea20e8a523ce.jpeg" /></p>
<p><span style="font-size: 16px;">游戏开发者更熟悉的AI技术，一个是有限状态机，一个是行为树。这两种技术都认为是一种规则技术，说白了就是人去写规则，你想要它什么样的行为，你就写出什么样的规则出来。</span></p>
<p><span style="font-size: 16px;">状态机也好，或者行为树也好，只是做了AI开发范示，怎么在游戏里面把规则写得清楚，不出现太大的问题——你要写一个非常复杂的AI，或者水平非常高的AI。为什么会有这个问题？因为人自己也想不清楚到底该去怎么打，这个场景太复杂了。如果想要变得那么强的话，一个是树变得非常巨大，二是可能树之间的规则写着写着就搞不太清楚了，很难把握这个点。</span></p>
<p><span style="font-size: 16px;">强化学习可以解决这个问题。</span><span style="font-size: 16px;">强化学习是一种自学习的技术，不需要你去写规则</span><span style="font-size: 16px;">。包括我们现在落地下来一些感觉：</span><span style="font-size: 16px;">很多场景，以前可能策划需要写两周，三四周的AI，强化学习交给它，策划不用管这个事情，让这个机器跑着就好了</span><span style="font-size: 16px;">。强化学习有这个能力，但是它也会有很多的问题。</span></p>
<p><img src="http://p7.itc.cn/q_70/images03/20200930/be960e1191f74b58922eecd0a1d5c047.jpeg" /></p>
<p><span style="font-size: 16px;">强化学习技术门槛也有点高，我们想的是：</span></p>
<p><span style="font-size: 16px;">第一点</span><span style="font-size: 16px;">，</span><span style="font-size: 16px;">怎么降低强化学习的接入和使用的门槛，让更多的游戏开发者能使用上这个技术？</span></p>
<p><span style="font-size: 16px;">第二点</span><span style="font-size: 16px;">，因为强化学习技术本身发展在日新月异，学术圈非常火爆，基本每年都会大量的文章出来，新技术、新发展。研究人员可能想在我们的游戏环境中，实验一下新想法、新算法，怎么能让AI研究人员更好地理解游戏的需求？因为游戏环境还是挺复杂的，需要很多的专业背景。</span></p>
<p><span style="font-size: 16px;">第三点</span><span style="font-size: 16px;">，我们已经有很多的传统AI技术，怎么结合传统AI技术与强化学习，这个也是比较重要的问题。</span></p>
<p><span style="font-size: 16px;">第四点</span><span style="font-size: 16px;">，我们在想这个问题，如何将强化学习这个东西应用到更广泛的游戏领域，提升玩家体验。</span></p>
<p style="text-align: center;"><strong><span style="font-size: 16px;">二</span></strong></p>
<p><span style="font-size: 16px;">下一步就是介绍的我们这边做的RLEase框架，这个本质上是为了解决一些问题。我们网易有一套自己的工具，传统的开发AI的工具，我们这边叫流程图。其实就是我们写代码的时候会破坏一些示意图，我们有这样的工具来开发游戏AI，比如说用锁开门这样的AI。</span></p>
<p><span style="font-size: 16px;">左边是示例，这里面这个东西跟行为树很像。它里面每个节点有状态，有颜色代表不同的转移，跟行为树整体上比较类似。支持一些异步的模式，这个是我们现在网易这边开发游戏很常用的一套工具。</span></p>
<p style="text-align: center;"><img src="http://p4.itc.cn/q_70/images03/20200930/7bf6a84ad41a430182d9b78f339fcb7c.jpeg" /></p>
<p><span style="font-size: 16px;">第一个问题，他们开发好了很多AI，我们怎么能把强化学习结合进去，它也有很多其他逻辑在里面，不可能从头用强化学习。我们的想法是，把强化学习的技术跟我们流程图工具结合起来，强化学习里加上两种新的节点，叫SendState和SendReward。</span></p>
<p><span style="font-size: 16px;">这是一个真实游戏里的流程图，我们截出来，结合强化学习来跑。这是游戏很复杂的时候——大型的吃鸡游戏，可能有很多AI，AI怎么跑毒，碰到人怎么打，里面有很多逻辑，强化学习跟它怎么结合呢？</span></p>
<p><span style="font-size: 16px;">因为</span><span style="font-size: 16px;">强化学习技术本身并没有那么神奇，好像什么场景都能解决，它对计算量要求很高，跟它的结合点，是让它解决一些强化学习比较适合解决的问题，或者传统AI不太好做的问题</span><span style="font-size: 16px;">。比如说碰到对手怎么跟它打，这个事情AI不太好写——游戏比较复杂，技能比较多，打起来套路很多，你就不知道怎么应对对手的套路。</span></p>
<p><span style="font-size: 16px;">针对这个我们把一部分功能替换成了强化学习的函数，对它来说调了一个接口。我把当前的游戏信息发给你，你只要告诉我该放什么技能就行了，其他的我自己不管。相当于我写了一段跟战斗相关的AI，但这个AI并不是他自己写的，而是交给我们强化学习训练出来的。剩下的跑毒也好，大地图里面捡东西也好，这种不去训练。因为这种逻辑很好写，没必要交给我们来做。我们是通过这样的方式。来结合传统的规则和强化学习的。</span></p>
<p><span style="font-size: 16px;">另外，刚才讲了强化学习的技术门槛好像有点高，很多传统的写AI的不太懂。我们希望开发一套东西能让这个强化学习变得简单一点，RLEase这套框架最重要的是简化环境的接入流程，能让游戏接入成本降低，降低强化学习的门槛，特别是让AI研究人员降低大规模强化学习的门槛，目前这些特性先不细讲了。对于AI研究员来说我们提供了标准的接口，这个技术在日新月异地发展，很多时候有新的算法和新的方法尝试。我们也是这套框架里面添加了标准的接口，这个框架本身是有很多特性，对于AI研究员来说只要新写一个算法，这些特性都已经集成好了。</span></p>
<p style="text-align: center;"><img src="http://p6.itc.cn/q_70/images03/20200930/4056e61f7d0b49aea9866c4cd1b172e1.jpeg" /></p>
<p><span style="font-size: 16px;">我们这套RLEase整体上是这样，跟传统深度学习有一点不一样，是大规模的计算，对计算支援要求比较高，对于框架要求也比较高。一个是面向游戏开发团队，能降低他们的难度，另外能让AI研究人员降低开发新算法的难度。让所有的节点通信都交给我们底层通信来做。</span></p>
<p><span style="font-size: 16px;">再上层一点就是我们深度学习的能力，另外就是深度学习，这些都是在我们框架里面比较好的支持。另外我们在上层，为游戏开发团队来说提供了一个ISDK。ISDK就是给游戏团队用的，用了这套SDK可以跑运算环境，他只要拿到上层的SDK就可以了。对于AI研究人员来说，只需要关注算法和深度学习框架。</span></p>
<p><img src="http://p2.itc.cn/q_70/images03/20200930/eb056a150c9b45a5b2e39254be08e580.jpeg" /></p>
<p><span style="font-size: 16px;">我刚才讲了怎么支持这种能力，简单介绍一下我们这种分布式结构里面，精简的话会有几种概念。第一种讲了三重类型的节点，一种是Leanre，模型训练。第二是Worer，模型推心。第三是Gome，游戏 <span>（环境）</span>。这样分离的方式支持分布式，每个节点可以放在不同物理的服务器上的。另外一个是所有节点之间都会有IBC通信，比如说一些高性能的模型分发相关的功能，能支撑我们把这个训练框架的规模提高到上千甚至上万这个级别。 </span></p>
<p><span style="font-size: 16px;">听了上半场觉得这东西好像特别费资源，我们自己做下来，对于很多场景，如果不想要追求职业选手这样水平的话，并不需要那么高，所以也没有那么大的硬件门槛。</span></p>
<p><img src="http://p2.itc.cn/q_70/images03/20200930/d7d981f03cca414992e4f46c9f4550ae.jpeg" /></p>
<p><span style="font-size: 16px;">讲个例子，我们上半年给《逆水寒》做五子棋。但是玩家跟玩家之间玩五子棋的人不多，再有一点，玩家输了不太爽，有受挫感。我们当时没有做围棋的的项目，我们从头开始集成算法框架。在RLEase里面简单实现了几个模块，标准定了几个接口。这个接口实现好了之后，我们的AlphaZero已经成功了，它自带大规模分布式的能力，我们可以做到好几个节点同时跑，大概跑到23000的样子，这个五子棋的AI就已经比市面上找到的所有传统搜索AI明显要强。游戏里面不需要那么强的AI，我们为什么做这么强的AI，因为我们发现做了强AI后再做简单AI非常容易。</span></p>
<p><span style="font-size: 16px;">另外一个是我们提供的SRA，常见的开发脚本，一般来说，传统端游里面会有C++，现在手游可能在集成脚本上的Lua来做。为了让游戏方用我们的SDK，我们提供了多语言版本的支持。举个例子，这个SDK是给研究员用的。怎么用呢？你在游戏里面Input一下SDK，在你想要做请求，比如说这个AI写不清楚了，想交给AI做，这个时候插一个函数就行了。Python这个游戏自己能学出来到底该怎么打。</span></p>
<p><img src="http://p1.itc.cn/q_70/images03/20200930/999c32a4eebb4cc4864f4a20dcec0919.jpeg" /></p>
<p><span style="font-size: 16px;">开</span><span style="font-size: 16px;">发完AI之后还得有个部署。游戏线上怎么用？我们这边做了好几款游戏，积累了一些经验，我们有服务端的ASI的部署能力，部署了AI服务器，让游戏请求到AI服务器，进行AI推理，进行对应的动作。另外一个提供一些客户端部署方案，现在有在安卓、iOS上的部署。有些游戏必须是在手游上部署的，因为逻辑就在客户端上，我们提供SDK能直接把训练好的模型变成在端上的模型直接用。</span></p>
<p style="text-align: center;"><span><strong><span style="font-size: 16px;">三</span></strong></span></p>
<p><span style="font-size: 16px;">第三部分介绍一下我们在《逆水寒》里的效果，这是给他们做的一个游戏场景，是一个流派竞技的玩法。这个玩法每天可以排行榜里挑战排行更高的玩家，但MMO里玩家不一定实时在线，当这个玩家不在线的时候，可以用AI替代玩家出战。以前AI很弱，基本上都能打过。游戏方要我们提供高水平的、提供不同难度的AI，让对手也能体验到乐趣。另外也希望AI能有这样一些行为多样性。</span></p>
<p><img src="http://p1.itc.cn/q_70/images03/20200930/b96d123a445b4b94819519acf3b9a8c1.jpeg" /></p>
<p><span style="font-size: 16px;">看上去好像很简单一个场景，1V1，实际上还有很多困难。《逆水寒》里面有20个技能，每次携带10个技能出场，每个玩家携带的不一样，升级路线也不一样。因为AI是替代玩家打，这就要求AI要去适应所有玩家的技能组合。这个组合其实很多。光这样一个职业AI，就有4万多种技能组合。</span></p>
<p><span style="font-size: 16px;">怎么表示这种场景？玩家可能携带了很多技能，怎么在建模过程中表示带了哪些技能、可以用哪些技能、让模型合理地用技能？我们用01向量表示玩家携带的技能。模型可能会输出未携带技能，当它输出不合法的动作，我们会替换掉。这个游戏里面龙吟地上插很多器件，可以刷技能CD，理论上它应该要看到这个信息。</span></p>
<p><img src="http://p5.itc.cn/q_70/images03/20200930/75666a0119da49e295a73936681b0c6a.jpeg" /></p>
<p><span style="font-size: 16px;">常见想法是，深度学习直接画一张图就行了，用Image表示就可以了。这样它的计算量成倍增长，需要很多GPU、很多计算时间。但这对于这样一款游戏真正落地来说是不适合的，</span><span style="font-size: 16px;">我们不可能用这么多的代价训练这样一个AI。我们做了一个取舍：我们让AI看到这些，雷达图让AI看到周边哪些地方是有器件的，不需要那么准的位置，标一下就行了。最后展出来就是八维的向量，输入到state里面，最后测出来这个已经达到水平了。</span></p>
<p><span style="font-size: 16px;">我们训出来比较强的AI，怎么匹配多难度的玩家？一种做法是比较简单的，一种比较天然的想法，因为我们训练这个模型就是越来越强的，我把前期的模型拿出来就是弱的，中期的模型拿出来比较中期的水平。</span></p>
<p><span style="font-size: 16px;">这样就会带来一个问题——可能在线上部署了非常多的模型，在线上用的时候，我要用十几个段位，部署十几个模型，对我们挑战也非常大。我们后来只做一个模型，专家跟低水平玩家之间的差距体现在几方面，一是操作反应速度、技能释放频率。高手技能释放间隔非常短，释放速度非常快，那种动作的反应非常好。低水平玩家，这点要弱一点。</span></p>
<p><span style="font-size: 16px;">所以我们增加了一维参数，调整AI输出频率。另外高水平玩家在APM高的基础上，误操率也很低。而有些玩家，可能按的很快，但是很多时候按错了，做了很多误操作，这也是影响人水平的过程。</span></p>
<p><span style="font-size: 16px;">还有一个维度就是动作随机概率，让模型有一定概率使出随机动作，这个也比较明显地降低了玩家AI水平。另外一点，我们是在仿照人类，玩家对于战场信息判断有问题的。针对这一点，可以在输入层上加噪音，在一些关键信息——比如说血量、位置、技能的CD——这些关键信息上加一些噪音，这个AI水平也会有明显的下降。他自己也看不清了，判断就会出错。</span></p>
<p><img src="http://p2.itc.cn/q_70/images03/20200930/bafa7f715d624428967cdc971761eaec.jpeg" /></p>
<p><span style="font-size: 16px;">这些东西到底有没有用？我们做了验证，让这些参数变得水平越来越低、间隔越来越大、随机概率越来越高。我们训一个AI之后，最高水平是1600，随着参数越来越弱，水平几乎是线性下降。线上打出来的感觉，也和低水平玩家蛮像的——这个基本上已经满足了策划的需求。</span></p>
<p><span style="font-size: 16px;">我们线上部署的时候部署了一个模型，这样一个场景下，基本上能满足当前1V1的需求。对于复杂的，比如说团队游戏，这些参数可能不够，还要在策略层上做一些丰富性。不过对当前的场景来说，只能说这是一个比较好的解决方案了。</span></p>
<p><span style="font-size: 16px;">另外，我们训练出的这个AI，水平到底够不够强，开发组这边请最高水平的玩家来体验过。实际上AI水平已经非常高了。</span></p>
<p><span style="font-size: 16px;">红色的是AI，绿色的是我们这边龙吟的高手。我们AI是不掉血的，基本上所有技能都可以完美躲过。如果没玩过这个游戏可能看不太清楚为什么赢。为什么两个人放同样的技能，看着差不多的，但有一方基本上没怎么掉血？我们采访过策划，他说</span><span style="font-size: 16px;">AI的一些组合非常合理，很多时候确实是他们策划怎么设计的，打出来就是什么样的，基本满足策划的需求、设计的想法</span><span style="font-size: 16px;">。再加上可能因为是最高水平，反应非常快，所以人类反应跟不上，实际上很难打过它。</span></p>
<p><img src="http://p0.itc.cn/q_70/images03/20200930/4d5a1fd7ca4f4fc8a8c44897d0285b5b.jpeg" /></p>
<p><span style="font-size: 16px;">最终我们上线之后调了难度，不会让玩家体验到这个AI。我们调了之后在贴吧里关注了玩家的反馈，感觉整体上正面反馈远远大于负面反馈。整个策划开发团队对这样的AI效果也是比较满意的。</span></p>
<p><span style="font-size: 16px;">我们这个AI让玩家自己选择打，他挑战别人的时候也可以用AI，而且他也可以选择什么类型的AI。</span><span style="font-size: 16px;">有了这样的AI之后，《逆水寒》1V1的代练就找不到了。</span></p>
<p><img src="http://p0.itc.cn/q_70/images03/20200930/4de8ea25016344f1b47ecf37586274f3.jpeg" /></p>
<p><span style="font-size: 16px;">这是更多游戏上落地的效果，我们在格斗、棋牌，卡牌和体育游戏都有相关积累。这些AI已经上线部署了，现在就在用。右下角是正在测试的一款游戏，年底也是要上线的，这是其中的卡牌玩法。</span></p>
<p><span style="font-size: 16px;">游戏方比较重视这个玩法，原来不太好做，因为卡牌很多，也不太好测卡组的平衡性。后来AI测试的时候，基本上达到了玩家体验的时候的感觉。因为我们有酒馆，这个场景下，AI的使用率达到70%，30%是玩家之间打。具体来讲，第一是打我们的AI受挫感比较低，第二没有人知道他打AI输了。他在酒馆设计自己的套路和想法是非常适合的。</span></p>
<p><img src="http://p9.itc.cn/q_70/images03/20200930/2af274b936cb49ac9a15ab4f29979940.jpeg" /></p>
<p><span style="font-size: 16px;">还有一些附加的效果，</span><span style="font-size: 16px;">强化学习还能做一些什么事情？比如说刚刚讲的平衡性测试</span><span style="font-size: 16px;">，我们在《逆水寒》里面做过，龙吟这个职业上线前做过一些平衡性测试，去看一下它跟其他职业整体对战的效果。</span></p>
<p><span style="font-size: 16px;">第一版给我们测之前，训完AI效果大概就是——这个职业碾压所有其他职业，而且碾压度非常高，是完虐型的打法。然后我们给开发组提供数据，给他们截了一些视频，他们看过之后做了一些数值、技能迭代。迭代完以后再测，测完后再给新版本。龙吟上线之后经历过三次版本，可以看到上线的效果，做种版本没有起初的那种碾压效果。</span></p>
<p style="text-align: center;"><span><strong><span style="font-size: 16px;">四</span></strong></span></p>
<p><span style="font-size: 16px;">强化学习也有很多问题，比如拟人化的游戏AI。怎么解决这个问题，一种比较简单的想法：用专家数据进行模仿学习。这里有个很大的问题是需要数据，如果是“像人”的话，接受学习肯定需要大量的玩家数据。</span><span style="font-size: 16px;">这里存在一个悖论，游戏对于AI最大的需求是游戏上线之后一开始那段时间，玩家不多的时候让AI活跃游戏</span><span style="font-size: 16px;">。当然，像《王者荣耀》那样热门的游戏，可能AI的需求度没那么高，因为玩家之间所有的难度匹配都能满足需求。</span></p>
<p><span style="font-size: 16px;">而如果游戏还没上线，游戏刚开始的时候需要AI，我们数据从哪儿来？没有那么多的玩家，这是一个比较大的问题。</span></p>
<p><img src="http://p9.itc.cn/q_70/images03/20200930/4cf9d47435d74edfb4ecaf796ee9b6f5.jpeg" /></p>
<p><span style="font-size: 16px;">另外，采集数据的时候是需要预处理的，预处理工作量比较大。还有一个困难，</span><span style="font-size: 16px;">“像人”是主观的</span><span style="font-size: 16px;">，实际上我们发现它非常主观，每个人都有自己的想法，关于像人到底是什么也是非常大的问题，怎么样评价像人这样一个指标？我们能想到的一点，是让玩家测试，直接让玩家做一些黑箱测试，让他判断对面是人还是AI。但这个成本比较高，因为要请一些玩家测试。怎么样通过数据评价？这是比较难的问题。</span></p>
<p><img src="http://p0.itc.cn/q_70/images03/20200930/0041c80b5dbf426da5f9d2f58496dd2d.jpeg" /></p>
<p><span style="font-size: 16px;">还有一个问题在模型上线之前。模型是个神经网络，很多时候动作会输出一些不合人类逻辑、常识的行为出来。所以策划跟QA一般给会很多意见，AI上线之后，持续迭代的过程中也会给很多意见。怎么样把这些意见跟模型结合起来？这也是比较大的问题，也有点难。</span></p>
<p><span style="font-size: 16px;">比较简单的，可能我在流程图里面插一些规则，在某些策划的强制建议里面走强制建议就行了。但这个时候也会出现意想不到的情况，比如说模型的输出跟策划的输入是矛盾的。因为可能没法控制模型它到底是什么行为，它有自己的想法，还有可能是对的，只是不符合我们的认知而已，有可能会出这样的一些死循环。</span></p>
<p><span style="font-size: 16px;">还有另一个比较大的需求——就是不仅需要拟人化的高水平AI，还希望AI的打法多一些，提升玩家乐趣。我们做过尝试，在《逆水寒》中做了多样化的AI。比如说右边这三个神像，有三种完全不同的打法。平衡型的可能符合正常人的思路，还有激进型的、保守型的。我们这边的一些经验，是可以结合进化算法来做的，</span><span style="font-size: 16px;">进化算法跟强化学习产生多种高水平的AI。进化算法比强化学习还高，这两种结合的要求会更高</span><span style="font-size: 16px;">，成本可能会超出我们目前能够承受的门槛。</span></p>
<p><span style="font-size: 16px;">另外，其实进化算法也需要设定一些目标。我们可能一开始是激进也好，保守也好，都是对这个游戏有一定的理解的，知道某个游戏有什么样的风格才行。如果是完全不同的游戏，就需要专家给出解答。因为策划的表述，并不是直接转化成我们理解的、直接用在算法里的东西。</span></p>
<p><span style="font-size: 16px;">这是我今天所有的内容了。总的来说，我感觉强化学习技术还是挺棒的，能做很多事情。但是也有很多新的问题，我们也在持续的探索过程中。</span></p>
<p><span style="font-size: 16px;">我们团队在很多新问题上做方法的尝试，或者是性能、效果的提升。希望</span><span style="font-size: 16px;">未来强化学习这个技术能在更多场景上——不只是游戏AI——还包括像自动化测试、关卡生成、关卡难度评价。我们确实看到它有这样的潜力</span><span style="font-size: 16px;">，只不过真的要达到这种能力，还需要很多深入研究。</span></p>
<p><span style="font-size: 16px;">今天就先到这儿，谢谢！</span></p>