➜人人皆可换脸，眼见不再为真：深度伪造如何影响了我们的安全与道德？
http://www.sohu.com/a/428099384_99897611	7200
<p><span>撰文 | 实习生 胡辰</span></p>
<p><span>编辑 | 黄月</span></p>
<p><span style="font-size: 16px;">印度Tehelka杂志社的记者拉娜·阿尤布（Rana Ayyub）曾卧底报道了印度古吉特拉暴乱中的教徒屠杀，揭露这一事件中官员的黑幕和不作为，没想到，等待她的不仅是死亡威胁，还有以其为主角的伪造色情视频。一些人利用深度伪造技术，将她的脸与色情片女主角的脸互换，合成粗糙的短视频，而这一虚假的图像骗过了成千上万的人，在脸书、推特和WhatsApp上广泛传播，甚至连家人都来问她：“这是你吗？”随后阿尤布的家庭地址等个人信息被曝光在网上，她收到了大量强奸威胁。</span></p>
<p><span style="font-size: 16px;">阿尤布的遭遇并非个例。她的报复者利用了一键生成裸照软件Deepnude，使用者可以上传任意一张女性照片，系统将自动“脱去”她的衣服。这项技术基于数据库中大量裸体照片，可以看起来相当真实地将不同人的身体和脸部相匹配。这一网站已经被全世界超过100,000名用户使用，其中有25,000个日活账号。内部调查显示，大约63%的使用者表示他们想要在软件中“脱去”衣服的对象是现实生活中认识的女孩。</span></p>
<p><img src="http://p5.itc.cn/q_70/images03/20201029/48e1ed28a3aa4f0f95ecafacc77d1e81.jpeg" /></p>
<p><span style="font-size: 16px;">拉娜·阿尤布（来源：Tribune India）</span></p>
<p><span style="font-size: 16px;">更为棘手的问题是，制作这样一个色情视频大约需要个人的491张图片，照片可以从受害者的社交账户上获取，这无疑降低了骚扰、侵犯和侮辱他人的成本。在未来，制作一个深度伪造视频甚至不需要大量的原始数据色彩，也许一张图片就足够创建一个视频。一个名为StyleGAN的人工智能系统在接受了近70个人体模型肖像的训练后，被用来在一天内生成100万张脸。</span></p>
<p><span style="font-size: 16px;">近些年来生成虚假图像所利用的技术发展迅速，以往需要高超技巧和高级图片编辑工具才能实现的效果，在今天变得轻而易举。在科技发展的暗面，犯罪的温床也在扩大，看似中立的技术背后隐藏着深刻的社会结构性偏见。在人类迈入人工智能时代之时，我们又应如何与大门口的陌生人共处？</span></p>
<p><img src="http://p5.itc.cn/q_70/images03/20201029/ec1aaba82cf041848f7511583ddc2fa7.jpeg" /></p>            <div class="lookall-box">
<div class="lookall-shadow"></div>
<section class="lookall">
<a href="javascript:;" class="show-all" id="showMore">
<em>展开全文</em>
</a>
</section>
</div>
<div class="hidden-content control-hide">
<p><span style="font-size: 16px;">StyleGAN系统的深度伪造效果</span></p>
<p>01</p>
<p style="text-align: justify;"><span>深度伪造技术中的偏见与歧视</span></p>
<p><span style="font-size: 16px;">催生深度伪造的是技术人员一个简单的想法，两个深度学习的算法相互叠加，最终创造了一个复杂的系统。这个系统可以实时匹配面部表情，并无缝切换生成换脸视频。深度伪造开发者表示，该技术正在迅速发展，他们可以模仿的对象没有限制。这也就意味着它既可能在明星身上使用，也极有可能用于任何普通人。每一个人都是潜在的目标。</span></p>
<p><span style="font-size: 16px;">人工智能重塑人的认知，而人作为人工智能的开发者将固有的偏见传递给了技术。技术并非中立，它复刻且放大了不公正的社会结构，也反映并强化了既有的、结构性的性别秩序。马里兰大学法学教授Danielle Citron曾参与了美国众议院情报委员会有关人工智能深度伪造的听证会，他在关于网络骚扰的研究中发现，这种现象越来越多发生在弱势群体身上，深度伪造的滥用可能会使技术弱势者处于更加不利的位置。</span></p>
<p><img src="http://p4.itc.cn/q_70/images03/20201029/2c9edd713c6a458bacc0aa19a41cfb69.jpeg" /></p>
<p><span style="font-size: 16px;">来源：视觉中国</span></p>
<p>02</p>
<p style="text-align: justify;"><span>同情心是如何消失的？</span></p>
<p><span style="font-size: 16px;">2017年，美国社交网站Reddit留言板上出现了deep fakes小组，让那些没有多少机器学习知识的人更容易创建自己的影片。该小组的负责人在接受采访时说，他不是专业研究人员，只是对机器学习感兴趣的程序员，他找到了一种算法来进行面部交换，并以色情影片的方式训练这一算法。高度依赖数据和计算、需要复杂技术才能实现的深度造假，在推广和使用过程中愈加方便易行。深度造假正向着廉价造假转化，借助一些低价乃至免费的软件，消费者无需专业知识和技术能力，即可通过终端实现调整速度、摄像头效果、更换背景、实现换脸等操作。这在一定程度上成为了色情视频滥觞的源头。</span></p>
<p><span style="font-size: 16px;">这种轻易生成的色情视频将很大程度上损害女性的工作前途、人际关系、名誉和心理健康，造成污名化女性、色情报复的恶果，使女性暴露在某种集体监视之中，网络也有可能滑向隐形的性交易场所。斯坦福大学历史学家、传播学学者弗莱德·特纳在追溯二战期间美国人对大众传媒的强烈恐惧心理时指出，媒体不仅会影响人们的观念，也会制造出新的感受和欲望，并将人们内心最深处的诉求激发出来。与之类似，裸照生成软件会将某些需求合理化和显性化。</span></p>
<p><img src="http://p0.itc.cn/q_70/images03/20201029/f2025fdd98ed4e1fb2c13fee36117e1a.jpeg" /></p>
<p><span style="font-size: 16px;">来源：图虫创意</span></p>
<p><span style="font-size: 16px;">这种轻松易得的方式也将削弱深度伪造生产者的道义责任和负罪感，因为屏幕带来的距离感使其似乎并没有参与到“实际”的影像生产当中，他认为自己不过是按下了鼠标而已。这仿佛构成了当代版的“现代性与大屠杀”——当每个人只是生产链条中的一个环节，而不与受害者产生直接关联时，他是否还能体认自己的罪行？</span></p>
<p><span style="font-size: 16px;">这种距离感同时也会削弱人们的同情心，传播学学者彭兰曾提出了“数字化元件”的概念，指的是在数字化生存状态下，一个完整的人被数据和技术拆分为可以相互独立的不同部分，这将影响我们如何存在以及如何认识他人。在此过程中，人极有可能被进一步被物化和他者化，进而丧失对他人最起码的同理心。</span></p>
<p><span style="font-size: 16px;">回到文章开头阿尤布的故事，她说自己已经承受了多年的网络性骚扰，但当她报案时，警察笑着观看那些深度伪造的照片。正如《智能机器时代：人工智能》一书所引用的机器人专家普菲弗尔的论述，感同身受是属于人类的智能，深度伪造将可能带来更大的信任危机。</span></p>
<p>03</p>
<p style="text-align: justify;"><span>如何应对“眼见不为实”？</span></p>
<p><span style="font-size: 16px;">深度伪造技术的出现和推广是一个重要的信号，它预示着人类社会未来将可能发生的视觉文化的重塑。</span><span style="font-size: 16px;">然而我们早已习惯了感官输入的物质世界，尚未做好如何应对非本能、非习得信息的准备。</span><span style="font-size: 16px;">中国传媒大学人类命运共同体研究院副院长姬德强认为，眼见为实在过去的人类历史中占据着最基本的认识论权威，人们相信视觉文本的客观性属性。</span><span style="font-size: 16px;">而深度造假的技术优势和游猎特征对这一权威造成了前所未有的挑战，其生产的视觉文本既造成了文本的自我颠覆，也从根本上颠覆了客观性或者真相的生产体制。</span><span style="font-size: 16px;">这将打破符号的社会共识，对视觉文本的不信任也会深刻瓦解社会的意义和价值空间。</span></p>
<p><span style="font-size: 16px;">美国众议院情报委员会于2019年6月13日组织听证会，重点分析了深度伪造技术影响下的国家和选举的安全风险，可被视作对此前美国政治领域由深度伪造事件带来的一系列危机的回应。这些危机包括2018年4月有技术团队制作了涉及美国前总统奥巴马的换脸视频，在视频中“奥巴马”称美国现总统特朗普为“彻头彻尾的白痴”；2018年5月，有人利用深度伪造技术制作了特朗普的视频，批评比利时的环保政策等。它们已经威胁到美国的政治秩序和选举。</span></p>
<p><img src="http://p0.itc.cn/q_70/images03/20201029/afefdbe44ac14dca9064920f54cdc5d5.jpeg" /></p>
<p><span style="font-size: 16px;">真实奥巴马图像与深度伪造图像的对比画面（来源：Youtube/UC Berkeley）</span></p>
<p><span style="font-size: 16px;">深度伪造很难真正被发现，并且存在法律盲区——即它是基于公开照片生成。欧盟曾提出“被遗忘权”的概念，以应对当今的数据滥用和数据暴力问题，然而，被遗忘权如何在真实生活中得以落实？公开的数据是否还属于个人？谁有权利删除数据？违法者或侵权者的数据是否拥有同样的权利？除此之外，当平台发现疑似深度伪造视频时，它是否能简单删除以规避责任，这种行为又是否会妨碍传播自由？</span></p>
<p><span style="font-size: 16px;">虚拟照片的版权归属界定似乎也是一个问题。Generated photos官网上写到，“所有的照片都是由AI系统从零开始创建。任何的照片都可以不受限地用于任何目的，而不用担心版权、分发权、侵权赔偿和版税的问题。”所以，如果一张照片完全基于庞大的数据库自动生成，那它还属于任何人吗？</span></p>
<p><img src="http://p1.itc.cn/q_70/images03/20201029/e3a05991d3b64dc1a1b789570a469ef3.jpeg" /></p>
<p><span style="font-size: 16px;">2019年1月25日，美国华盛顿，一名记者在自己的办公桌上观看一段利用人工智能操纵的“深度伪造”视频。（来源：视觉中国）</span></p>
<p><span style="font-size: 16px;">计算机与人工智能在带来的便捷和红利的同时，也如一把达摩克利斯之剑悬挂在人类社会的头顶。对于技术发展的盲目乐观和自信，正让我们逐步失去对技术发展以及技术背后隐藏的权力结构的关注。总之，深度伪造问题不仅与技术进步有关，更关乎平台的责任、传播和言论自由、社会伦理和社会治理以及人的存在方式。</span></p>
<p><span style="font-size: 16px;">本文为独家原创内容，撰文：</span><span style="font-size: 16px;">胡辰</span><span style="font-size: 16px;">，编辑：黄月，未经界面文化（ID：Booksandfun）授权不得转载。</span></p>
➜“全民抑郁”的调侃，暴露了怎样的偏见？
http://www.sohu.com/a/428099471_99897611	7200
<p>最近，一名患抑郁症的大学生被拒绝登机。当事人在登机前因为服用了药物，导致手抖，春秋航公司认为她“情绪激动、病情不明”，可能影响航班旅客安全，拒绝让她登机。</p>
<p>春秋航空的做法是对大多数人的保护，还是对抑郁症患者的歧视？这一问题随即引起争议，也暴露出人们对抑郁症等精神疾病的不同态度。</p>
<p>据世界卫生组织报告，2019年，中国患抑郁症人数已达9000万，这个数字还在呈上升趋势，并且开始出现患者低龄化现象。这两年，随着精神疾病相关知识的普及，人们对抑郁症的认知有了一定提升，但与此同时，关于“全民抑郁”的调侃也不断出现，“矫情”、“脆弱”成了贴在抑郁症上的标签。</p>
<p>为什么人们对抑郁症有这么强的偏见呢？今天我们就来聊聊这个话题。</p>
<p><strong>点击小程序 · <span><span>观看视频</span></span></strong></p>