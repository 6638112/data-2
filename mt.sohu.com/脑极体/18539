➜Uber安全员担责，掩盖自动驾驶的追责困境
http://www.sohu.com/a/422647654_99997500	57573
<p>还记得2年多前Uber的那起自动驾驶汽车导致行人死亡的车祸吗？最新消息是，今年的9月15日，亚利桑那州的大陪审团决定以过失杀人罪起诉当时Uber自动驾驶汽车前安全驾驶员拉斐尔·瓦斯奎兹，并建议判处其2.5年有期徒刑，而这位安全员当庭表示拒绝认罪，这场官司可能还要继续打下去。</p>
<p class="ql-align-center"><img src="http://p6.itc.cn/images01/20201004/f5d802d02fc74c5a82f1b9d8ecdd929e.jpeg" max-width="600" /></p>
<p>这场事故背后的责任方Uber呢？其实早在去年3月份，作为肇事方的Uber已经被美国法院判定无罪。</p>
<p>被称为“自动驾驶致行人死亡第一案”的当事方就这样轻而易举地逃脱担责，让这个确实存在一定过错的安全员来承担全部罪责。这结果确实令人唏嘘，难道这是一起“大公司作恶，小职员背锅”的司法腐败？抑或是，这场判决是美国司法的老模式遇到新问题，不知道如何对自动驾驶算法系统及其所有者做出裁定？</p>
<p>在有安全员监控的自动驾驶测试或者商用中，我们自然还是会把车辆的安全事故责任归咎于这个安全员，但一旦真正的无人驾驶大规模普及，车上的安全员，甚至是方向盘、刹车都去掉之后，车辆的安全事故责任，那自然就要算到研发和使用这套自动驾驶算法的企业主体身上了。那么到时候，关于自动驾驶算法的追责将变得更加复杂。</p>
<p>在讨论这一问题之前，我们不妨回到Uber的这起车祸细节中，来看下这场车祸判决存在哪些争议点，Uber是否真的可以全身而退？一旦去掉安全员，无人汽车和自动驾驶算法该如何担责？这些看似未来才会遭遇的问题已经摆到了你我的面前，亟待思考和讨论。</p>
<p><strong>回到现场：车祸是如何发生的？</strong></p>
<p>去年11月，美国国家安全运输委员会（NTSB）发布了一份报告，披露了Uber自动驾驶汽车在碰撞前10秒的细节。值得注意的是，当时已经判决了Uber平台无责，但是这份报告中却指出了Uber自动驾驶系统有种种漏洞。</p>
<p>这起车祸的大致经过是这样。2018年3月18日晚上，亚利桑那州坦佩市一位女性在推着自行车过马路时，被时速60多公里Uber无人驾驶汽车撞死。</p>
<p>如果这辆车只是一辆普通车辆，那么事故责任就很明显，一边是行人横穿马路，负有一定责任，但车辆司机因没有及时刹车和避让，要负主要责任。但这辆车是Uber的无人驾驶测试车辆，车上面配有一名安全员，负责处理车辆的紧急情况。</p>            <div class="lookall-box">
<div class="lookall-shadow"></div>
<section class="lookall">
<a href="javascript:;" class="show-all" id="showMore">
<em>展开全文</em>
</a>
</section>
</div>
<div class="hidden-content control-hide">
<p>在这起车祸中，这名安全员显然没有尽职尽责。根据调查，这名安全员在行车过程中，一直在通过手机观看类似于“中国好声音”的娱乐节目，这期间监控摄像头拍到他一直在反复低头，直到事故发生前的0.5秒，他才注意到车辆前方的行人，最后只是在撞到后的0.7秒才踩下刹车，但事故已经发生了。</p>
<p class="ql-align-center"><img src="http://p7.itc.cn/images01/20201004/1eb9b4f740bf4d93828f332a56513bf7.jpeg" max-width="600" /></p>
<p>这场事故判决安全员担责是毫无问题的。毕竟他的职责就是确保车辆行驶安全和道路行人安全，可由于他的疏忽大意，直接造成了这一严重事故。日常生活中，大量的行车事故大多由这类疏忽大意造成。</p>
<p>但正是Uber无人驾驶车辆的自动驾驶系统给了安全员一种错觉，认为车辆可以自行判断前方的路况，而自己可以偷懒去看手机。这也是自动驾驶技术等级中L3级别的困境。车辆可以高度自动驾驶，但是出了事故要算驾驶员的。那么怎么可以让驾驶员放心的休息或者娱乐游戏呢？</p>
<p>回到Uber这辆车，难道它就没有任何问题么？从调查来看，问题也很多。</p>
<p>在Uber车辆撞到行人前的10秒中，车辆本来识别到这个行人并避免车祸的。但是一系列系统的误判导致了车辆未曾减速就撞了上去。报告中有几个关键数据：在9.9秒到5.8秒中，汽车从56公里加速到70公里；在5.6秒，汽车毫米波雷达（Radar）第一次检测到前方有物体，并识别其为“汽车”，5.2秒，汽车激光雷达（Lidar）第一次检测到前方物体，将其识别为“其他”，判定其静止不动。4.2秒到2.7秒，汽车对识别对象在“汽车”和“未知”之间来回摇摆，但是没有参考对物体的跟踪历史记录，最终将其判定为静止物体。</p>
<p class="ql-align-center"><img src="http://p5.itc.cn/images01/20201004/c5e436bba7c54c3fbe0ae240fbb50a50.jpeg" max-width="600" /></p>
<p>2.6秒到1.2秒的时间，激光雷达才将物体识别为静止的自行车，但又出现判定摇摆，等到重新识别为自动车，并决定制动。但车辆真正制动是在车祸前的0.2秒开始。这时时速64公里的车辆已经无法避免撞到行人。车祸发生。</p>
<p>我们看到，在车祸发生前的几秒钟，车辆发生了多次摇摆不定的误判，浪费了大量时间。根据NTSB报告指出，造成事故的关键问题就是，软件无法正确预测受害者的类别和运动轨迹。如果系统及早正确地识别出前方物体是行人，就应该大幅放慢速度，或者设法绕开避让。</p>
<p>但是Uber的自动驾驶系统并没有如此谨慎行事，反而是因为Uber认为紧急制动系统会造成车辆的不稳定，所以对该系统做了限制。</p>
<p>也就是说，Uber把自动驾驶系统的刹车当成了最后才考虑的因素，真是细思极恐。</p>
<p><strong>自动驾驶系统开车，安全员负责？</strong></p>
<p>如果按照NTSB的调查，那么Uber的自动驾驶系统就存在巨大安全缺陷，首先是汽车的识别算法的准确度和时效性问题，其次就是对于紧急制动系统的设置权限问题。NTSB得出结论说，Uber取消车辆出厂自带的自动紧急制动系统的做法，增加了在公共道路上测试自动驾驶车辆的风险。</p>
<p class="ql-align-center"><img src="http://p5.itc.cn/images01/20201004/a549be6ecc9049e59689f58ec4a5304d.jpeg" max-width="600" /></p>
<p>据调查报告，这辆Uber汽车在车祸前，已经以自动驾驶模式运行了约19分钟，车辆大约至少行驶了约22公里。那么在这段距离内，如果安全员没有踩过一次刹车，那就意味着自动驾驶系统也很可能没有启动过一次刹车。如果有开车经验的人来说，哪怕是夜深人静的街道，很少会在以每小时接近70公里的时速下行驶20多公里，都不需要减速或刹车。</p>
<p>如果是Uber真的把刹车权限交给了安全员，那么这个安全员怎么又可能在完全不顾及自己和行人安全的情况下，在高速行驶中还敢沉浸在娱乐节目当中。</p>
<p>也就是说，Uber将刹车权限交给安全员的同时，却没有让安全员意识到自己要百分百了解这一安全措施。Uber通过设置安全员规避了法律风险，但是它自身却没有预计到车辆的安全风险，也没有尽到告知义务，使得一个被算法“忽悠”的人类成为自动驾驶技术走进现实世界的注脚。</p>
<p>反过来说，一辆汽车的自动驾驶系统在自动驾驶模式下系统没有刹车权限，而是完全需要安全员操作的话，那么这场自动驾驶测试到底意味着什么，一场假的自动驾驶测试吗？</p>
<p>根据Uber的一名离职工程师的说法，“Uber的车祸发生率会还是太高了”，“如果是Waymo出现这样的表现，就会停止测试以找出原因，而Uber则会忽略这一问题”。</p>
<p>这些问题也正是外界诟病Uber的无人驾驶计划的地方。Uber既想通过激进的自动驾驶计划来推进其自动驾驶出租车业务的商业化，又想通过设置安全员来规避其在自动驾驶系统上的缺陷和漏洞，最终出现问题，还可以把责任推给这些雇员。</p>
<p>显然，Uber做到了。在2018年底，Uber又恢复了部分城市的无人车路测，为每辆车配备了2名安全员，并进行更为严格的监控，以及对自动驾驶系统做了优化。</p>
<p>而对于当地的司法机关来说，判决Uber无需担责的原因则很简单，就是“没有任何判决依据”。</p>
<p><strong>无人驾驶之后，谁来真正担责？</strong></p>
<p>因为缺乏法律责任的认定，这次Uber得以“侥幸”逃脱。但根据以上分析，Uber在事实责任面前是难辞其咎的。</p>
<p>首先，Uber自动驾驶系统并没有以安全作为第一考虑要素，而是更强调系统的稳定性和持续性。这是为Uber无人车出现众多安全事故埋下了隐患。如果未来Uber是以这样一套“激进”的算法来推进其无人驾驶出租车的行驶策略，那么，很容易出现车辆以快速行驶优先而忽略道路安全的情况。</p>
<p>其次，该驾驶系统的测试存在纰漏，按照其对制动系统的设置，需要安全员的干预才能完成，这显然是背离自动驾驶技术的本意。显然，这样的系统是无法真正实现无人驾驶的商用的。</p>
<p>就在Uber出现致命事故的同一年，美国的加州却进一步放松了无人驾驶的监管，可以允许车辆上没有安全驾驶员，只需要保证自动驾驶车辆出问题时，能被远程接管即可。</p>
<p>2019年，Waymo就拿到了加州机动车辆管理局（DMV）颁发的完全自动驾驶测试牌照，测试时可以不用安全员。后面在无人驾驶出租车上，乘客也已经可以打到没有安全员的出租车，只是在遇到突发危险后，可以在行驶中按下汽车帮助按钮或在应用程序中与安全员取得联系。</p>
<p class="ql-align-center"><img src="http://p3.itc.cn/images01/20201004/d0648035bd4f4c9cb05437c2f35ec2eb.jpeg" max-width="600" /></p>
<p>那么，这一情况下，就必须要考虑到无人车的新的责任归属和相关问题了，毕竟车辆出现事故不能再归咎于远程指导的安全员了。</p>
<p>那责任归属其实就比较简单了。在根据正常的交通事故责任认定后，如果排除了对方责任之后，那么事故责任就会判定为无人驾驶汽车的责任，但至于是车生产商、自动驾驶系统提供商或业务运营方来承担责任，则需要根据商业模式的责任划分和对现场事故的原因判定来进行划分。</p>
<p>但这里会有一个法律责任主体缺失问题。在现有一般情况下，几乎每一场事故都会有专门的人来对此负责，大多数都是违规肇事司机，但一旦换成无人驾驶汽车，那么也就找不到这样一个法律责任主体。因为不可能去控告一个购买了无人驾驶汽车的车主吧，毕竟他没有开车，也不可能去控告设计了这个自动驾驶算法的工程师吧，工程师又不是一个人，事故原因也不能仅仅归因于某行代码。那么，归结于提供自动驾驶系统的公司吗？那这样没有任何一家公司会在愿意承担如此巨大的风险了。</p>
<p>也许未来将会有一个由自动驾驶汽车各方和保险公司共同成立的责任主体，这些制造、设计和运营各方根据责任大小承担相应比例的保险费，无人驾驶的私家车主（估计会很少是个人）也会在购买服务中支付一定的保险费用，形成一个保险资产池，来应对可能出现的事故。</p>
<p>这个责任主体对事故承担整体的责任认定和赔偿，同时也在内部形成一套AI测算系统，根据不同汽车厂商的车辆损坏情况、不同自动驾驶算法的事故率和运营商的运营策略来认定具体责任，以决定不同主体未来的保费。</p>
<p>比如，有些汽车厂商以保障车内乘客的安全优先，那么在出现事故导致行人受损后，基于这种策略的公司就要多交保费；如果有些厂商是以保障行人乘客的安全优先，出现车内乘客受伤或致命事故，就要多支付费用，多赔付车内乘客。</p>
<p>可以预见，当自动驾驶无人车普及之后，各种各样复杂状况的责任认定案例会层出不穷。我们必须在此之前就要开始思考和尝试立法工作。而不是等到事情发生之后，才开始摸索。千万不要像Uber案例一样，最终只能把罪责扣在这个不负责任的人类身上，而对自动驾驶算法系统束手无策。</p>
<p>对无人驾驶汽车的严苛管制，并不意味着我们不看好这一产业。在我看来，无人驾驶汽车的前途是非常光明的。尽管会出现这样那样的极端事故，但是无人驾驶在未来一定会比现有的人类驾驶的出行状况是更安全的。</p>
<p class="ql-align-center"><img src="http://p9.itc.cn/images01/20201004/99322e51b36d48c6a3a542b95cd5c05f.jpeg" max-width="600" /></p>
<p>就像目前Waymo出现的众多事故中，绝大多数都是人类司机的全责。当未来一旦无人驾驶汽车占据多数的时候，我们就不必再小心这些车辆，而是要更小心人类司机的车辆了。因为自动驾驶系统开车时是不会去看“达人秀”的。</p>