➜时间胶囊式玩法，AR社交应用“物布空间”上线苹果应用商店
http://www.sohu.com/a/415131962_395737	14567
<p>在一条消息可以在毫秒间跨越山河大海的时代，仍然有一些地方，不迈出双脚就永远无法到达，有一些心境，需要你去到那里才能体会。</p>
<p>沉浸式AR社交应用“物布空间（Arteffect）”，现已上线苹果App Store，玩家可免费下载体验。据悉，“物布空间”由北京新势界科技打造，致力于提供一个以Z世代为切入点的沉浸式利基社交综合应用。</p>
<p>在这里，你可以用游戏化的交互方式把生活的感知（情感、个人信息等）加载到数字化的时间胶囊 —— “物布”之中，再把它用AR的方式发布在所处地点的真实情景里，无论多久，“物布”都会等待你指定的人在身临其境中将其开启。</p>
<p class="ql-align-center"><img src="http://p2.itc.cn/images01/20200827/aa10d0885596482287bcf11f401d61f9.jpeg" max-width="600" /></p>
<p class="ql-align-center"> “物布空间”把时间、空间、信息有机地结合在一起，第一次允许我们用手机播种数字化的时间胶囊，</p>
<p class="ql-align-center">并以此作为沟通的支点，开创了前所未有的AR表达方式。</p>
<p>让C端用户耳目一新！</p>
<p>如何让C端用户耳目一新？新势界科技在深耕“物布空间”的功能逻辑以外，与北欧设计巨头North Kingdom （北部王国）携手，打造了一套游戏化的视觉语言体系，为这个新颖的表达方式匹配上独特的视觉体验。</p>
<p class="ql-align-center"><img src="http://p9.itc.cn/images01/20200827/a0701e24b6a34ecea9cda94905399c4a.jpeg" max-width="600" /></p>            <div class="lookall-box">
<div class="lookall-shadow"></div>
<section class="lookall">
<a href="javascript:;" class="show-all" id="showMore">
<em>展开全文</em>
</a>
</section>
</div>
<div class="hidden-content control-hide">
<p class="ql-align-center"> 新势界科技与北欧设计巨头North Kingdom （北部王国）为“物布空间”携手打造游戏化的视觉语言体系。</p>
<p>不仅如此，新势界科技还与国内领先的声音制作公司Mega Wave Music Production （北京响鼓）合作，为“物布空间”量身定制了其应用音效与背景音乐，在满足使用者视觉感受的同时，第一次在社交应用中为人们带来更为沉浸的听觉体验。</p>
<p>“物布空间”打破了既有社交媒体的表现方式，从“地点”出发，让每个用户都可以变身成为AR空间的创作者，在由物布打造的社区中，让想象力和创造力在这个充满神奇的维度中不期而遇。而在社区中创作优质内容的AR达人们，我们将其定义为“物布一代”，在这个独一无二的展示空间中，“物布一代”代表着不同领域中的潮与酷，代表着物布世界中的与众不同。</p>
<p>为了增加C端用户的粘度，新势界科技的研发团队为“物布空间”设计了详尽、周密的功能升级计划，在视线内的时间中，将一一解锁“物布空间”的秘密，让用户感受更多新颖、独特、有趣的AR社交体验。</p>
<p>开启“地点+信息”的AR新媒体时代</p>
<p>“物布空间”借助其新颖的AR社交方式，开启了全新的AR媒体时代。在社交赋能AR落户C端的新平台中，媒体的表达方式也将跳出虚拟的互联网世界，第一次让数字信息与真实的场景有了实质意义的结合，为现有互联网的媒体提供一个整合资源、再次增值的新平台。</p>
<p class="ql-align-center"><img src="http://p0.itc.cn/images01/20200827/ff419b7274e24de6985dd0e3031331fc.jpeg" max-width="600" /></p>
<p class="ql-align-center"> 在“物布空间”中，人们慢递自己的心情，在身临其境中分享每个人的小确幸。</p>
<p>在这个全新的AR媒介平台上，虚拟的一切将因为“地点上的”社交圈而变得直观，“触景生情”与“身临其境”不再是存留在字典中的词语，它们变身为一种全新的“地点+内容”、“地点+体验”、“地点+运营”的媒体运营、增值服务机制。在物布的AR空间里， 那个被拆除的编号为002-06的“鹿角邮筒”将永远存在于中山东一路的街角，无论时间如何推移，粉丝们始终可以在偶像留下的情景中互动。</p>
<p class="ql-align-center"><img src="http://p4.itc.cn/images01/20200827/9c7ded85f32544c7bc851712d9946667.jpeg" max-width="600" /></p>
<p class="ql-align-center"> “物布空间”期待更多优质AR内容的创作达人们以及MCN机构加入“物布一代 ”，展现不同领域中的潮与酷。</p>
<p>社交与地点的叠加，产生了更大的交集，由此带来的强关联，将快速汇聚地点周边带有共同特性的用户，“圈子”的运营可以不再以生活主题分类，而是以叠加在“地点”上的“感知”将路过的用户结合在一起，邀请他们与信息发生个性化的交互，并触发内容及信息的裂变传播，从而引发更广泛的链式反应。</p>
<p>在这个崭新的AR媒介平台中，信息、地点与人之间的交互方式将进一步促进媒介多样化的形成。人与信息的关系从被动的接收，变成了主动对周边空间的发现与探索，因此更富于情感与想象，故事也将由此产生。</p>
<p>让AR科技不只是“锦上添花”</p>
<p>2020年的今天，AR虽然曾被描述为前景无限的黑科技，但在C端用户的参与上，大多只活跃于景区的导览，其中更以发放AR礼品卷作为促进C端用户参与的主要推广手段。就像早前发布的《增强现实C端应用白皮书》中所提及的：“在现阶段，AR对于C端消费者来说“并不是刚需，仅作为‘锦上添花’的存在”。但AR的魅力仅止于此么？不尽然！</p>
<p>物布团队通过对生活特有的敏感与把握，让AR与LBS相结合，把AR的特质发挥得淋漓尽致。让用户在智能手机上可以完整领略到AR科技带来的突破性体验，让绿色的AR落地C端的同时，更让使用者惊呼“未来就是这个样子吧”。</p>
<p>“物布空间”从C端社交场景出发，挖掘AR与“沟通”这一人与人之间基本需求的结合，更易获得C端的天然接受。同时，“物布空间”赋予C端信息接收者+内容生产者的角色，让AR应用真正能为C端所用。</p>
<p>5G时代已乘风破浪而来，处于成长阶段的AR科技依旧需要同业企业的携手加持，众人拾柴火焰才能高。对于此，无论“物布空间”的创作团队，还是初来乍到的新势界科技，都抱着谦卑的心态，希望与AR行业的企业们共同探讨增强现实的现在与未来，把每一个小我融汇为推动AR技术的大我，让科技更好地服务于C端，让AR不再只是“锦上添花”！</p>
➜高通与Ultraleap合作，为XR2参考设计打通手势识别功能
http://www.sohu.com/a/415136202_395737	16551
<p>8月27日消息，高通与Ultraleap宣布达成多年合作，计划将Ultraleap的手势识别技术与基于高通骁龙XR2的AR/VR头显结合。Ultraleaps号称将提供快速、准确且稳定的手势识别技术。</p>
<p class="ql-align-center"><img src="http://p7.itc.cn/images01/20200827/686d1fcece934bc5abf80f210e2de858.jpeg" max-width="600" /></p>
<p>据青亭网了解，Ultraleap由Ultrahptics和Leap Motion两家手势识别相关技术公司组成，Ultrahaptics收购Leap Motion后，将二者业务整合，并更名为新的品牌Ultraleap。此前，Leap Motion曾推出便携式手势追踪模块，适用于PC、AR/VR等设备。</p>
<p>而高通在去年底推出的XR2则是一款具备接入5G网络能力的AR/VR专用芯片，适用于AR/VR一体机头显。在结合Ultraleap的手势追踪功能后，未来可能会看到更多一体机支持像Quest或是HoloLens那样的手势识别功能，降低这项技术的门槛。</p>
<p>细节方面，高通将为XR2加入对Ultraleap手势识别技术的原生优化，AR/VR头显厂商如果在头显中加入Ultraleap手势识别软件/模块，则无需额外的优化。同时，这也意味着Ultraleap的手势识别软件技术将授权给基于XR2的AR/VR头显使用。</p>
<p>考虑到Oculus Quest一体机加入手势识别后带来的更多样化玩法，无需手柄的操作为用户带来很大方便，未来AR/VR与手势识别结合有望成为一种趋势，而Ultraleap也有望通过这次与高通合作，将技术应用在更多设备上。</p>
➜优于NeRF方案，Intel Labs发布高清3D图片合成新研究
http://www.sohu.com/a/415136543_395737	16862
<p>8月27日消息，Intel Labs科研人员发表了一项3D场景重建相关研究，研究中指出了一种通过视角合成，将2D原生照片（无标记或描述）转化为支持多视角查看的3D图的方案：Free View Synthesis。</p>
<p class="ql-align-center"><img src="http://p5.itc.cn/images01/20200827/24b965d54a92478f9e5f4bef0495b870.png" max-width="600" /></p>
<p>据青亭网了解，Free View Synthesis方案结合传统算法和神经网络，其特点是可生成彩色的3D图，效果比NeRF方案，或是三星近期发布的NPBG渲染方案更好，合成画质更清晰。</p>
<p>在论文中，科研人员阐述了Free View Synthesis方案的具体流程：</p>
<ul>
<li>1）利用开源COLMAP（Structure from Motion）算法来确定源图片的摄像头位置，并生成场景的基础点云数据；</li>
<li>2）COLMAP在每张源图片中运行多视角立体算法（MVS），生成基于点云数据的基础建模；</li>
<li>3）根据狄洛尼三角剖分原理，生成临时的几何网格；</li>
<li>4）利用共享的卷曲神经网络将源图片的关键特征进行编码；</li>
<li>5）通过临时几何网格中生成深度图，并利用深度图将关键特征分布在目标视角上；</li>
<li>6）利用循环神经网络，将特征融合在单一的帧画面中。</li>
</ul>
<p>目前，运行这些步骤需要大量时间，因此Free View Synthesis方案还无法达到实时生成速度。</p>
<p>未来，当这种技术得到继续优化，将有望进一步降低实时3D照片渲染的门槛，更广泛应用于社交、新闻报道、展览展示等多种场景。</p>
➜受游戏启发，美军CCDC推出一套AR/VR数据分析流程系统
http://www.sohu.com/a/415136777_395737	17109
<p>8月27日消息，美国陆军战斗能力发展司令部（CCDC）军队研究实验室的科研人员研发了一套将AR/VR用于日常工作的流程，为科学家和工程师降低AR/VR技术的使用门槛。</p>
<p class="ql-align-center"><img src="http://p1.itc.cn/images01/20200827/bd9814b646114d20913a87b94d364920.jpeg" max-width="600" /></p>
<p>据青亭网了解，军队研究室将AR/VR技术用于帮助科研人员分析大量数据，或是工程场景。该实验室的国防部超级计算资源中心的一名计算机科学家Simon Su博士表示：随着3D游戏技术发展，AR/VR技术也在不断得到提升，不仅硬件成本降低，分辨率等体验也越来越优秀，大大降低AR/VR门槛。于是为了帮助军队科研人员快速熟悉AR/VR，实验室研发了这个相关工作流程。</p>
<p>简单来讲，科研人员无需考虑使用哪种AR/VR软件，直接就能利用AR/VR可视化系统来分析数据，像使用一台电脑一样简单，不用提前培训。这将有望帮助到70%的科研人员。</p>
<p>Su和科研人员还开发了多款AR/VR应用来提升市面上多种技术的可用性，比如：为ParaView开源可视化软件加入对AR/VR学习平台zSpace和HTC Vive的兼容优化，让科员人员能够在zSpace上以3D形式预览2D数据。</p>
<p>另外，还开发了一款基于HoloLens的3D AR可视化和多人协作应用。科研人员可在虚拟环境中进一步分析3D可视化的数据、集合结构等信息。</p>
➜谷歌Pixel 4a手机将不兼容AR滤镜应用Playground
http://www.sohu.com/a/415138122_395737	17442
<p>8月27日据外媒报道，谷歌证实从新款手机Pixel 4a开始将不再兼容AR贴图/滤镜应用，而且尽管此前的Pixel版本支持这款应用，但应用中的IP授权Playmoji角色（类似于苹果的Animoji）似乎全部下架，只剩下谷歌自带的3D贴图滤镜。</p>
<p class="ql-align-center"><img src="http://p3.itc.cn/images01/20200827/3c8549d5cbc84c418f2574a57428d849.png" max-width="600" /></p>
<p>据青亭网了解，Playground是一个基于ARCore的应用，其前身为AR Stickers。它的特点是在你拍照的时候可以添加动态的3D AR滤镜，主要以卡通角色为主，部分AR角色支持AI互动。此前，Playground曾上架基于漫威、游侠索罗、星球大战、怪奇物语等IP的多种动态AR滤镜。</p>
<p>从Pixel 4a机型开始，当你打开Google Camera功能时，不会再找到Playground的AR滤镜。但这并不意味着谷歌放弃AR技术，谷歌表示：将继续在Pixel 4a等ARCore设备中更新ARCore技术，面向更多用户开发AR内容。</p>
<p>也就是说，谷歌可能未来不在自家手机中提供专门的AR滤镜，但会继续将AR用在其他场景，比如：AR导航、与搜索引擎结合的AR模型预览等。随着Snapchat、Instagram、Tik Tok等社交应用的AR功能越来越受欢迎，更多人可能会优先选择这些热门应用，而不是手机自带的AR滤镜功能，这可能是谷歌放弃Playground的原因之一。</p>
<p>此外，考虑到Pixel 4a定位中端手机，采用骁龙730G CPU，性能和旗舰机有一定差距，这可能是因此才不支持Playground AR功能。</p>
➜Facebook面部追踪系统：一套眼球＋语音＋AI的轻量化方案
http://www.sohu.com/a/415186414_395737	33274
<p>此前我们多次报道Facebook Codec Avatars虚拟化身和面部追踪的研究，该研究中Facebook采用了一系列复杂面部追踪技术，从而在VR中呈现出一个惟妙惟肖的虚拟化身，无论是眼神动作、面部表情，还是肢体动作，都足够自然和逼真。</p>
<p>不过，最开始版本（2018年开始研究）需要132个相机去进行专业化的捕捉，显然这是一个方案的定型，通过现有技术方案实现一个高的标准。当然，这样的一套设备对于落实到最终产品中也会降低用户体验。</p>
<p class="ql-align-center"><img src="http://p8.itc.cn/images01/20200827/2d20e8dcc0c34afeb301c8b0aaac7e6c.jpeg" max-width="600" /></p>
<p>去年，Facebook就公布了三摄新方案，通过内置两个摄像头和一个鼻梁下方捕捉嘴部的摄像头，看上去已经很完美。</p>
<p>熟悉Facebook或FRL的朋友可能知道，Facebook近两年在人工智能算法上的投入大幅增加，而算法的加入就是为了解决硬件和算力不足等等问题。</p>
<p class="ql-align-center"><img src="http://p4.itc.cn/images01/20200827/dbb1f09791404c2d9df80e77a64d0689.jpeg" max-width="600" /></p>
<p class="ql-align-center"><img src="http://p6.itc.cn/images01/20200827/b5fcc1d2bef44050b9ddb849fdb33510.jpeg" max-width="600" /></p>            <div class="lookall-box">
<div class="lookall-shadow"></div>
<section class="lookall">
<a href="javascript:;" class="show-all" id="showMore">
<em>展开全文</em>
</a>
</section>
</div>
<div class="hidden-content control-hide">
<p>近期，Facebook公布了新一版Codec Avatars的研究，其基于AI技术，用更轻量化的方案去达到类似高标准的效果。其中，光学捕捉方面几乎双眼的眼球追踪，而嘴部动作则基于麦克风拾取的人声，也就是双摄＋麦克风＋AI技术。</p>
<p>眼球追踪用途不用说，它可以准确识别眼球动作从而模拟更真实的眼神和注视效果，而通过麦克风识别你的说话语音来模拟嘴部和面部动作，可能你会质疑它的效果。</p>
<p class="ql-align-center"><img src="http://p7.itc.cn/images01/20200827/143b8cce9a4548cb8ce6c1dda83f2100.gif" max-width="600" /></p>
<p>上面就是最终效果。研究人员表示，通过音频数据可以还原微妙的面部动作，例如舔嘴唇等动作都可以模拟。不过值得注意的是，这需要具备高品质的麦克风。</p>
<p>相关阅读：《一个眼神都不放过，FRL公布自然表情系统MCA》</p>
<p>参考：fb</p>