➜数说新冠疫情丨全球日增逾68万例，近16天激增1000万例
https://www.gelonghui.com/p/432920	4669
<p>来源：半导体行业观察</p><p><span>对于GPU爱好者来说，这是一个漫长的等待。&nbsp;英伟达将Turing产品线维持了两年，然后在2020年9月用Ampere取代了它。AMD更友善一点，他们的新设计间隔了15个月，但大多数人对此并不感兴趣。</span></p><p><span>他们希望看到的是AMD推出一款高端机型，与英伟达(Nvidia)最优秀的产品展开正面竞争。他们做到了，现在我们已经看到了结果，在花钱买最好的图形卡时，PC游戏玩家现在（在理论上）有了很多选择。</span></p><p><span>但是驱动它们的芯片呢?其中一个从根本上来说比另一个好吗?继续读下去，看看Ampere和RDNA 2是如何决一死战的!</span></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p><span><strong><br></strong></span></p><h3 style="text-align: center;"><span><font color="#3daad6">Nvidia衰退，AMD成长</font></span></h3><p><span><strong><br></strong></span></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p><span><strong><span>节点和die尺寸</span></strong></span></p><p><span>多年来，高端GPU一直比 CPU大得多，而且它们的尺寸一直在稳步增长。AMD最新推出的Navi芯片面积约为520mm2，是之前Navi芯片的两倍多。不过，这并不是他们最大的——这项荣誉颁给了他们的Instinct MI100加速器（约750 mm2）中的GPU。</span></p><p><span>上一次AMD制造的接近Navi 21大小的游戏处理器是为Radeon R9 Fury和Nano显卡设计的，这两款产品在Fiji 芯片上采用了GCN 3.0架构。它的裸片面积为596 mm2，但它是在台积电的28HP工艺节点上生产的。</span></p><p><span>自2018年以来，AMD一直在使用台积电更小的N7工艺，该生产线生产的最大芯片是Vega 20 (Radeon VII)，面积为331mm2。他们所有的Navi gpu都是在略微升级的N7P处理器上制作的，所以可以比较这些产品。</span></p><p><img src="https://img3.gelonghui.com/850c0-95df7ecf-f030-4038-99b9-be6c0148fa6b.png"></p><p><span><em><span>Radeon R9 Nano：微型卡，大型GPU</span></em></span></p><p><span>但说到纯粹的die尺寸，英伟达拿下了王冠，并不是说这一定是件好事。最新的基于Ampere的芯片，GA102，是628mm2。这实际上比它的前身TU102小了17%——GPU面积达到惊人的754mm2。</span></p><p><span>与Nvidia巨大的GA100芯片(用于AI和数据中心)相比，这两款芯片的尺寸都相形见绌，其GPU为826 mm2，采用的是台积电的N7芯片。虽然它从来没有被设计用来驱动桌面显卡，但它确实显示了GPU制造的可能规模。</span></p><p><span>把它们放在一起突出了Nvidia最大的GPU有多大。Navi 21看起来相当苗条，尽管处理器的功能不仅仅是芯片区。GA102封装了283亿个晶体管，而AMD的新芯片减少了5%，达到268亿个。</span></p><p><img src="https://img3.gelonghui.com/a72d1-fd7243c0-e635-4b37-b741-edee942d1d90.png"></p><p><span>我们不知道每个GPU构建多少层，因此我们所能比较的是晶体管与die面积的比率，通常称为die密度。Navi 21的晶体管约为每平方毫米5150万个晶体管，但GA102明显低于41.1，这可能是Nvidia的芯片堆叠程度比AMD的略高，但它更可能表示工艺节点。</span></p><p><span>如前所述，Navi 21是由台积电生产的，采用N7P生产方法，性能比N7略有提高;但在新产品GA102上，英伟达求助于三星来完成生产任务。这家韩国半导体巨头正在使用他们所谓的8nm节点(标记为8N或8NN)的改良版本，专门为Nvidia设计。</span></p><p><span><b>这些节点值，7和8，与芯片组件的实际尺寸没有多大关系:它们只是市场营销术语，用于区分不同的生产技术。也就是说，即使GA102比Navi 21有更多的层，die尺寸确实有一个特殊的影响。</b></span></p><p><img src="https://img3.gelonghui.com/1bfb4-7103e169-1363-4aa4-a803-3a1bd2ec6f5a.png"></p><p><span>一台300毫米(12英寸)的晶圆片正在台积电的制造工厂进行测试。</span></p><p><span>微处理器和其他芯片是由高度精炼的硅和其他材料制成的大圆盘，称为晶圆。台积电和三星为AMD和Nvidia使用的是300毫米晶圆，相对于更大的die，使用更小的die，每块晶圆将产生更多的芯片。</span></p><p><span>这种差异不可能很大，但是在降低制造成本方面，当每片晶圆的生产成本达到数千美元时，AMD相对于Nvidia而言优势较小。&nbsp;当然，这是假设三星或台积电没有与AMD / Nvidia进行某种财务交易。</span></p><p><b>如果芯片本身不能很好地完成设计工作，那么所有这些die尺寸和晶体管数量都将是徒劳的。</b>&nbsp;因此，让我们深入研究每个新GPU的布局，看看它们背后的东西。</p><p><span><br></span></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><h3 style="text-align: center;"><strong style="font-style: inherit;"><font color="#3daad6">剖析die</font></strong></h3><p><strong style="font-style: inherit;"><br></strong></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p><span><strong><span>Ampere GA102和RDNA 2 Navi 21的总体架构</span></strong></span></p><p><span>我们从分析Ampere GA102和RDNA 2 Navi 21 GPU的总体架构开始我们对架构的探索——这些图表不一定向我们展示所有的物理布局，但它们给出了处理器有多少组件的明确指示。</span></p><p><span>在这两种情况下，布局都是非常熟悉的，因为它们基本上都是其前身的扩展版本。在处理指令中添加更多的单元将始终提高GPU的性能，因为在最新的3D大片中，在高分辨率下，渲染工作量涉及大量的并行计算。</span></p><p><img src="https://img3.gelonghui.com/19085-6c9aaf34-9fae-4014-bed3-05fe18a8c0c1.png"></p><p><span>这样的图表是有用的，但是对于这个特定的分析来说，更有趣的是看看各个组件在GPU中的位置。在设计大型处理器时，您通常希望共享资源（如控制器和缓存）位于中心位置，以确保每个组件都具有相同的路径。</span></p><p><span>接口系统，如本地内存控制器或视频输出，应该安装在芯片的边缘，以便更容易地将它们连接到连接GPU和显卡其余部分的数千根单独的电线上。</span></p><p><span>以下是AMD的Navi 21和Nvidia的GA102 die的伪彩色图像。&nbsp;它们实际上只显示了芯片中的一层；但它们确实给我们提供了一个现代GPU内部的极好视图。</span></p><p><img src="https://img3.gelonghui.com/54731-7fbf931a-e0d4-4ad0-8450-4904ecfd2a64.png"></p><p><span>两种设计之间最明显的区别在于，Nvidia在芯片布局上没有遵循集中化的方法——所有的系统控制器和主缓存都在底部，逻辑单元以长列形式运行。他们过去也这样做过，但只针对中低端机型。</span></p><p><span>例如，Pascal GP106（用于GeForce GTX 1060等）实际上是GP104（来自GeForce GTX 1070）的一半。&nbsp;后者是较大的芯片，其缓存和控制器位于中间。&nbsp;这些都移到了它的兄弟姐妹那一边，但这只是因为设计已经被拆分了。</span></p><p><img src="https://img3.gelonghui.com/4a08b-fb5b25c2-5b3e-4c85-aa6a-a5fc8b6cac0d.png"></p><p><span><em><span>Pascal GP104和GP106 资料来源：Fritzchens Fritz</span></em></span></p><p><span>对于之前所有的高端GPU布局，Nvidia都使用了经典的集中式结构。为什么这里会有变化呢?这不可能是由于接口的原因，因为内存控制器和PCI Express系统都运行在die的边缘。</span></p><p><span>这也不是出于热学原因，因为即使die 的缓存/控制器部分比逻辑部分的温度更高，您仍然希望在其中间具有更多的硅以帮助吸收和散发热量 。尽管我们不能完全确定更改的原因，但我们怀疑这与Nvidia对芯片中ROP（渲染输出）单元实施的更改有关。</span></p><p><span>我们将在后面更详细地讨论它们，但是现在让我们说，虽然布局的改变看起来很奇怪，但它不会对性能产生显着的影响。这是因为3D渲染充斥着许多长时间的延迟，通常是由于必须等待数据。因此，由于一些逻辑单元比其他逻辑单元离缓存更远而增加的纳秒数，都被隐藏在了整个系统中。</span></p><p><span>在我们继续之前，值得注意的是AMD在Navi 21布局中实施的工程改变，与驱动类似Radeon rx5700 XT的Navi 10相比。尽管新芯片在面积和晶体管数量上都比之前的芯片大了一倍，但设计者还设法在不显着增加功耗的情况下提高了时钟速度。</span></p><p><span>例如，Radeon RX 6800 XT运动的基时钟和升压时钟分别为1825和2250mhz, TDP为300 W;Radeon RX 5700 XT的相同性能为1605 MHz、1905 MHz和225 W。英伟达也通过Ampere提高了时钟速度，但部分原因是使用了更小、更高效的进程节点。</span></p><p><img src="https://img3.gelonghui.com/3798b-a08968e4-a066-4e43-ac63-dfeefe374fa4.png"></p><p><span>我们对Ampere和RDNA 2显卡的每瓦特性能检查显示，两家供应商在这方面都取得了显着的改进，但AMD和台积电取得了一些相当显着的成就——比较上图中Radeon RX 6800和Radeon VII之间的差异。</span></p><p><span>后者是他们首次使用N7节点进行GPU合作，并且在不到两年的时间内，他们将每瓦性能提高了64％。的确，如果英伟达继续与台积电合作，那Ampere GA102的性能会好得多。</span></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p><span><strong><br></strong></span></p><h3 style="text-align: center;"><span><strong><font color="#3daad6">管理GPU工厂</font></strong></span></h3><p><span><strong><br></strong></span></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p><strong><span>芯片内部的一切组织方式</span></strong></p><p><span>当涉及到指令处理和数据传输管理时，Ampere和RDNA2都遵循类似的模式来组织芯片内部的一切。游戏开发人员使用图形API编写标题，以制作所有图像；它可能是Direct3D、OpenGL或Vulkan。这些基本上是软件库，充满了规则、结构和简化指令的“书籍”。</span></p><p><span>AMD和Nvidia为他们的芯片创建的驱动程序本质上起着翻译的作用:将通过API发布的例程转换为GPU能够理解的操作序列。在那之后，就完全由硬件来管理了，比如什么指令首先执行，芯片的哪个部分执行这些指令，等等。</span></p><p><span>指令管理的初始阶段由合理地集中在芯片中的一组单元处理。在RDNA 2中，图形和计算着色器通过单独的管线进行路由，这些管线将指令调度并分派到芯片的其余部分。前者称为图形命令处理器，后者是异步计算引擎（ACE）。</span></p><p><img src="https://img3.gelonghui.com/2e931-4baf716c-d40f-4e08-8551-e55d57105238.png"></p><p><span>Nvidia只是用一个名字来描述他们的一组管理单元，即GigaThread Engine，在Ampere中它执行与RDNA 2相同的任务，尽管Nvidia并未过多说明其实际管理方式。总之，这些命令处理器的功能类似于工厂的生产经理。</span></p><p><span>GPU通过并行执行所有操作来获得性能，因此在整个芯片上复制了下一个组织层次。坚持工厂的类比，这类似于一家拥有中央办公室但在多个地点生产商品的企业。</span></p><p><span>AMD使用标签着色器引擎（SE），而Nvidia则称其为图形处理集群（GPC）-不同的名称，相同的角色。</span></p><p><img src="https://img3.gelonghui.com/df23b-53de0375-51a5-4bfb-81b2-1115fc9bcbb2.png"></p><p><span>对芯片进行这种分区的原因很简单：命令处理单元不能处理所有事情，因为它最终会变得过于庞大和复杂。因此，将一些日程安排和组织职责进一步向下推进是有意义的。这也意味着每个分离分区可以完全独立于其他分区执行某些操作，因此一个分区可以处理大量的图形着色器，而其他分区则在处理长而复杂的计算着色器。</span></p><p><span>在RDNA 2的例子中，每个SE都有自己一套固定的功能单元:被设计用来完成一项特定任务的电路，程序员通常无法对其进行大量调整。</span></p><ul><li><blockquote><b><span>mitive Setup unit——获取顶点，准备好进行处理，同时生成更多的顶点(essellation)并将其剔除<br></span><span>Rasterizer——将三角形的3D世界转换为像素的2D网格<br></span><span>Render Outputs(ROPs)——读取、写入和混合像素</span></b></blockquote></li></ul><p><span>原始的设置单元以每个时钟周期1个三角形的速率运行。这听起来可能不是很多，但是不要忘记这些芯片运行在1.8到2.2 GHz之间，所以原始的设置不应该成为GPU的瓶颈。对Ampere来说，原始单位是在组织的下一层找到的，我们很快就会讲到。</span></p><p><span>AMD和Nvidia都没有过多提及他们的光栅化器。后者称为光栅引擎，我们知道它们每个时钟周期处理一个三角形，并输出若干像素，但没有进一步的信息，例如它们的亚像素精度。</span></p><p><span>Navi 21芯片中的每个SE都有4组8个ROP，总共产生128个渲染输出单元；Nvidia的GA102每GPC包含2组8个ROP，因此整个芯片可运动112个ROP。这看起来AMD在这方面有优势，因为更多的ROP意味着每个时钟可以处理更多的像素。但是这样的单元需要对缓存和本地内存的良好访问，我们将在本文后面详细介绍。现在，让我们继续研究SE/GPC分区是如何进一步划分的。</span></p><p><img src="https://img3.gelonghui.com/7d2d9-be608209-e50f-413a-a778-e1cb47273c33.png"></p><p><span>AMD的着色引擎被划分为双计算单元（DCU），Navi 21芯片本身就有10个DCU——请注意，在一些文档中，它们也被归类为工作组处理器（WGP）。在Ampere和GA102的例子中，它们被称为纹理处理簇（TPC），每个GPU包含6个tpc。Nvidia设计的每一个集群都有一个叫做“变形引擎”的东西——本质上是Ampere的原始设置单元。</span></p><p><span>Nvidia也以每时钟1个三角形的速度运行，尽管Nvidia的GPU比AMD的低，但他们的TPC数量比Navi 21的SE要多得多。因此，对于相同的时钟速度，GA102应该有一个显着的优势，因为完整的芯片拥有42个原始设置单元，而AMD的新RDNA 2只有4个。但由于每个光栅引擎有6个TPC, GA102实际上有7个完整的原始系统，而Navi 21有4个。由于后者的时钟并没有比前者高75%，当涉及到几何处理(尽管没有游戏可能在这方面受到限制)时，似乎英伟达在这方面具有明显的领先优势。</span></p><p><span>芯片组织的最后一层是RDNA 2中的计算单元（CU）和Ampere中的流式多处理器（SM），这是我们GPU工厂的生产线。</span></p><p><img src="https://img3.gelonghui.com/ba7a6-153883d4-56af-4081-82c3-47d950e11b49.png"></p><p><span>这些是图形处理器馅饼中的肉和蔬菜，因为它们拥有所有用于处理图形、计算和现在的光线追踪着色器的高度可编程单元。正如你在上图中看到的，每一个芯片都只占整个芯片空间的很小一部分，但是它们仍然是非常复杂的，并且对芯片的整体性能非常重要。</span></p><p><span>到目前为止，在两个GPU的布局和组织方式方面，还没有什么真正的突破性协议。术语全都不同，但是它们的功能却大同小异。而且由于它们所做的很多事情都受可编程性和灵活性的限制，因此一个相对于另一个所具有的任何优势，都只能归结为规模感，即哪个拥有最大的特色。</span></p><p><span>但是对于CU和SM，AMD和Nvidia采取了不同的方式来处理着色器。在某些领域，它们有很多共同点，但在其他许多领域则并非如此。</span></p><p><span><br></span></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><h3 style="text-align: center;"><font color="#3daad6">计数核心是Nvidia的方式</font></h3><p><strong><br></strong></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p><span>由于安培（Ampere）在RDNA 2之前就冒险进入野外，我们首先来看看Nvidia的SM。现在没有必要查看裸片本身的图像，因为它们无法准确告诉我们其中的内容，因此让我们使用组织图。这些不应该代表芯片中各种组件的物理排列方式，而只是每种类型中存在多少种。</span></p><p><span>图灵对其台式机前身Pascal进行了实质性更改（去掉了一堆FP64单元和寄存器，但是增加了张量核和光线跟踪），而Ampere实际上是一个相当温和的更新-至少从表面上看。不过，就Nvidia的市场部门而言，新设计使每个SM中CUDA内核的数量增加了一倍以上。</span></p><p><img src="https://img3.gelonghui.com/48a83-110d07a1-20fb-4a9f-ad83-87b15f503ac8.png"></p><p><span>在图灵中，流多处理器包含四个分区（有时称为处理块），每个分区中容纳16个INT32和16x FP32逻辑单元。这些电路旨在对32位数据值执行非常具体的数学运算：INT单位处理整数，而FP单位处理浮点数（即十进制）。</span></p><p><span>英伟达表示，一个Ampere SM总共有128个CUDA内核，但严格来说，这是不正确的-或者，如果我们必须坚持这一点，那么图灵（Turing）也是如此。该芯片中的INT32单元实际上可以处理浮点值，但只能以非常少量的简单操作进行。对于Ampere，Nvidia已开放了它们支持的浮点数学运算范围，以匹配其他FP32单元。这意味着每个SM的CUDA内核总数并没有真正改变。只是其中的一半现在拥有更多功能。</span></p><p><span>每个SM分区中的所有内核都可以随时处理同一条指令，但是由于INT / FP单元可以独立运行，因此Ampere SM每个周期最多可以处理128x FP32计算，或一起处理64x FP32和64x INT32操作。而图灵只是后者。</span></p><p><span>因此，新的GPU可能使FP32的输出量比其上一代产品大一倍。对于计算工作负载，尤其是在专业应用程序中，这是向前迈出的一大步。但是对于游戏而言，优势却远远没有达到预期。当我们首次测试GeForce RTX 3080时，这一点很明显，它使用启用了68个SM的GA102芯片。</span></p><p><img src="https://img3.gelonghui.com/dc3d0-87f8a734-399c-499d-a2c3-d65175568cb3.png"></p><p><span>尽管FP32的峰值吞吐量比GeForce 2080 Ti高出121％，但平均帧速率仅提高了31％。那么，为什么所有这些计算能力都会浪费掉呢？一个简单的答案是，游戏并非一直在运行FP32指令。</span></p><p><span>当Nvidia在2018年发布Turing时，他们指出， GPU处理的指令平均约有36％涉及INT32例程。这些计算通常用于计算内存地址，两个值之间的比较以及逻辑流/控制。</span></p><p><img src="https://img3.gelonghui.com/bd691-4807231e-7a45-4da1-8637-e4b1e44765b8.png"></p><p><span>因此，对于这些操作，双速率FP32功能不起作用，因为具有两个数据路径的单元只能执行整数或浮点运算。而且，只有在当时由它处理的所有32个线程都排队处理相同的FP32操作时，SM分区才会切换到此模式。在所有其他情况下，安培中的分区与图灵中的分区一样运行。</span></p><p><span>这意味着在INT + FP模式下运行时，GeForce RTX 3080之类的FP32仅比2080 Ti具有11％的FP32优势。这就是为什么在游戏中看到的实际性能提升没有原始数据所预期的那么高的原因。</span></p><p><span>至于其他改进。每个SM分区的Tensor Core更少，但每个都比Turing中的功能强大得多。这些电路执行非常具体的计算（例如将两个FP16值相乘并用另一个FP16编号累加答案），每个内核现在每个周期执行32次这些操作。</span></p><p><img src="https://img3.gelonghui.com/c1132-2fa87f55-2db2-458f-9533-c215c16f6265.png"></p><p><span>它们还支持一种名为“细粒度结构稀疏性”的新特性，在不涉及所有细节的情况下，这意味着通过剔除那些对答案没有影响的数据，计算率可以翻倍。同样，这对于从事神经网络和人工智能工作的专业人员来说是个好消息，但目前对游戏开发者来说并没有什么明显的好处。</span></p><p><span>光线跟踪核心也已进行了调整：它们现在可以独立于CUDA核心工作，因此，在进行BVH遍历或光线原始相交数学时，SM的其余部分仍可以处理着色器。处理射线是否与原语相交测试的RT核心的部分性能也增加了一倍。</span></p><p><img src="https://img3.gelonghui.com/782a4-a67f5d50-830a-42d3-b1a3-14434a4fe59c.png"></p><p><span>RT内核还具有附加的硬件，可帮助将光线跟踪应用于运动模煳，但是此功能目前仅通过Nvidia专有的Optix API公开。</span></p><p><span>还有其他一些调整，但是整体方法是明智但稳定的演进之一，而不是主要的新设计。但是考虑到图灵的原始功能并没有什么特别的错误，因此看到这一点不足为奇。</span></p><p><span><b>那么AMD怎么办-他们对RDNA 2中的计算单元做了什么？</b></span></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p><strong><br></strong></p><h3 style="text-align: center;"><strong><font color="#3daad6">追寻美妙的光线</font></strong></h3><p><strong><br></strong></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p><span>从表面上看，AMD在计算单元方面并没有太大变化-它们仍然包含两组SIMD32向量单元，一个SISD标量单元，纹理单元以及各种缓存堆栈。关于它们可以执行的数据类型和相关的数学运算，已经发生了一些变化，我们稍后将详细介绍。对于普通消费者而言，最明显的变化是AMD现在为光线跟踪中的特定例程提供了硬件加速。</span></p><p><span>CU的这部分执行ray-box或ray-triangle交叉检查——与安培中的RT内核相同。然而，后者也加速了BVH遍历算法，而在RDNA 2，这是通过使用SIMD 32单元计算着色器来完成的。</span></p><p><img src="https://img3.gelonghui.com/3f402-baa67319-1c7b-4c27-af21-5f9611f9d2ec.png"></p><p><span>不管一个着色器内核有多少个，或者它们的时钟速率有多高，使用设计为仅完成一项工作的定制电路总是比通用方法更好。这就是为什么首先发明GPU的原因：渲染世界中的所有事物都可以使用CPU来完成，但是它们的通用性使其不适合于此。</span></p><p><span>RA单元紧邻纹理处理器，因为它们实际上是同一结构的一部分。早在2019年7月，我们就报道了AMD申请的一项专利的内容，该专利使用``混合''方法详细处理了光线追踪中的关键算法...</span></p><p><img src="https://img3.gelonghui.com/0ec1e-00ae6432-4b3a-4948-a735-3ddfcf345614.png"></p><p><span>尽管该系统确实提供了更大的灵活性，并且消除了当存在光线追踪工作量时裸片的一部分不做任何事情的需求，但AMD的第一个实现确实有一些缺点。最值得注意的是，纹理处理器在任何时候都只能处理涉及纹理或ray-primitive交点的操作。</span></p><p><span>鉴于Nvidia的RT核心现在完全独立于SM的其余部分而运行，与RNDA 2相比，在通过光线跟踪所需的加速结构和交叉测试进行磨削时，这似乎给Ampere带来了明显的领先优势。</span></p><p><span>尽管我们仅简要检查了AMD最新图形卡中的光线追踪性能，但到目前为止，我们确实发现使用光线追踪的影响很大程度上取决于所玩的游戏。</span></p><p><img src="https://img3.gelonghui.com/f3386-7adac69b-184a-45aa-8e05-9f620cb1bb04.png"></p><p><span>例如，在Gears 5中，Radeon RX 6800（使用Navi 21 GPU的60 CU变体）仅降低了17％的帧速率，而在《古墓丽影》的阴影中，平均损失达到52％ 。相比之下，英伟达的RTX 3080（使用68 SM GA102）在这两款游戏中的平均帧率损失分别为23％和40％。</span></p><p><span>需要对射线追踪进行更详细的分析来说明AMD的实现，但是作为该技术的第一个迭代，它看起来很有竞争力，但对应用程序正在进行的射线追踪很敏感。</span></p><p><span>如前所述，RDNA 2中的计算单元现在支持更多数据类型。最值得注意的是低精度数据类型，例如INT4和INT8。它们用于机器学习算法中的张量运算，而AMD具有用于AI和数据中心的单独架构（CDNA），但此更新适用于DirectML。</span></p><p><img src="https://img3.gelonghui.com/6c8a4-e04b3500-77e7-45f0-a583-180daca35447.png"></p><p><span>该API是Microsoft DirectX 12家族的最新成员，硬件和软件的组合将为光线跟踪和时间放大算法中的降噪提供更好的加速。对于后者，Nvidia当然拥有自己的名称，称为DLSS。他们的系统使用SM中的Tensor核心执行部分计算，但是鉴于可以通过DirectML构建类似的过程，因此这些单元似乎有些多余。但是，在Turing和Ampere中，Tensor核心还可以处理所有涉及FP16数据格式的数学运算。</span></p><p><span>对于RDNA 2，此类计算是使用着色器单元，使用打包数据格式完成的，即每个32位向量寄存器都包含两个16位寄存器。那么哪种方法更好呢？AMD将其SIMD32单元标记为矢量处理器，因为它们能针对多个数据值发出一条指令。</span></p><p><span>每个向量单元包含32个流处理器，由于每个流处理器只处理单个数据片段，因此实际操作本身是标量的。这本质上与安培中的SM分区相同，其中每个处理块还针对32个数据值携带一条指令。</span></p><p><span>但是，在Nvidia设计中的整个SM每个周期最多可以处理128个FP32 FMA计算（融合乘加）时，单个RDNA 2计算单元只能处理64个。在执行标准FP16数学时，使用FP16可以将其提高到每个周期128 FMA，这与Ampere的Tensor核心是一样的。</span></p><p><span>Nvidia的SM可以处理指令时可以同时处理整数和浮点值（例如64 FP32和64 INT32），并且具有用于FP16操作，张量数学和光线跟踪例程的独立单元。尽管AMD CU具有独立的支持简单整数数学的标量单元，但它们在SIMD32单元上承担了大部分工作量。</span></p><p><span>因此，安培似乎在这方面有优势:GA102比Navi 21拥有更多的CU，而且在峰值吞吐量、灵活性和提供的功能方面，它们的表现更出色。但是AMD有一个相当不错的锦囊妙计。</span></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p><strong>内存系统，多层缓存</strong></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p><span>拥有成千上万个逻辑单元的GPU，在复杂的数学运算中一路高歌勐进，这一切都很好，但是但如果他们不能足够快地提供所需的指令和数据，他们将在海量的数据中挣扎。这两种设计都拥有丰富的多级缓存，拥有巨大的带宽。</span></p><p><span>让我们来看看安培的。总体而言，内部发生了一些显着变化。2级缓存的数量增加了50％（图灵TU102的运动速度分别为4096 kB），并且每个SM中的1级缓存的大小都增加了一倍。</span></p><p><img src="https://img3.gelonghui.com/12b87-bdcf2fce-728d-4b38-9eda-58ef107ff081.png"></p><p><span>与以前一样，就可以为数据，纹理或一般计算用途分配多少缓存空间而言，Ampere的L1缓存是可配置的。但是，对于图形着色器（例如顶点，像素）和异步计算，缓存实际上设置为：</span></p><ul><li><p><span>64 kB用于数据和纹理</span></p></li><li><p><span>48 kB用于共享通用内存</span></p></li><li><p><span>16 kB保留用于特定操作</span></p></li></ul><p><span>只有在完全计算模式下运行时，L1才可以完全配置。从好的方面来说，可用带宽的数量也增加了一倍，因为缓存现在可以每个时钟读取/写入128个字节（尽管没有关于延迟是否得到改善的消息）。</span></p><p><span>内部存储器系统的其余部分在Ampere中保持不变，但是当我们仅移至GPU外部时，对于我们来说，这是一个很好的惊喜。Nvidia与DRAM制造商美光合作，将GDDR6的修改版本用于其本地内存需求。从本质上讲，它仍然是GDDR6，但数据总线已被完全替换。GDDR6X使用四个电压，而不是使用传统的每个引脚设置1位（信号只是在两个电压（又名PAM）之间快速反弹）设置的方式：</span></p><p><img src="https://img3.gelonghui.com/64d9a-879492bb-cf44-46de-9577-c6b1e8b73757.jpg"></p><p><span>进行此更改后，GDDR6X每个周期每个引脚有效传输2位数据-因此，对于相同的时钟速度和引脚数，带宽增加了一倍。GeForce RTX 3090具有24个GDDR6X模块，它们以单通道模式运行，额定速率为19 Gbps，提供的峰值传输带宽为936 GB / s。</span></p><p><span>与GeForce RTX 2080 Ti相比，这增加了52％，并且不能轻易忽视。过去仅通过使用类似HBM2的方式获得了这样的带宽数字，与GDDR6相比，HBM2的实现成本很高。</span></p><p><span>但是，只有Micron可以制造这种存储器，而PAM4的使用为生产过程增加了额外的复杂性，对信号的公差要严格得多。AMD走了一条不同的道路-他们没有寻求外部机构的帮助，而是利用其CPU部门为桌面带来了新的东西。与它的前代产品相比，RDNA 2中的整个内存系统没有太大变化，只有两个主要变化。</span></p><p><img src="https://img3.gelonghui.com/c0f61-1096dc6a-0b85-459c-9173-b701eca81636.png"></p><p><span>每个着色器引擎现在都有两组Level 1缓存，但是由于它们现在具有两组Dual Compute Unit（RDNA拥有一组），因此这种改变是可以预期的。但是将128 MB的3级缓存缓存到GPU中吗？这让很多人感到惊讶。利用其EPYC系列Zen 2服务器芯片中的L3高速缓存的SRAM设计，AMD在该芯片中嵌入了两组64 MB高密度高速缓存。数据事务由16组接口处理，每个接口每个时钟周期移位64个字节。</span></p><p><span>所谓的无限缓存具有其自己的时钟域，并且可以在1.94 GHz上运行，从而提供1986.6 GB / s的内部峰值传输带宽。而且由于它不是外部DRAM，因此涉及的延迟非常低。这种高速缓存非常适合存储光线跟踪加速结构，并且由于BVH遍历涉及大量数据检查，因此Infinity高速缓存应特别为此提供帮助。</span></p><p><img src="https://img3.gelonghui.com/0d4fc-002fae7f-f967-446b-9f48-a0fb64ec9c71.png"></p><p><span><em><span>两个64 MB的Infinity缓存条和Infinity Fabric系统</span></em></span></p><p><span>目前，尚不清楚RDNA 2中的3级缓存是否以与Zen 2 CPU中相同的方式运行：即作为2级victim缓存。通常，当需要清除最后一级的高速缓存以为新数据腾出空间时，对该信息的任何新请求都必须发送到DRAM。</span></p><p><span>victim缓存存储的数据已经被标记为要从下一层内存移除，并且有128MB的数据可用，Infinity缓存可能存储32个完整的L2缓存集。该系统的结果是，在GDDR6控制器和DRAM上放置的需求更少。</span></p><p><span>AMD的较旧GPU设计一直在缺乏内部带宽的情况下苦苦挣扎，尤其是当它们的时钟速度提高后，但是额外的缓存将使该问题逐渐消失。</span></p><p><img src="https://img3.gelonghui.com/0df17-64ba4f58-4366-42fe-a82a-9433bbb8e884.png"></p><p><span>那么，哪种设计更好呢？GDDR6X的使用为GA102提供了到本地内存的巨大带宽，并且更大的缓存将有助于减少缓存未命中（这会使线程的处理停滞）的影响。Navi 21的大型3级缓存意味着DRAM不必经常被窃听，并利用了以更高的时钟速度运行GPU的能力，而不会出现数据匮乏的情况。</span></p><p><span>AMD决定坚持使用GDDR6的决定意味着第三方供应商可以使用更多的内存，同时任何制造GeForce RTX 3080或3090的公司都必须使用美光。尽管GDDR6有多种模块密度，但GDDR6X当前限于8 Gb。</span></p><p><span>RDNA 2中的缓存系统可以说是比Ampere中使用的缓存系统更好的方法，因为与外部DRAM无关，使用多个级别的片上SRAM始终比外部DRAM提供更低的延迟和更好的性能（在给定的功率范围内）。</span></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p><span><strong><br></strong></span></p><h3 style="text-align: center;"><span><font color="#3daad6">GPU的来龙去脉</font></span></h3><p><span><strong><br></strong></span></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p><span><strong><span>渲染管线</span></strong></span></p><p><span>这两种架构都对渲染管线的前端和后端进行了大量更新。DirectX12 Ultimate中的Ampere和RDNA 2完全具有运动型网格着色器和可变速率着色器，但Nvidia的芯片具有更出色的几何性能，而这要归功于Nvidia用了更多的任务处理器。</span></p><p><span>尽管使用网格着色器可以使开发人员创建更加逼真的环境，但没有一款游戏的性能会完全以来于渲染过程中的这个阶段。因为大部分最难的工作是在像素或光线跟踪阶段。</span></p><p><img src="https://img3.gelonghui.com/2b20f-af4301e6-c82a-400e-88f6-59b15aac3f62.png"></p><p><span>这就是使用可变率着色器发挥作用的地方——基本上该过程涉及在一个像素块而不是单个像素上应用照明和颜色着色器。这类似于为了提高性能而降低游戏的分辨率，但由于它只能应用于选定的区域，因此视觉质量的损失并不明显。</span></p><p><span>无论是否使用可变速率着色器，这两种体系结构都已更新了其渲染输出单元（ROP），这将提高在高分辨率下的性能。在所有以前的GPU中，Nvidia都将ROPs与内存控制器和二级缓存绑定在一起。</span></p><p><span>在Turing中，8个ROP单元(统称为一个分区)会直接链接到一个控制器和一个512kb的高速缓存上。添加更多的ROP会带来问题，因为它需要更多的控制器和缓存，因此对于Ampere而言，现在ROP已完全分配给了GPC。GA102每个GPC拥有12个ROP（每个时钟周期处理1个像素），整个芯片共有112个单位。</span></p><p><span>AMD采用了与Nvidia的旧方法类似的系统（即与内存控制器和L2缓存片绑定），尽管它们的ROP主要使用1级缓存进行像素读/写和混合。在Navi 21芯片中，已经为它们提供了急需的更新，并且每个ROP分区现在每个周期以32位颜色处理8个像素，并以64位处理4个像素。</span></p><p><span>Nvidia还为Ampere带来了RTX IO，这是一种数据处理系统，可以让GPU直接访问存储驱动器，复制所需的数据，然后使用CUDA内核解压。但是，目前该系统不能在任何游戏中使用，因为Nvidia正在使用DirectStorage API（另一种DirectX12增强功能）来控制它，并且尚未准备好公开发布。</span></p><p><img src="https://img3.gelonghui.com/da8b2-eed23240-6bbd-4656-b14b-084e1aef052d.png"></p><p><span>目前使用的方法包括让CPU管理所有这一切：它接收来自GPU驱动程序的数据请求，将数据从存储驱动器复制到系统内存中，进行解压缩，然后再复制到图形卡的DRAM中。</span></p><p><span>除了涉及大量浪费的复制之外，这种机制在本质上是串行的——CPU一次只能处理一个请求。Nvidia声称可以达到“100倍的数据吞吐量”和“20倍的CPU利用率低”，但是在系统能够在现实世界中测试之前，并不能证明它能够实现这种效果。</span></p><p><img src="https://img3.gelonghui.com/d04a8-6eb14cdd-a0cd-4050-85e7-a3bc06a35bd6.png"></p><p><span>当AMD推出RDNA 2和新的Radeon RX 6000图形卡时，他们推出了称为Smart Access Memory的产品。这不是他们对Nvidia的RTX IO的答案——实际上，它甚至不是真正的新功能。默认情况下，每个单独的访问请求中，CPU中的PCI Express控制器最多可以寻址256 MB的图形卡内存。</span></p><p><span>此值由基址寄存器（BAR）的大小设置，并且早在2008年，PCI Express 2.0规范中就有一项可选功能，可以调整其大小。这样做的好处是，只需处理较少的访问请求即可访问整个卡的DRAM。</span></p><p><span>该功能需要操作系统，CPU，主板，GPU及其驱动程序的支持。当前，在Windows PC上，系统仅限于Ryzen 5000 CPU，500系列主板和Radeon RX 6000图形卡的特定组合。</span></p><p><img src="https://img3.gelonghui.com/cc862-42fc9a2e-34d3-4e06-97c5-b729d462d2d1.png"></p><p><span>测试时，这个简单的功能给出了一些令人吃惊的结果——在4K环境下将性能提升15%是不容小觑的，所以英伟达表示他们将在不久的将来为RTX 3000范围提供这个特性也就不足为奇了。</span></p><p><span>是否可调整大小的BAR支持是否适用于其他平台组合还有待观察，但是它的使用无疑是受欢迎的，即使它不是Ampere / RDNA 2的体系结构功能。</span></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p><span><strong>视频取代了广播</strong></span></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p><span><strong><span>多媒体引擎，视频输出</span></strong></span></p><p><span>GPU世界通常由核心访问量、TFLOPS、GB/s和一些其他指标为主导，由于YouTube内容创造者和直播游戏流的崛起，使得市场开始注意GPU的显示和多媒体引擎的能力。</span></p><p><span>随着支持此类功能的显示器价格的下降，对所有分辨率下的超高刷新率的需求也在增长。两年前，一台144 Hz 4K 27”的HDR显示器要花你2000美元;今天，你可以用几乎一半的价格买到类似的东西。</span></p><p><span>两种架构均通过HDMI 2.1和DisplayPort 1.4a提供显示输出。前者提供了更多的信号带宽，但是在HDR和240 Hz时，它们的额定频率均为4K，在60 Hz时，其额定值为8K。这是通过使用4：2：0色度二次采样或DSC 1.2a实现的。这些是视频信号压缩算法，可显着减少带宽需求，而不会损失太多的视觉质量。如果没有它们，即使HDMI 2.1的峰值带宽为6gb /s，也不足以以6hz的速率传输4K图像。</span></p><p><img src="https://img3.gelonghui.com/50b90-a670fb0c-e9b2-48f8-b011-d22856ec5135.png"></p><p><span><em><span>48英寸LG CK OLED'显示器'-120 Hz时的4K需要HDMI 2.1</span></em></span></p><p><span>Ampere和RDNA 2还支持可变刷新率系统（用于AMD的FreeSync，用于Nvidia的G-Sync），在视频信号的编码和解码方面，也没有明显的区别。</span></p><p><span>无论您使用哪种处理器，您都会发现对8K AV1、4K H.264和8K H.265解码的支持，尽管它们在这种情况下的性能究竟如何还没有得到彻底的研究。两家公司都没有详细说明他们的显示和多媒体引擎的内部结构。尽管它们很重要，但GPU的其余部分依旧值得关注。</span></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p><span><strong><br></strong></span></p><h3 style="text-align: center;"><span><strong><font color="#3daad6">不同的策略</font></strong></span></h3><p><span><strong><br></strong></span></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p><span><strong><span>为计算而生，还是为游戏而生</span></strong></span></p><p><span>GPU历史的爱好者将知道AMD和Nvidia过去在架构选择和配置上采用了截然不同的方法。但是，随着3D图形越来越受到计算世界和API的同质化的支配，它们的总体设计也越来越相似。</span></p><p><span>如今的游戏并不是以渲染需求为架构定下基调，GPU产业已经扩展到的市场领域才是引领方向。在撰写本文时，Nvidia有三种使用Ampere 技术的芯片:GA100、GA102和GA104。</span></p><p><span>最后一个只是GA102的精简版——每个GPC拥有的TPC更少（整体GPU更少），而二级缓存则只有三分之二。其他所有内容都完全相同。而GA100则是与此完全不同的产品。</span></p><p><span>GA100没有RT核，也没有INT32 + FP32支持的CUDA核。相反，它打包了许多额外的FP64单元，更多的加载/存储系统以及大量的L1 / L2缓存。它也没有显示器或多媒体引擎。这是因为它完全是为用于AI和数据分析的大规模计算集群而设计的。</span></p><p><span>从应用场景上看，GA102/104需要覆盖Nvidia瞄准市场是:游戏爱好者、专业图形艺术家和工程师，以及小规模的人工智能和计算工作。Ampere则想要成为“万事通”，并且能够精通所有行业，但这可不是一件容易的事。</span></p><p><img src="https://img3.gelonghui.com/86eba-49294054-76b0-4157-8a13-992c9c643b9c.png"></p><p><span><em><span>750平方毫米的Arcturus CDNA</span></em></span></p><p><span>RDNA 2专为PC和游戏机上的游戏而设计，尽管它可以转向与Ampere相同的应用市场。然而，AMD选择继续他们的GCN架构，并更新它，以满足今天的专业客户的需求。</span></p><p><span>RDNA 2产生了“ Big Navi”，而CDNA产生了“ Big Vega”-Instinct MI100装有Arcturus芯片，这是一个拥有128个计算单元的500亿晶体管GPU。与Nvidia的GA100一样，它也不包含显示器或多媒体引擎。</span></p><p><span>尽管英伟达凭借Quadro和特斯拉(Tesla)等在专业市场占据了主导地位，但Navi 21之类的产品并非旨在与之抗衡，而是进行了相应的设计。这是否会使RDNA 2成为更好的结构体系; Ampere 适应多种市场的要求是否在限制了它的发展?</span></p><p><span>当您查看证据时，答案似乎是：不。</span></p><p><img src="https://img3.gelonghui.com/4cda0-2dfd0bbe-5ff9-4af6-b840-b294490b05aa.png"></p><p><span>AMD将很快发布Radeon RX 6900 XT，它使用了完整的Navi 21(没有禁用CUs)，其性能可能与GeForce RTX 3090或更好。但是那张卡上的GA102也没有被完全释放，所以Nvidia总是可以选择升级到一个“超级”版本，就像他们去年对 Turing所做的那样。</span></p><p><span>可能有人会说，因为RDNA 2被用在Xbox系列X/S和PlayStation 5中，游戏开发者会倾向于将这种架构用于他们的游戏引擎。但是，您只需要查看在Xbox One和PlayStation 4中使用了GCN的时间，便可以了解这种情况如何发挥作用。</span></p><p><span>前者在2013年的第一次发布中使用了基于GCN 1.0架构的GPU——这种设计直到第二年才出现在桌面PC图形卡中。2017年发布的Xbox One X使用的是GCN 2.0，这是一个已经使用了3年多的成熟设计。</span></p><p><span>那么，所有为Xbox One或PS4制作的游戏，只要移植到PC上，就能在AMD显卡上运行得更好吗?实际上，并没有。因此，尽管RDNA 2具有令人印象深刻的功能，但我们不能认为该产品会与RDNA 2有所不同。</span></p><p><span>但这些最终都无关紧要，因为这两种GPU设计都具有非凡的能力，是半导体制造领域的奇迹。英伟达和AMD带来了不同的工具，因为他们都在试图解决不同的问题;Ampere的目标是面向所有人，RDNA 2主要是关于游戏的。</span></p><p><span>这一次，战斗陷入了僵局，尽管双方都可以在特定的一两个区域宣告胜利。GPU之战将持续到明年，一个新的竞争者将加入这场战斗：英特尔的Xe系列芯片。在不久的将来，我们就能看到这场战斗的结果了!</span></p><p></p><p></p><p></p><p></p><p></p>
➜任泽平：南北经济差距在拉大吗？原因何在？
https://www.gelonghui.com/p/432921	5036
<p><b>作者：任泽平 熊柴 于嘉俊</b><br></p><p><span>来源：泽平宏观</span></p><p><span><strong><span>当前我国南北差距明显拉大。</span></strong><span>2012-2019年北方经济占全国比重从42.9%快速下降至35.4%，南北经济总量差距从14个百分点迅速扩大至29个百分点，人均GDP差距从0.97迅速增至1.30。</span></span></p><p><span><strong><span>南北差距原因：从自然地理差异到市场发育差异。</span></strong><span>从五千年历史看，由于北方因农耕、游牧两大文明长期冲突融合导致战乱频发及南北气候差异等，中国人口和经济重心逐渐从黄河中下游向长江中下游转移。计划经济时期，北方因资源富集等形成重化工业优势而领先南方。改革开放后，北方依靠要素和投资驱动继续阶段领先，但也导致市场化改革内生动力不足；而南方依托便利的海运和长江内河航运优势，通过市场化改革大力发展外向型经济而逐渐崛起。<strong>2012年后，中国经济转向依靠创新驱动的高质量发展阶段，南北市场发育差异问题凸显，南方较快转型升级，而北方逐渐乏力</strong>。</span></span></p><p><span><strong><span>南北差距拉大，这是市场经济对计划经济的胜利，证明北方加大市场化改革的必要性和紧迫性。</span></strong></span></p><p><span><strong><span>解决南北差距既要针对北方短板加快市场化改革，还要从全国层面基于市场规律统筹推进区域协调发展。</span></strong><span>一方面，北方要大力向南方学习，加快深化产权、要素等市场化改革，加快打造亲清新型政商关系以优化营商环境。另一方面，要充分尊重人口和产业向优势区域集聚的客观规律，立足各地区比较优势顺势而为，加快都市圈城市群建设，在集聚中促进平衡。</span></span></p><p><span><strong>“双循环”的核心是对内扩大内需、对外提升产业链安全，关键是三大抓手：“新基建”、城市群和放开生育。</strong>这是这些年我们在公共政策领域的三大建言和呼吁，其中新基建已经从学术讨论走向国家战略，都市圈城市群逐渐走向社会共识但尚未完全落实，而全面放开生育则面临巨大的学术分歧和社会争议。</span></p><p><span><strong><span><br></span></strong></span></p><h3 style="text-align: center;"><font color="#3daad6"><span>1&nbsp;</span></font></h3><h3 style="text-align: center;"><font color="#3daad6"><span>我国区域发展新特征：南北差距明显拉大</span></font></h3><p><span><strong><span><br></span></strong></span></p><p><span><strong><span>改革开放以来，我国区域发展差距总体呈缩小态势，但2014年后区域差距有所扩大。</span></strong><span>由于历史原因，新中国成立初期北方尤其是东北重工业基础良好、经济基础较好，1950年代苏联援助也主要集中在东北。1960年代基于国防安全考虑的“三线建设”促进了中西部地区经济发展，1960-1977年人均GDP最高的东北与最低的西部的差距由3.06降至2.20。1978年改革开放后，东部基于区位优势率先发展，大量人口从内地向东部集聚，1991年东部人均GDP超过东北居四大区域之首，其人均GDP与最低的西部的比值一度扩大至2003年的峰值2.61。2003年后，随着西部开发、东北振兴、中部崛起等区域发展战略的实施，以及2008年金融危机后沿海地区向内地转移产业，各区域人均GDP相对差距逐渐缩小，但2014年后有所扩大。</span></span></p><p><span><span><strong>从全国看，</strong>以反映各省人均GDP整体相对差异水平的变异系数看，31省人均GDP变异系数从1978年的0.966快速下降至1990年的谷值0.593，随后在东部率先发展的带动下爬升至2002年的峰值0.708，再回落到2014年的0.435，之后又攀升至2019年的0.472。<strong>分地区看，</strong>四大地区人均GDP变异系数的发展趋势与全国较为一致，2014年达谷值后有所扩大。</span></span></p><p><img src="https://img3.gelonghui.com/e9861-5b5d776f-6d44-4403-8922-5958d7b817bc.png"></p><p><img src="https://img3.gelonghui.com/7a59b-76730af7-58b7-4595-a7b0-512f4c099bec.png"></p><p><span><strong><span>当前区域差距的扩大主要在于南北差距，2012-2019年南北经济总量差距从14个百分点迅速扩大至29个百分点，但人口份额变化很小，导致该时期南北人均GDP差距由0.97迅速增至1.30。从经济看，</span></strong><span>1978-2012年南北经济份额（以地区GDP合计为分母）分别从53.7%、46.3%变化至57.1%、42.9%，差距从7.5个百分点扩大至14.2个百分点；其中1995年南北经济份额差距一度达17.3个百分点。2013年起，南北经济总量差距迅速拉大，2019年经济份额分别为64.6%、35.4%，差距扩大至29.1个百分点。</span></span></p><p><span><span><strong>从人口看，</strong>改革开放以来，我国人口流动的主要方向是从中西部到东部的珠三角、长三角和京津地区，1978-2019年东部人口份额从34.0%增至38.6%；南北人口份额变化较小，1978-2019年南北人口份额分别从42.2%、57.8%变化至41.6%、58.4%，变化仅0.6个百分点。</span></span></p><p><span><span><strong>从人均GDP看，</strong>我国北方人均GDP长期高于南方但逐渐缩小，1978-2012年南北人均GDP差距由0.85缩小至0.97。之后，南北人均差距迅速扩大至2019年的1.30。即使扣除东北地区，2012-2019年南北人均GDP差距仍从0.98扩大至1.24，表明<strong>东北的相对衰落只能部分解释南北人均差距扩大。</strong></span></span></p><p><img src="https://img3.gelonghui.com/4c42e-b4d41c8c-5a2b-467c-8ae0-def761a4926a.png"></p><p><img src="https://img3.gelonghui.com/c9518-5f757601-81d3-43a3-a3d2-342db8039df8.png"></p><p><span><strong><span>从10强省看，1978-2020年北方从5个降至仅剩山东、河南2个。</span></strong><span>1978-2019年，我国10强省经济份额从54.9%提升至61.3%。在改革开放初期，北方在我国10强省中占据5席，其中东北占两席（辽宁、黑龙江）。之后，东南沿海省份迅速崛起，1984年浙江取代黑龙江进入前10。此后，北方的山东、辽宁、河南、河北长期位居前10。由于2010年后经济转型缓慢，辽宁、河北先后在2016、2018年跌出全国前10。目前北方在全国经济10强中仅剩山东、河南两省。其中，山东从1980年起一直位列前3，2007年开始持续位居第三，但与第二名江苏的差距从2007年的242亿元持续扩大2019年的2.9万亿元，而与第四名浙江的差距逐渐缩小至不到9000亿元。</span></span></p><p><img src="https://img3.gelonghui.com/9f2fb-f48fc55d-f8fc-44a9-b531-83f9fafb036d.png"></p><p><span><strong><span>从20强城市看，1978-2020年北方从11个降至5个，其中10强城市从6个降至仅剩北京1个。</span></strong><span>1978-2019年，我国20强城市经济份额从29.7%上升至34.5%。改革开放初期，北方在20强城市中占11个，其中东北6个。随着改革开放后深圳、无锡、宁波等东南沿海城市陆续崛起，1990年20强城市中北方减至9个，东北的长春、鞍山陆续掉队。2010年 20强城市中北方降至8个，且有3城位居倒数，哈尔滨从1978年的第8名降至第20名。2001年加入世界贸易组织后，以出口为导向的东南沿海地区进一步融入全球经济体系，佛山、东莞等制造业城市崛起，哈尔滨、石家庄、大庆逐渐掉出20强。2010年，北方在 20强城市中降至7个。2014年后，北方的唐山、大连、沈阳、烟台先后掉队。2017-2018年，北方在20强城市仅剩北京、天津、青岛、郑州4个，10强中仅剩北京、天津2个；2019年济南在合并莱芜后进入20强。2020年，南京取代天津进入10强，北方在10强城市中仅剩北京。</span></span></p><p><img src="https://img3.gelonghui.com/ebf12-a4e93d82-122e-4102-bf3e-c286f310ac16.png"></p><p><span><strong><span><br></span></strong></span></p><h3 style="text-align: center;"><font color="#3daad6"><span>2</span></font></h3><h3 style="text-align: center;"><font color="#3daad6"><span>&nbsp;</span><span>南北差距原因：从自然地理差异到市场发育差异</span></font></h3><p><span><strong><span><br></span></strong></span></p><p><span><strong><span>从五千年历史看，因农耕技术进步、北方战乱频发、南北气候差异等，中国人口重心逐渐从北方黄河中下游向南方长江中下游转移，南方逐渐从山地密林的蛮荒瘴气之地开发成宜居宜业之地，在南宋时期彻底取代北方成为经济重心。</span></strong><span>不可否认，长江与黄河都是华夏文化的摇篮，但位于黄河中下游的中原地区无疑是早期中心，夏商周等王朝核心范围均位于此，原因可能在于南北气候差异，北方干燥缺水、温差大，南方湿润、温差小，这使得在农耕时代初期，相对干旱、疏松的黄土沉积平原，比南方的黏土湿地更容易开发耕作。在秦汉时期，关中平原是全国经济重心，北方经济、人口长期领先，而南方不少地区仍是蛮荒瘴气之地。</span></span></p><p><span><span>但北方长期处于王朝更替的中心和农耕文明与游牧文明的冲突融合，战乱频发，从东汉末年开始北方人口大量移居南方，南方地区逐渐开发并快速发展，特别是在两晋南北朝时期。江南经济的快速发展，使得隋炀帝开凿北起涿郡、南到杭州的大运河，主要目的在于把江南丰富的物产往北运调。唐朝安史之乱后，南方人口和经济开始超过北方。到南宋时期，岭南快速开发，南方绝对取代北方成为中国经济和人口重心，西北陆上丝绸之路让位于东南海上丝绸之路，南方领先格局基本延续至今。尽管清朝中期开始闭关锁国，但仍保留了广州一地作为通商口岸。</span></span></p><p><span><strong><span>计划经济时期，资源富集等奠定北方重化工业优势，因而领先于南方。</span></strong><span>在计划经济时期，中国经济发展基本依靠内循环，北方依托丰富的煤炭、石油、铁矿资源和苏联援助等逐渐形成了以资源型和重化工业型为主的产业结构，以货运为主的铁路建设更使得北方区位优势凸显，经济发展水平明显超过北方。东北地区作为我国重工业基地，发展水平更是居前，辽宁GDP长期位居全国前三、一度位居第一。而南方资源相对匮乏，经济发展较为落后；东南沿海更处海防前线，重工业、大项目的布局较少。改革开放前，北方GDP占比长期在46%-49%之间，1960年更是一度高达49.9%，而南方人均GDP仅相当于北方的80%-90%。</span></span></p><p><span><strong><span>改革开放后，南方依托便利的海运和长江内河航运优势、通过市场化改革大力发展外向型经济而逐渐崛起，而北方在重化工业需求拉动下通过要素和投资驱动仍保持了较长时期辉煌、但也造成市场化改革内生动力不足。</span></strong><span>1978年后，我国逐渐从计划经济体制向社会主义市场经济体制转型，但南北市场化改革进展差异明显。<strong>从自然地理角度，</strong>改革开放要求融入全球化体系，东南沿海较北方沿海具有更为便利的海运优势，并通过长江、珠江较易形成广阔市场和腹地。而黄河水量少河道浅，通航能力差，使得北方省份经济联系明显不如南方，在发展外向型经济时面临劣势。</span></span></p><p><span><span><strong>从制度演化角度，</strong>改革开放初期南方珠三角地区利用毗邻港澳优势等，大力发展加工制造业，广东经济总量在1980年代末开始跃居第一；该时期江苏、浙江也快速发展。1990年以上海浦东开发开放为标志，长三角和长江流域明显带动。在北方，尽管东北地区因强大的计划经济惯性、沉重的计划经济包袱和资源逐渐枯竭等在1990年代开始衰落、大量国企倒闭，但大规模铁公基建设对钢铁、水泥、石化、煤炭等重化工业需求巨大，使得北方经济仍保持了较长时间辉煌，特别是山东、天津、河北、山西等地区；山东经济总量在2004、2006年两次超过江苏位居全国第二，山西煤老板风光全国。</span></span></p><p><span><strong><span>南北市场发育差异在2008年末“四万亿”投资后凸显，南方较快转型升级发展高新产业，而北方逐渐乏力。</span></strong><span>2008年全球金融危机后，两年“四万亿”投资使得北方经济再延续了短暂辉煌。但之后，全球经济长期低迷，国际大宗商品和能源价格一度进入漫长熊市；中国经济发展进入新常态，依靠要素和投资驱动的老路难以为继，波切需要转向创新驱动。2015年末，中央提出大力推进供给侧结构性改革；2020年，中央要求，加快形成以国内大循环为主体、国际国内双循环相互促进的新发展格局。<strong>在南方，</strong>东南地区因日益发育的市场机制快速出清过剩产能，大力腾笼换鸟推动经济转型升级，南方内陆省份依托长江等承接沿海产业，近年贵州、云南、西藏、江西等省份经济增速持续领跑全国。<strong>在北方，</strong>因市场机制改革滞后，营商环境相对较差，新经济新动能培育缓慢，产业转型升级艰难。</span></span></p><p><span><strong><span>从经济普查等情况看，南北差距拉大的情况可能发生更早，但被北方较多的数据注水掩盖。</span></strong><span>2014年，中央巡视组发现东北地区经济数据注水严重；在“挤水分”之后，2016年辽宁名义GDP较2015年缩水22.4%。2018年第四次全国经济普查后，全国GDP比初步核算数增加2.1%；其中，南方16省有14省上调、2省下调，北方15省有12省下调、3省上调。下调超过10%的有天津、吉林、黑龙江、山东，均为北方省份，分别为-29.0%、-25.3%、-21.5%、-12.8%。山东调整幅度超过甘肃省2019年GDP（8718亿元），天津调整幅度超过海南GDP（5309亿元）。部分地区GDP的大幅调整，虽然有统计标准规范和调整的因素，但更与挤掉多年累积的GDP“水分”有关。</span></span></p><p><img src="https://img3.gelonghui.com/02810-b45d1984-4507-4e2e-a5ed-0fed58676423.png"></p><p><span><strong><span><br></span></strong></span></p><h3 style="text-align: center;"><font color="#3daad6"><span>3</span></font></h3><h3 style="text-align: center;"><font color="#3daad6"><span>&nbsp;</span><span>推进区域协调发展的国际经验</span></font></h3><p><span><strong><span><br></span></strong></span></p><p><span><strong><span>总体上看，发达国家区域人均差距长期较小，关键在于各类要素在市场机制下充分流动，进而在集聚中走向平衡。</span></strong><span>比如，人口迁移的基本逻辑是人往高处走，人随产业走。理论上，较高的人均收入将不断吸引区外人口净流入，直至该地区人均收入与其他地区持平，即各地区经济份额与人口份额的比值趋近1，形成区域发展的相对平衡。</span></span></p><p><span><strong><span>在美国，区域人均差距长期较小，地区人口份额与经济份额变化比较一致。从总体看，</span></strong><span>1963-2019年美国不含阿拉斯加的49个州人均GDP变异系数0.193波动变至0.192，基本保持在0.15-0.20之间，远低于中国当前的0.47。<strong>分州看，</strong>2019年美国50个州中有46个州的经济-人口比值在0.7-1.3之间，人口合计占比约90%；其中有21个州的经济-人口比值在0.9-1.0之间。而中国2019年31省中只有15省经济-人口比值在0.7-1.3之间，人口合计占比仅51%；其中北京、上海在2.2以上，甘肃、黑龙江在0.6以下。</span></span></p><p><span><span><strong>从都会区看，</strong>1910-2015年美国都会区人口比重从28.4%增至85.6%，其中人口向大都会区化集聚态势明显。2015年5-25万、25-100万、100-500万、500万人以上都会区经济-人口比值分别为0.75、0.84、1.09、1.26，差异较小。</span></span></p><p><span><span><strong>从重点地区看，</strong>1970年开始，美国传统制造逐渐衰落，人口逐渐从相对衰落的五大湖区向能源、现代制造和现代服务业主导的西海岸、南海岸集聚。1970-2019年，美国“铁锈八州”的经济份额由37.9%下降至25.8%，人口份额也由35.4%降至24.7%，经济-人口比值从1.07下降至1.04；同期加利福尼亚、佛罗里达、德克萨斯三州的经济份额由19.3%升至28.5%，人口份额由18.7%升至27.4%，经济-人口比值从1.03略升至1.04。</span></span></p><p><img src="https://img3.gelonghui.com/c2551-fd5c3da8-44bf-4214-aa8b-a4e2ef555bb0.png"></p><p><img src="https://img3.gelonghui.com/c172b-c2bb9968-1089-4909-a9c7-8538f9eaa726.png"></p><p><span><strong><span>在日本，人口随产业持续向向东京圈、大坂圈、名古屋圈“三极”集聚1973年左右后转为向东京圈“一极”集聚，三大都市圈经济-人口比值逐渐趋近于1.0。</span></strong><span>日本三大都市圈土地面积合计3.8万平方公里，占日本的10.2%，当前经济份额、人口份额分别为56%、52%。在1970年代日本经济增速换挡以前，因三大都市圈收入水平较高且经济持续集聚，人口大规模流入。1955年东京圈、大坂圈、名古屋圈GDP占全国份额分别为23.8%、15.3%、8.6%，人口占比分别为17.3%、12.3%、7.7%，经济-人口比值为1.38、1.24、1.12。到1973年，三大都市圈GDP占比分别增至29.1%、16.9%、9.4%，人口分别达2607、1636、918万人，占比分别达23.9%、15%、8.4%，经济-人口比值分别为1.22、1.13、1.12。</span></span></p><p><span><span><strong>1973年之后，</strong>东京圈人口继续保持明显净迁入，名古屋圈大坂圈人口迁入基本停滞、主要依靠自然增长。2014年东京圈、大坂圈、名古屋圈经济份额分别为32.3%、13.9%、9.9%，人口分别为3592、1836、1132万人，占比分别为28.3%、14.4%、8.9%，经济-人口比值分别为1.14、0.96、1.11。</span></span></p><p><img src="https://img3.gelonghui.com/a9da4-82707ba4-13c2-45d0-9f05-1401bcb5459e.png"></p><p><img src="https://img3.gelonghui.com/cef46-ef0f5016-2ce1-48e1-b36a-40376fcb8175.png"></p><p><span><strong><span>在韩国，首尔圈人口大量流入使得其经济-人口比值趋近1。</span></strong><span>1955-2015年首尔都市圈人口从393万人增至2442万人，占全国比重从18.3%增至49.1%。随着人口持续大量迁入，首尔圈经济-人口比值逐渐下降，1985年为1.122，持续降至2010年0.998，然后在接近1的位置波动，2016年为1.008。</span></span></p><p><span><strong><span><br></span></strong></span></p><h3 style="text-align: center;"><font color="#3daad6"><span>4</span></font></h3><h3 style="text-align: center;"><font color="#3daad6"><span>&nbsp;</span><span>建议：北方加大市场化改革，全国统筹推进区域协调发展</span></font></h3><p><span><strong><span><br></span></strong></span></p><p><span>当今世界正经历百年未有之大变局，我国正处于实现中华民族伟大复兴的关键时期，推进区域协调发展是加快形成以国内大循环为主体、国际国内双循环相互促进的新发展格局的应有之义，是社会和谐、政治稳定和经济可持续发展的重要保障。<strong>我们认为，解决南北差距既要针对北方短板加快市场化改革，还要从全国层面基于市场规律统筹推进区域协调发展。</strong></span></p><p><span><strong><span>一方面，北方要大力向南方学习，加快深化产权、要素等市场化改革，大力转变政府职能并加快打造“亲”“清”新型政商关系以优化营商环境。</span></strong><span>北方地区应大力向东南沿海地区学习，进一步解放思想、破除体制机制障碍，加快深化产权改革、要素改革、国企改革等市场化改革。理顺政府和市场关系，大幅减少政府对资源的直接配置，强化事中事后监管，给市场发育创造条件。进一步推动简政放权、放管结合、优化服务，建立健全权力清单、责任清单制度。打造“亲”“清”新型政商关系，培育有利于民营经济发展、有利于新经济发展的市场环境，消解民企发展面临的歧视性限制和隐性障碍。</span></span></p><p><span><strong><span>另一方面，要充分尊重人口和产业向优势区域集聚的客观规律，立足各地区比较优势顺势而为，打破地区行政分割、破除要素流动障碍、完善财政转移支付机制和生态补偿机制等，加快都市圈城市群建设，在集聚中促进平衡。</span></strong><span>推进区域协调发展的目标促进人民生活水平大体相当，绝不能是追求各地区经济总量均衡，也不可能要求各地区在经济发展上达到同一水平。习近平总书记2019年12月在《求是》发表文章《推动形成优势互补高质量发展的区域经济布局》指出，要尊重人口和产业向优势地区集聚的客观规律，增强中心城市和城市群等经济发展优势区域的经济和人口承载能力，增强其他地区在保障粮食安全、生态安全、边疆安全等方面的功能，形成优势互补、高质量发展的区域经济布局。</span></span></p><p><span><strong><span>一是进一步打破地区行政分割，全面破除要素流动障碍，加快形成全国统一开放、竞争有序的商品和要素市场。</span></strong><span>经过40多年改革开放，中国商品市场发育较为充分，商品和服务价格97%以上由市场定价，但仍存在地区分割问题；土地、劳动力、资本、技术、数据等要素市场发育相对滞后，市场决定要素配置范围有限、要素流动存在体制机制障碍、新型要素市场规则建设滞后等，影响了市场对资源配置决定性作用的发挥。要树立全国经济“一盘棋”的思想，消除歧视性、隐蔽性的区域市场壁垒，打破行政性垄断，坚决破除地方保护主义；加快促进土地、劳动力、资本、技术、数据自由流动，提高要素配置效率。养老保险全国统筹对维护全国统一大市场、促进企业间公平竞争和劳动力自由流动具有重要意义，要加快养老保险全国统筹进度、提高统筹水平，在全国范围内实现制度统一和区域间互助共济。</span></span></p><p><span><strong><span>二是深化土地制度改革，建立健全宅基地自愿有偿退出机制，以常住人口增量为主要标准供给城镇用地，推进市场化的跨省换地。</span></strong><span>土地是各项要素中市场化改革最为滞后的领域，潜力极大。<strong>从城乡角度看，</strong>应加快建立健全宅基地自愿有偿退出机制，进而加快推进农业转移人口市民化，并推行新增常住人口与土地供应挂钩，对人口增长的地区加大建设用地供应，对人口减少的地区要减少土地供应。目前的“人地挂钩”指农业转移人口落户数量与城镇建设用地供应量挂钩（2016年《关于建立城镇建设用地增加规模同吸纳农业转移人口落户数量挂钩机制的实施意见》），作用有限。</span></span></p><p><span><span><strong>从地区角度看，</strong>应通过市场机制优化城镇用地指标在地区和城市之间的空间配置。中国补充耕地潜力主要在西部、东北地区，而需求主要在东部；人口、资本、技术等各种要素基本可以跨省流动，但耕地占补平衡、城乡建设用地增减挂钩等土地要素配置目前仍主要局限在省域乃至市域内部。2018年3月，国务院发布《跨省域补充耕地国家统筹管理办法》和《城乡建设用地增减挂钩节余指标跨省域调剂管理办法》，开始允许在中央统筹下的小规模跨省换地；但规定由中央统一下达调剂任务，统一确定调剂价格标准，统一资金收取和支出，本质仍是计划配置。</span></span></p><p><span><strong><span>三是充分尊重产业和人口向优势地区集聚的客观规律，加快贯彻落实城市群都市圈战略。</span></strong><span>因共享效应、匹配效应、学习效应因等，大多数产业发展需要集聚，服务、高新技术、金融、制造等更明显，人随产业走，人口自然向以大城市为核心的都市圈城市群集聚，向经济更发达、收入水平更高、更能提供就业机会的地区流动和集聚，这是人类社会发展的一般规律。但在过去几十年，关于“控制大城市规模、积极发展中小城镇、区域均衡发展”的计划经济思想长期占据主导，初衷是为了避免其他国家走过的城市化弯路，比如欧美的大城市病、拉美的贫民窟等问题这听起来好像非常理想，关起门来想好像也很合理，但实践中却严重脱离实际，造成了一系列严重问题。在广泛呼吁下，近年来中国区域空间发展战略逐渐明确调整为“以中心城市为引领，以培育都市圈为突破口，以城市群为主体，以城市群带动区域发展，对中小城市分类施策”。</span></span></p><p><span><strong><span>过去中国城市化发展很快，城市治理能力未能跟上，导致不少城市、即便是小城市也面临大城市病，但除少数超大城市外的核心区域外，多数大城市的承载能力均还有较大提升空间。</span></strong><span>从理论上看，当城市从集聚经济转向集聚不经济时，产业和人口将自动外溢，使得城市单体规模面临上限；不过，城市承载力随着城市治理能力上升而提高，这意味着城市最优规模呈现动态变化。从国际比较看，部分超大城市的核心区域人口已趋于饱和。北京五环内、上海外环内土地面积分别为668、664平方公里，与首尔市、东京都区的606、622平方公里非常接近，这意味着人口密度具有较好的可比性。2015年北京五环内、上海外环内人口密度分别为15774人/平方公里、17056人/平方公里，而首尔市为15527人/平方公里（高峰曾达17500人/平方公里）、东京都区为14797人/平方公里。</span></span></p><p><span><strong><span>四是完善财政转移支付机制确保基本公共服务全覆盖，完善生态补偿机制确保受益者付费、保护者得到合理补偿。在转移支付方面，</span></strong><span>根据地区间财力差异状况，通过转移支付将常住人口人均基本公共服务支出差异控制在合理区间，特别是要对森林草原湿地等重点生态功能区、农产品主产区、困难地区提供足够转移支付。<strong>在生态补偿方面，</strong>要按照区际公平、权责对等原则，鼓励区际开展资金、产业、人才等多种补偿，加快建立健全市场化、多元化生态补偿机制。</span></span></p>
➜高层会议定调2021年经济工作，释放出五大信号，首提需求侧改革
https://www.gelonghui.com/p/432922	5437
<p>来源：半导体行业观察</p><p><span>对于GPU爱好者来说，这是一个漫长的等待。&nbsp;英伟达将Turing产品线维持了两年，然后在2020年9月用Ampere取代了它。AMD更友善一点，他们的新设计间隔了15个月，但大多数人对此并不感兴趣。</span></p><p><span>他们希望看到的是AMD推出一款高端机型，与英伟达(Nvidia)最优秀的产品展开正面竞争。他们做到了，现在我们已经看到了结果，在花钱买最好的图形卡时，PC游戏玩家现在（在理论上）有了很多选择。</span></p><p><span>但是驱动它们的芯片呢?其中一个从根本上来说比另一个好吗?继续读下去，看看Ampere和RDNA 2是如何决一死战的!</span></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p><span><strong><br></strong></span></p><h3 style="text-align: center;"><span><font color="#3daad6">Nvidia衰退，AMD成长</font></span></h3><p><span><strong><br></strong></span></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p><span><strong><span>节点和die尺寸</span></strong></span></p><p><span>多年来，高端GPU一直比 CPU大得多，而且它们的尺寸一直在稳步增长。AMD最新推出的Navi芯片面积约为520mm2，是之前Navi芯片的两倍多。不过，这并不是他们最大的——这项荣誉颁给了他们的Instinct MI100加速器（约750 mm2）中的GPU。</span></p><p><span>上一次AMD制造的接近Navi 21大小的游戏处理器是为Radeon R9 Fury和Nano显卡设计的，这两款产品在Fiji 芯片上采用了GCN 3.0架构。它的裸片面积为596 mm2，但它是在台积电的28HP工艺节点上生产的。</span></p><p><span>自2018年以来，AMD一直在使用台积电更小的N7工艺，该生产线生产的最大芯片是Vega 20 (Radeon VII)，面积为331mm2。他们所有的Navi gpu都是在略微升级的N7P处理器上制作的，所以可以比较这些产品。</span></p><p><img src="https://img3.gelonghui.com/850c0-95df7ecf-f030-4038-99b9-be6c0148fa6b.png"></p><p><span><em><span>Radeon R9 Nano：微型卡，大型GPU</span></em></span></p><p><span>但说到纯粹的die尺寸，英伟达拿下了王冠，并不是说这一定是件好事。最新的基于Ampere的芯片，GA102，是628mm2。这实际上比它的前身TU102小了17%——GPU面积达到惊人的754mm2。</span></p><p><span>与Nvidia巨大的GA100芯片(用于AI和数据中心)相比，这两款芯片的尺寸都相形见绌，其GPU为826 mm2，采用的是台积电的N7芯片。虽然它从来没有被设计用来驱动桌面显卡，但它确实显示了GPU制造的可能规模。</span></p><p><span>把它们放在一起突出了Nvidia最大的GPU有多大。Navi 21看起来相当苗条，尽管处理器的功能不仅仅是芯片区。GA102封装了283亿个晶体管，而AMD的新芯片减少了5%，达到268亿个。</span></p><p><img src="https://img3.gelonghui.com/a72d1-fd7243c0-e635-4b37-b741-edee942d1d90.png"></p><p><span>我们不知道每个GPU构建多少层，因此我们所能比较的是晶体管与die面积的比率，通常称为die密度。Navi 21的晶体管约为每平方毫米5150万个晶体管，但GA102明显低于41.1，这可能是Nvidia的芯片堆叠程度比AMD的略高，但它更可能表示工艺节点。</span></p><p><span>如前所述，Navi 21是由台积电生产的，采用N7P生产方法，性能比N7略有提高;但在新产品GA102上，英伟达求助于三星来完成生产任务。这家韩国半导体巨头正在使用他们所谓的8nm节点(标记为8N或8NN)的改良版本，专门为Nvidia设计。</span></p><p><span><b>这些节点值，7和8，与芯片组件的实际尺寸没有多大关系:它们只是市场营销术语，用于区分不同的生产技术。也就是说，即使GA102比Navi 21有更多的层，die尺寸确实有一个特殊的影响。</b></span></p><p><img src="https://img3.gelonghui.com/1bfb4-7103e169-1363-4aa4-a803-3a1bd2ec6f5a.png"></p><p><span>一台300毫米(12英寸)的晶圆片正在台积电的制造工厂进行测试。</span></p><p><span>微处理器和其他芯片是由高度精炼的硅和其他材料制成的大圆盘，称为晶圆。台积电和三星为AMD和Nvidia使用的是300毫米晶圆，相对于更大的die，使用更小的die，每块晶圆将产生更多的芯片。</span></p><p><span>这种差异不可能很大，但是在降低制造成本方面，当每片晶圆的生产成本达到数千美元时，AMD相对于Nvidia而言优势较小。&nbsp;当然，这是假设三星或台积电没有与AMD / Nvidia进行某种财务交易。</span></p><p><b>如果芯片本身不能很好地完成设计工作，那么所有这些die尺寸和晶体管数量都将是徒劳的。</b>&nbsp;因此，让我们深入研究每个新GPU的布局，看看它们背后的东西。</p><p><span><br></span></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><h3 style="text-align: center;"><strong style="font-style: inherit;"><font color="#3daad6">剖析die</font></strong></h3><p><strong style="font-style: inherit;"><br></strong></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p><span><strong><span>Ampere GA102和RDNA 2 Navi 21的总体架构</span></strong></span></p><p><span>我们从分析Ampere GA102和RDNA 2 Navi 21 GPU的总体架构开始我们对架构的探索——这些图表不一定向我们展示所有的物理布局，但它们给出了处理器有多少组件的明确指示。</span></p><p><span>在这两种情况下，布局都是非常熟悉的，因为它们基本上都是其前身的扩展版本。在处理指令中添加更多的单元将始终提高GPU的性能，因为在最新的3D大片中，在高分辨率下，渲染工作量涉及大量的并行计算。</span></p><p><img src="https://img3.gelonghui.com/19085-6c9aaf34-9fae-4014-bed3-05fe18a8c0c1.png"></p><p><span>这样的图表是有用的，但是对于这个特定的分析来说，更有趣的是看看各个组件在GPU中的位置。在设计大型处理器时，您通常希望共享资源（如控制器和缓存）位于中心位置，以确保每个组件都具有相同的路径。</span></p><p><span>接口系统，如本地内存控制器或视频输出，应该安装在芯片的边缘，以便更容易地将它们连接到连接GPU和显卡其余部分的数千根单独的电线上。</span></p><p><span>以下是AMD的Navi 21和Nvidia的GA102 die的伪彩色图像。&nbsp;它们实际上只显示了芯片中的一层；但它们确实给我们提供了一个现代GPU内部的极好视图。</span></p><p><img src="https://img3.gelonghui.com/54731-7fbf931a-e0d4-4ad0-8450-4904ecfd2a64.png"></p><p><span>两种设计之间最明显的区别在于，Nvidia在芯片布局上没有遵循集中化的方法——所有的系统控制器和主缓存都在底部，逻辑单元以长列形式运行。他们过去也这样做过，但只针对中低端机型。</span></p><p><span>例如，Pascal GP106（用于GeForce GTX 1060等）实际上是GP104（来自GeForce GTX 1070）的一半。&nbsp;后者是较大的芯片，其缓存和控制器位于中间。&nbsp;这些都移到了它的兄弟姐妹那一边，但这只是因为设计已经被拆分了。</span></p><p><img src="https://img3.gelonghui.com/4a08b-fb5b25c2-5b3e-4c85-aa6a-a5fc8b6cac0d.png"></p><p><span><em><span>Pascal GP104和GP106 资料来源：Fritzchens Fritz</span></em></span></p><p><span>对于之前所有的高端GPU布局，Nvidia都使用了经典的集中式结构。为什么这里会有变化呢?这不可能是由于接口的原因，因为内存控制器和PCI Express系统都运行在die的边缘。</span></p><p><span>这也不是出于热学原因，因为即使die 的缓存/控制器部分比逻辑部分的温度更高，您仍然希望在其中间具有更多的硅以帮助吸收和散发热量 。尽管我们不能完全确定更改的原因，但我们怀疑这与Nvidia对芯片中ROP（渲染输出）单元实施的更改有关。</span></p><p><span>我们将在后面更详细地讨论它们，但是现在让我们说，虽然布局的改变看起来很奇怪，但它不会对性能产生显着的影响。这是因为3D渲染充斥着许多长时间的延迟，通常是由于必须等待数据。因此，由于一些逻辑单元比其他逻辑单元离缓存更远而增加的纳秒数，都被隐藏在了整个系统中。</span></p><p><span>在我们继续之前，值得注意的是AMD在Navi 21布局中实施的工程改变，与驱动类似Radeon rx5700 XT的Navi 10相比。尽管新芯片在面积和晶体管数量上都比之前的芯片大了一倍，但设计者还设法在不显着增加功耗的情况下提高了时钟速度。</span></p><p><span>例如，Radeon RX 6800 XT运动的基时钟和升压时钟分别为1825和2250mhz, TDP为300 W;Radeon RX 5700 XT的相同性能为1605 MHz、1905 MHz和225 W。英伟达也通过Ampere提高了时钟速度，但部分原因是使用了更小、更高效的进程节点。</span></p><p><img src="https://img3.gelonghui.com/3798b-a08968e4-a066-4e43-ac63-dfeefe374fa4.png"></p><p><span>我们对Ampere和RDNA 2显卡的每瓦特性能检查显示，两家供应商在这方面都取得了显着的改进，但AMD和台积电取得了一些相当显着的成就——比较上图中Radeon RX 6800和Radeon VII之间的差异。</span></p><p><span>后者是他们首次使用N7节点进行GPU合作，并且在不到两年的时间内，他们将每瓦性能提高了64％。的确，如果英伟达继续与台积电合作，那Ampere GA102的性能会好得多。</span></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p><span><strong><br></strong></span></p><h3 style="text-align: center;"><span><strong><font color="#3daad6">管理GPU工厂</font></strong></span></h3><p><span><strong><br></strong></span></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p><strong><span>芯片内部的一切组织方式</span></strong></p><p><span>当涉及到指令处理和数据传输管理时，Ampere和RDNA2都遵循类似的模式来组织芯片内部的一切。游戏开发人员使用图形API编写标题，以制作所有图像；它可能是Direct3D、OpenGL或Vulkan。这些基本上是软件库，充满了规则、结构和简化指令的“书籍”。</span></p><p><span>AMD和Nvidia为他们的芯片创建的驱动程序本质上起着翻译的作用:将通过API发布的例程转换为GPU能够理解的操作序列。在那之后，就完全由硬件来管理了，比如什么指令首先执行，芯片的哪个部分执行这些指令，等等。</span></p><p><span>指令管理的初始阶段由合理地集中在芯片中的一组单元处理。在RDNA 2中，图形和计算着色器通过单独的管线进行路由，这些管线将指令调度并分派到芯片的其余部分。前者称为图形命令处理器，后者是异步计算引擎（ACE）。</span></p><p><img src="https://img3.gelonghui.com/2e931-4baf716c-d40f-4e08-8551-e55d57105238.png"></p><p><span>Nvidia只是用一个名字来描述他们的一组管理单元，即GigaThread Engine，在Ampere中它执行与RDNA 2相同的任务，尽管Nvidia并未过多说明其实际管理方式。总之，这些命令处理器的功能类似于工厂的生产经理。</span></p><p><span>GPU通过并行执行所有操作来获得性能，因此在整个芯片上复制了下一个组织层次。坚持工厂的类比，这类似于一家拥有中央办公室但在多个地点生产商品的企业。</span></p><p><span>AMD使用标签着色器引擎（SE），而Nvidia则称其为图形处理集群（GPC）-不同的名称，相同的角色。</span></p><p><img src="https://img3.gelonghui.com/df23b-53de0375-51a5-4bfb-81b2-1115fc9bcbb2.png"></p><p><span>对芯片进行这种分区的原因很简单：命令处理单元不能处理所有事情，因为它最终会变得过于庞大和复杂。因此，将一些日程安排和组织职责进一步向下推进是有意义的。这也意味着每个分离分区可以完全独立于其他分区执行某些操作，因此一个分区可以处理大量的图形着色器，而其他分区则在处理长而复杂的计算着色器。</span></p><p><span>在RDNA 2的例子中，每个SE都有自己一套固定的功能单元:被设计用来完成一项特定任务的电路，程序员通常无法对其进行大量调整。</span></p><ul><li><blockquote><b><span>mitive Setup unit——获取顶点，准备好进行处理，同时生成更多的顶点(essellation)并将其剔除<br></span><span>Rasterizer——将三角形的3D世界转换为像素的2D网格<br></span><span>Render Outputs(ROPs)——读取、写入和混合像素</span></b></blockquote></li></ul><p><span>原始的设置单元以每个时钟周期1个三角形的速率运行。这听起来可能不是很多，但是不要忘记这些芯片运行在1.8到2.2 GHz之间，所以原始的设置不应该成为GPU的瓶颈。对Ampere来说，原始单位是在组织的下一层找到的，我们很快就会讲到。</span></p><p><span>AMD和Nvidia都没有过多提及他们的光栅化器。后者称为光栅引擎，我们知道它们每个时钟周期处理一个三角形，并输出若干像素，但没有进一步的信息，例如它们的亚像素精度。</span></p><p><span>Navi 21芯片中的每个SE都有4组8个ROP，总共产生128个渲染输出单元；Nvidia的GA102每GPC包含2组8个ROP，因此整个芯片可运动112个ROP。这看起来AMD在这方面有优势，因为更多的ROP意味着每个时钟可以处理更多的像素。但是这样的单元需要对缓存和本地内存的良好访问，我们将在本文后面详细介绍。现在，让我们继续研究SE/GPC分区是如何进一步划分的。</span></p><p><img src="https://img3.gelonghui.com/7d2d9-be608209-e50f-413a-a778-e1cb47273c33.png"></p><p><span>AMD的着色引擎被划分为双计算单元（DCU），Navi 21芯片本身就有10个DCU——请注意，在一些文档中，它们也被归类为工作组处理器（WGP）。在Ampere和GA102的例子中，它们被称为纹理处理簇（TPC），每个GPU包含6个tpc。Nvidia设计的每一个集群都有一个叫做“变形引擎”的东西——本质上是Ampere的原始设置单元。</span></p><p><span>Nvidia也以每时钟1个三角形的速度运行，尽管Nvidia的GPU比AMD的低，但他们的TPC数量比Navi 21的SE要多得多。因此，对于相同的时钟速度，GA102应该有一个显着的优势，因为完整的芯片拥有42个原始设置单元，而AMD的新RDNA 2只有4个。但由于每个光栅引擎有6个TPC, GA102实际上有7个完整的原始系统，而Navi 21有4个。由于后者的时钟并没有比前者高75%，当涉及到几何处理(尽管没有游戏可能在这方面受到限制)时，似乎英伟达在这方面具有明显的领先优势。</span></p><p><span>芯片组织的最后一层是RDNA 2中的计算单元（CU）和Ampere中的流式多处理器（SM），这是我们GPU工厂的生产线。</span></p><p><img src="https://img3.gelonghui.com/ba7a6-153883d4-56af-4081-82c3-47d950e11b49.png"></p><p><span>这些是图形处理器馅饼中的肉和蔬菜，因为它们拥有所有用于处理图形、计算和现在的光线追踪着色器的高度可编程单元。正如你在上图中看到的，每一个芯片都只占整个芯片空间的很小一部分，但是它们仍然是非常复杂的，并且对芯片的整体性能非常重要。</span></p><p><span>到目前为止，在两个GPU的布局和组织方式方面，还没有什么真正的突破性协议。术语全都不同，但是它们的功能却大同小异。而且由于它们所做的很多事情都受可编程性和灵活性的限制，因此一个相对于另一个所具有的任何优势，都只能归结为规模感，即哪个拥有最大的特色。</span></p><p><span>但是对于CU和SM，AMD和Nvidia采取了不同的方式来处理着色器。在某些领域，它们有很多共同点，但在其他许多领域则并非如此。</span></p><p><span><br></span></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><h3 style="text-align: center;"><font color="#3daad6">计数核心是Nvidia的方式</font></h3><p><strong><br></strong></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p><span>由于安培（Ampere）在RDNA 2之前就冒险进入野外，我们首先来看看Nvidia的SM。现在没有必要查看裸片本身的图像，因为它们无法准确告诉我们其中的内容，因此让我们使用组织图。这些不应该代表芯片中各种组件的物理排列方式，而只是每种类型中存在多少种。</span></p><p><span>图灵对其台式机前身Pascal进行了实质性更改（去掉了一堆FP64单元和寄存器，但是增加了张量核和光线跟踪），而Ampere实际上是一个相当温和的更新-至少从表面上看。不过，就Nvidia的市场部门而言，新设计使每个SM中CUDA内核的数量增加了一倍以上。</span></p><p><img src="https://img3.gelonghui.com/48a83-110d07a1-20fb-4a9f-ad83-87b15f503ac8.png"></p><p><span>在图灵中，流多处理器包含四个分区（有时称为处理块），每个分区中容纳16个INT32和16x FP32逻辑单元。这些电路旨在对32位数据值执行非常具体的数学运算：INT单位处理整数，而FP单位处理浮点数（即十进制）。</span></p><p><span>英伟达表示，一个Ampere SM总共有128个CUDA内核，但严格来说，这是不正确的-或者，如果我们必须坚持这一点，那么图灵（Turing）也是如此。该芯片中的INT32单元实际上可以处理浮点值，但只能以非常少量的简单操作进行。对于Ampere，Nvidia已开放了它们支持的浮点数学运算范围，以匹配其他FP32单元。这意味着每个SM的CUDA内核总数并没有真正改变。只是其中的一半现在拥有更多功能。</span></p><p><span>每个SM分区中的所有内核都可以随时处理同一条指令，但是由于INT / FP单元可以独立运行，因此Ampere SM每个周期最多可以处理128x FP32计算，或一起处理64x FP32和64x INT32操作。而图灵只是后者。</span></p><p><span>因此，新的GPU可能使FP32的输出量比其上一代产品大一倍。对于计算工作负载，尤其是在专业应用程序中，这是向前迈出的一大步。但是对于游戏而言，优势却远远没有达到预期。当我们首次测试GeForce RTX 3080时，这一点很明显，它使用启用了68个SM的GA102芯片。</span></p><p><img src="https://img3.gelonghui.com/dc3d0-87f8a734-399c-499d-a2c3-d65175568cb3.png"></p><p><span>尽管FP32的峰值吞吐量比GeForce 2080 Ti高出121％，但平均帧速率仅提高了31％。那么，为什么所有这些计算能力都会浪费掉呢？一个简单的答案是，游戏并非一直在运行FP32指令。</span></p><p><span>当Nvidia在2018年发布Turing时，他们指出， GPU处理的指令平均约有36％涉及INT32例程。这些计算通常用于计算内存地址，两个值之间的比较以及逻辑流/控制。</span></p><p><img src="https://img3.gelonghui.com/bd691-4807231e-7a45-4da1-8637-e4b1e44765b8.png"></p><p><span>因此，对于这些操作，双速率FP32功能不起作用，因为具有两个数据路径的单元只能执行整数或浮点运算。而且，只有在当时由它处理的所有32个线程都排队处理相同的FP32操作时，SM分区才会切换到此模式。在所有其他情况下，安培中的分区与图灵中的分区一样运行。</span></p><p><span>这意味着在INT + FP模式下运行时，GeForce RTX 3080之类的FP32仅比2080 Ti具有11％的FP32优势。这就是为什么在游戏中看到的实际性能提升没有原始数据所预期的那么高的原因。</span></p><p><span>至于其他改进。每个SM分区的Tensor Core更少，但每个都比Turing中的功能强大得多。这些电路执行非常具体的计算（例如将两个FP16值相乘并用另一个FP16编号累加答案），每个内核现在每个周期执行32次这些操作。</span></p><p><img src="https://img3.gelonghui.com/c1132-2fa87f55-2db2-458f-9533-c215c16f6265.png"></p><p><span>它们还支持一种名为“细粒度结构稀疏性”的新特性，在不涉及所有细节的情况下，这意味着通过剔除那些对答案没有影响的数据，计算率可以翻倍。同样，这对于从事神经网络和人工智能工作的专业人员来说是个好消息，但目前对游戏开发者来说并没有什么明显的好处。</span></p><p><span>光线跟踪核心也已进行了调整：它们现在可以独立于CUDA核心工作，因此，在进行BVH遍历或光线原始相交数学时，SM的其余部分仍可以处理着色器。处理射线是否与原语相交测试的RT核心的部分性能也增加了一倍。</span></p><p><img src="https://img3.gelonghui.com/782a4-a67f5d50-830a-42d3-b1a3-14434a4fe59c.png"></p><p><span>RT内核还具有附加的硬件，可帮助将光线跟踪应用于运动模煳，但是此功能目前仅通过Nvidia专有的Optix API公开。</span></p><p><span>还有其他一些调整，但是整体方法是明智但稳定的演进之一，而不是主要的新设计。但是考虑到图灵的原始功能并没有什么特别的错误，因此看到这一点不足为奇。</span></p><p><span><b>那么AMD怎么办-他们对RDNA 2中的计算单元做了什么？</b></span></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p><strong><br></strong></p><h3 style="text-align: center;"><strong><font color="#3daad6">追寻美妙的光线</font></strong></h3><p><strong><br></strong></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p><span>从表面上看，AMD在计算单元方面并没有太大变化-它们仍然包含两组SIMD32向量单元，一个SISD标量单元，纹理单元以及各种缓存堆栈。关于它们可以执行的数据类型和相关的数学运算，已经发生了一些变化，我们稍后将详细介绍。对于普通消费者而言，最明显的变化是AMD现在为光线跟踪中的特定例程提供了硬件加速。</span></p><p><span>CU的这部分执行ray-box或ray-triangle交叉检查——与安培中的RT内核相同。然而，后者也加速了BVH遍历算法，而在RDNA 2，这是通过使用SIMD 32单元计算着色器来完成的。</span></p><p><img src="https://img3.gelonghui.com/3f402-baa67319-1c7b-4c27-af21-5f9611f9d2ec.png"></p><p><span>不管一个着色器内核有多少个，或者它们的时钟速率有多高，使用设计为仅完成一项工作的定制电路总是比通用方法更好。这就是为什么首先发明GPU的原因：渲染世界中的所有事物都可以使用CPU来完成，但是它们的通用性使其不适合于此。</span></p><p><span>RA单元紧邻纹理处理器，因为它们实际上是同一结构的一部分。早在2019年7月，我们就报道了AMD申请的一项专利的内容，该专利使用``混合''方法详细处理了光线追踪中的关键算法...</span></p><p><img src="https://img3.gelonghui.com/0ec1e-00ae6432-4b3a-4948-a735-3ddfcf345614.png"></p><p><span>尽管该系统确实提供了更大的灵活性，并且消除了当存在光线追踪工作量时裸片的一部分不做任何事情的需求，但AMD的第一个实现确实有一些缺点。最值得注意的是，纹理处理器在任何时候都只能处理涉及纹理或ray-primitive交点的操作。</span></p><p><span>鉴于Nvidia的RT核心现在完全独立于SM的其余部分而运行，与RNDA 2相比，在通过光线跟踪所需的加速结构和交叉测试进行磨削时，这似乎给Ampere带来了明显的领先优势。</span></p><p><span>尽管我们仅简要检查了AMD最新图形卡中的光线追踪性能，但到目前为止，我们确实发现使用光线追踪的影响很大程度上取决于所玩的游戏。</span></p><p><img src="https://img3.gelonghui.com/f3386-7adac69b-184a-45aa-8e05-9f620cb1bb04.png"></p><p><span>例如，在Gears 5中，Radeon RX 6800（使用Navi 21 GPU的60 CU变体）仅降低了17％的帧速率，而在《古墓丽影》的阴影中，平均损失达到52％ 。相比之下，英伟达的RTX 3080（使用68 SM GA102）在这两款游戏中的平均帧率损失分别为23％和40％。</span></p><p><span>需要对射线追踪进行更详细的分析来说明AMD的实现，但是作为该技术的第一个迭代，它看起来很有竞争力，但对应用程序正在进行的射线追踪很敏感。</span></p><p><span>如前所述，RDNA 2中的计算单元现在支持更多数据类型。最值得注意的是低精度数据类型，例如INT4和INT8。它们用于机器学习算法中的张量运算，而AMD具有用于AI和数据中心的单独架构（CDNA），但此更新适用于DirectML。</span></p><p><img src="https://img3.gelonghui.com/6c8a4-e04b3500-77e7-45f0-a583-180daca35447.png"></p><p><span>该API是Microsoft DirectX 12家族的最新成员，硬件和软件的组合将为光线跟踪和时间放大算法中的降噪提供更好的加速。对于后者，Nvidia当然拥有自己的名称，称为DLSS。他们的系统使用SM中的Tensor核心执行部分计算，但是鉴于可以通过DirectML构建类似的过程，因此这些单元似乎有些多余。但是，在Turing和Ampere中，Tensor核心还可以处理所有涉及FP16数据格式的数学运算。</span></p><p><span>对于RDNA 2，此类计算是使用着色器单元，使用打包数据格式完成的，即每个32位向量寄存器都包含两个16位寄存器。那么哪种方法更好呢？AMD将其SIMD32单元标记为矢量处理器，因为它们能针对多个数据值发出一条指令。</span></p><p><span>每个向量单元包含32个流处理器，由于每个流处理器只处理单个数据片段，因此实际操作本身是标量的。这本质上与安培中的SM分区相同，其中每个处理块还针对32个数据值携带一条指令。</span></p><p><span>但是，在Nvidia设计中的整个SM每个周期最多可以处理128个FP32 FMA计算（融合乘加）时，单个RDNA 2计算单元只能处理64个。在执行标准FP16数学时，使用FP16可以将其提高到每个周期128 FMA，这与Ampere的Tensor核心是一样的。</span></p><p><span>Nvidia的SM可以处理指令时可以同时处理整数和浮点值（例如64 FP32和64 INT32），并且具有用于FP16操作，张量数学和光线跟踪例程的独立单元。尽管AMD CU具有独立的支持简单整数数学的标量单元，但它们在SIMD32单元上承担了大部分工作量。</span></p><p><span>因此，安培似乎在这方面有优势:GA102比Navi 21拥有更多的CU，而且在峰值吞吐量、灵活性和提供的功能方面，它们的表现更出色。但是AMD有一个相当不错的锦囊妙计。</span></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p><strong>内存系统，多层缓存</strong></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p><span>拥有成千上万个逻辑单元的GPU，在复杂的数学运算中一路高歌勐进，这一切都很好，但是但如果他们不能足够快地提供所需的指令和数据，他们将在海量的数据中挣扎。这两种设计都拥有丰富的多级缓存，拥有巨大的带宽。</span></p><p><span>让我们来看看安培的。总体而言，内部发生了一些显着变化。2级缓存的数量增加了50％（图灵TU102的运动速度分别为4096 kB），并且每个SM中的1级缓存的大小都增加了一倍。</span></p><p><img src="https://img3.gelonghui.com/12b87-bdcf2fce-728d-4b38-9eda-58ef107ff081.png"></p><p><span>与以前一样，就可以为数据，纹理或一般计算用途分配多少缓存空间而言，Ampere的L1缓存是可配置的。但是，对于图形着色器（例如顶点，像素）和异步计算，缓存实际上设置为：</span></p><ul><li><p><span>64 kB用于数据和纹理</span></p></li><li><p><span>48 kB用于共享通用内存</span></p></li><li><p><span>16 kB保留用于特定操作</span></p></li></ul><p><span>只有在完全计算模式下运行时，L1才可以完全配置。从好的方面来说，可用带宽的数量也增加了一倍，因为缓存现在可以每个时钟读取/写入128个字节（尽管没有关于延迟是否得到改善的消息）。</span></p><p><span>内部存储器系统的其余部分在Ampere中保持不变，但是当我们仅移至GPU外部时，对于我们来说，这是一个很好的惊喜。Nvidia与DRAM制造商美光合作，将GDDR6的修改版本用于其本地内存需求。从本质上讲，它仍然是GDDR6，但数据总线已被完全替换。GDDR6X使用四个电压，而不是使用传统的每个引脚设置1位（信号只是在两个电压（又名PAM）之间快速反弹）设置的方式：</span></p><p><img src="https://img3.gelonghui.com/64d9a-879492bb-cf44-46de-9577-c6b1e8b73757.jpg"></p><p><span>进行此更改后，GDDR6X每个周期每个引脚有效传输2位数据-因此，对于相同的时钟速度和引脚数，带宽增加了一倍。GeForce RTX 3090具有24个GDDR6X模块，它们以单通道模式运行，额定速率为19 Gbps，提供的峰值传输带宽为936 GB / s。</span></p><p><span>与GeForce RTX 2080 Ti相比，这增加了52％，并且不能轻易忽视。过去仅通过使用类似HBM2的方式获得了这样的带宽数字，与GDDR6相比，HBM2的实现成本很高。</span></p><p><span>但是，只有Micron可以制造这种存储器，而PAM4的使用为生产过程增加了额外的复杂性，对信号的公差要严格得多。AMD走了一条不同的道路-他们没有寻求外部机构的帮助，而是利用其CPU部门为桌面带来了新的东西。与它的前代产品相比，RDNA 2中的整个内存系统没有太大变化，只有两个主要变化。</span></p><p><img src="https://img3.gelonghui.com/c0f61-1096dc6a-0b85-459c-9173-b701eca81636.png"></p><p><span>每个着色器引擎现在都有两组Level 1缓存，但是由于它们现在具有两组Dual Compute Unit（RDNA拥有一组），因此这种改变是可以预期的。但是将128 MB的3级缓存缓存到GPU中吗？这让很多人感到惊讶。利用其EPYC系列Zen 2服务器芯片中的L3高速缓存的SRAM设计，AMD在该芯片中嵌入了两组64 MB高密度高速缓存。数据事务由16组接口处理，每个接口每个时钟周期移位64个字节。</span></p><p><span>所谓的无限缓存具有其自己的时钟域，并且可以在1.94 GHz上运行，从而提供1986.6 GB / s的内部峰值传输带宽。而且由于它不是外部DRAM，因此涉及的延迟非常低。这种高速缓存非常适合存储光线跟踪加速结构，并且由于BVH遍历涉及大量数据检查，因此Infinity高速缓存应特别为此提供帮助。</span></p><p><img src="https://img3.gelonghui.com/0d4fc-002fae7f-f967-446b-9f48-a0fb64ec9c71.png"></p><p><span><em><span>两个64 MB的Infinity缓存条和Infinity Fabric系统</span></em></span></p><p><span>目前，尚不清楚RDNA 2中的3级缓存是否以与Zen 2 CPU中相同的方式运行：即作为2级victim缓存。通常，当需要清除最后一级的高速缓存以为新数据腾出空间时，对该信息的任何新请求都必须发送到DRAM。</span></p><p><span>victim缓存存储的数据已经被标记为要从下一层内存移除，并且有128MB的数据可用，Infinity缓存可能存储32个完整的L2缓存集。该系统的结果是，在GDDR6控制器和DRAM上放置的需求更少。</span></p><p><span>AMD的较旧GPU设计一直在缺乏内部带宽的情况下苦苦挣扎，尤其是当它们的时钟速度提高后，但是额外的缓存将使该问题逐渐消失。</span></p><p><img src="https://img3.gelonghui.com/0df17-64ba4f58-4366-42fe-a82a-9433bbb8e884.png"></p><p><span>那么，哪种设计更好呢？GDDR6X的使用为GA102提供了到本地内存的巨大带宽，并且更大的缓存将有助于减少缓存未命中（这会使线程的处理停滞）的影响。Navi 21的大型3级缓存意味着DRAM不必经常被窃听，并利用了以更高的时钟速度运行GPU的能力，而不会出现数据匮乏的情况。</span></p><p><span>AMD决定坚持使用GDDR6的决定意味着第三方供应商可以使用更多的内存，同时任何制造GeForce RTX 3080或3090的公司都必须使用美光。尽管GDDR6有多种模块密度，但GDDR6X当前限于8 Gb。</span></p><p><span>RDNA 2中的缓存系统可以说是比Ampere中使用的缓存系统更好的方法，因为与外部DRAM无关，使用多个级别的片上SRAM始终比外部DRAM提供更低的延迟和更好的性能（在给定的功率范围内）。</span></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p><span><strong><br></strong></span></p><h3 style="text-align: center;"><span><font color="#3daad6">GPU的来龙去脉</font></span></h3><p><span><strong><br></strong></span></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p><span><strong><span>渲染管线</span></strong></span></p><p><span>这两种架构都对渲染管线的前端和后端进行了大量更新。DirectX12 Ultimate中的Ampere和RDNA 2完全具有运动型网格着色器和可变速率着色器，但Nvidia的芯片具有更出色的几何性能，而这要归功于Nvidia用了更多的任务处理器。</span></p><p><span>尽管使用网格着色器可以使开发人员创建更加逼真的环境，但没有一款游戏的性能会完全以来于渲染过程中的这个阶段。因为大部分最难的工作是在像素或光线跟踪阶段。</span></p><p><img src="https://img3.gelonghui.com/2b20f-af4301e6-c82a-400e-88f6-59b15aac3f62.png"></p><p><span>这就是使用可变率着色器发挥作用的地方——基本上该过程涉及在一个像素块而不是单个像素上应用照明和颜色着色器。这类似于为了提高性能而降低游戏的分辨率，但由于它只能应用于选定的区域，因此视觉质量的损失并不明显。</span></p><p><span>无论是否使用可变速率着色器，这两种体系结构都已更新了其渲染输出单元（ROP），这将提高在高分辨率下的性能。在所有以前的GPU中，Nvidia都将ROPs与内存控制器和二级缓存绑定在一起。</span></p><p><span>在Turing中，8个ROP单元(统称为一个分区)会直接链接到一个控制器和一个512kb的高速缓存上。添加更多的ROP会带来问题，因为它需要更多的控制器和缓存，因此对于Ampere而言，现在ROP已完全分配给了GPC。GA102每个GPC拥有12个ROP（每个时钟周期处理1个像素），整个芯片共有112个单位。</span></p><p><span>AMD采用了与Nvidia的旧方法类似的系统（即与内存控制器和L2缓存片绑定），尽管它们的ROP主要使用1级缓存进行像素读/写和混合。在Navi 21芯片中，已经为它们提供了急需的更新，并且每个ROP分区现在每个周期以32位颜色处理8个像素，并以64位处理4个像素。</span></p><p><span>Nvidia还为Ampere带来了RTX IO，这是一种数据处理系统，可以让GPU直接访问存储驱动器，复制所需的数据，然后使用CUDA内核解压。但是，目前该系统不能在任何游戏中使用，因为Nvidia正在使用DirectStorage API（另一种DirectX12增强功能）来控制它，并且尚未准备好公开发布。</span></p><p><img src="https://img3.gelonghui.com/da8b2-eed23240-6bbd-4656-b14b-084e1aef052d.png"></p><p><span>目前使用的方法包括让CPU管理所有这一切：它接收来自GPU驱动程序的数据请求，将数据从存储驱动器复制到系统内存中，进行解压缩，然后再复制到图形卡的DRAM中。</span></p><p><span>除了涉及大量浪费的复制之外，这种机制在本质上是串行的——CPU一次只能处理一个请求。Nvidia声称可以达到“100倍的数据吞吐量”和“20倍的CPU利用率低”，但是在系统能够在现实世界中测试之前，并不能证明它能够实现这种效果。</span></p><p><img src="https://img3.gelonghui.com/d04a8-6eb14cdd-a0cd-4050-85e7-a3bc06a35bd6.png"></p><p><span>当AMD推出RDNA 2和新的Radeon RX 6000图形卡时，他们推出了称为Smart Access Memory的产品。这不是他们对Nvidia的RTX IO的答案——实际上，它甚至不是真正的新功能。默认情况下，每个单独的访问请求中，CPU中的PCI Express控制器最多可以寻址256 MB的图形卡内存。</span></p><p><span>此值由基址寄存器（BAR）的大小设置，并且早在2008年，PCI Express 2.0规范中就有一项可选功能，可以调整其大小。这样做的好处是，只需处理较少的访问请求即可访问整个卡的DRAM。</span></p><p><span>该功能需要操作系统，CPU，主板，GPU及其驱动程序的支持。当前，在Windows PC上，系统仅限于Ryzen 5000 CPU，500系列主板和Radeon RX 6000图形卡的特定组合。</span></p><p><img src="https://img3.gelonghui.com/cc862-42fc9a2e-34d3-4e06-97c5-b729d462d2d1.png"></p><p><span>测试时，这个简单的功能给出了一些令人吃惊的结果——在4K环境下将性能提升15%是不容小觑的，所以英伟达表示他们将在不久的将来为RTX 3000范围提供这个特性也就不足为奇了。</span></p><p><span>是否可调整大小的BAR支持是否适用于其他平台组合还有待观察，但是它的使用无疑是受欢迎的，即使它不是Ampere / RDNA 2的体系结构功能。</span></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p><span><strong>视频取代了广播</strong></span></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p><span><strong><span>多媒体引擎，视频输出</span></strong></span></p><p><span>GPU世界通常由核心访问量、TFLOPS、GB/s和一些其他指标为主导，由于YouTube内容创造者和直播游戏流的崛起，使得市场开始注意GPU的显示和多媒体引擎的能力。</span></p><p><span>随着支持此类功能的显示器价格的下降，对所有分辨率下的超高刷新率的需求也在增长。两年前，一台144 Hz 4K 27”的HDR显示器要花你2000美元;今天，你可以用几乎一半的价格买到类似的东西。</span></p><p><span>两种架构均通过HDMI 2.1和DisplayPort 1.4a提供显示输出。前者提供了更多的信号带宽，但是在HDR和240 Hz时，它们的额定频率均为4K，在60 Hz时，其额定值为8K。这是通过使用4：2：0色度二次采样或DSC 1.2a实现的。这些是视频信号压缩算法，可显着减少带宽需求，而不会损失太多的视觉质量。如果没有它们，即使HDMI 2.1的峰值带宽为6gb /s，也不足以以6hz的速率传输4K图像。</span></p><p><img src="https://img3.gelonghui.com/50b90-a670fb0c-e9b2-48f8-b011-d22856ec5135.png"></p><p><span><em><span>48英寸LG CK OLED'显示器'-120 Hz时的4K需要HDMI 2.1</span></em></span></p><p><span>Ampere和RDNA 2还支持可变刷新率系统（用于AMD的FreeSync，用于Nvidia的G-Sync），在视频信号的编码和解码方面，也没有明显的区别。</span></p><p><span>无论您使用哪种处理器，您都会发现对8K AV1、4K H.264和8K H.265解码的支持，尽管它们在这种情况下的性能究竟如何还没有得到彻底的研究。两家公司都没有详细说明他们的显示和多媒体引擎的内部结构。尽管它们很重要，但GPU的其余部分依旧值得关注。</span></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p><span><strong><br></strong></span></p><h3 style="text-align: center;"><span><strong><font color="#3daad6">不同的策略</font></strong></span></h3><p><span><strong><br></strong></span></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p><span><strong><span>为计算而生，还是为游戏而生</span></strong></span></p><p><span>GPU历史的爱好者将知道AMD和Nvidia过去在架构选择和配置上采用了截然不同的方法。但是，随着3D图形越来越受到计算世界和API的同质化的支配，它们的总体设计也越来越相似。</span></p><p><span>如今的游戏并不是以渲染需求为架构定下基调，GPU产业已经扩展到的市场领域才是引领方向。在撰写本文时，Nvidia有三种使用Ampere 技术的芯片:GA100、GA102和GA104。</span></p><p><span>最后一个只是GA102的精简版——每个GPC拥有的TPC更少（整体GPU更少），而二级缓存则只有三分之二。其他所有内容都完全相同。而GA100则是与此完全不同的产品。</span></p><p><span>GA100没有RT核，也没有INT32 + FP32支持的CUDA核。相反，它打包了许多额外的FP64单元，更多的加载/存储系统以及大量的L1 / L2缓存。它也没有显示器或多媒体引擎。这是因为它完全是为用于AI和数据分析的大规模计算集群而设计的。</span></p><p><span>从应用场景上看，GA102/104需要覆盖Nvidia瞄准市场是:游戏爱好者、专业图形艺术家和工程师，以及小规模的人工智能和计算工作。Ampere则想要成为“万事通”，并且能够精通所有行业，但这可不是一件容易的事。</span></p><p><img src="https://img3.gelonghui.com/86eba-49294054-76b0-4157-8a13-992c9c643b9c.png"></p><p><span><em><span>750平方毫米的Arcturus CDNA</span></em></span></p><p><span>RDNA 2专为PC和游戏机上的游戏而设计，尽管它可以转向与Ampere相同的应用市场。然而，AMD选择继续他们的GCN架构，并更新它，以满足今天的专业客户的需求。</span></p><p><span>RDNA 2产生了“ Big Navi”，而CDNA产生了“ Big Vega”-Instinct MI100装有Arcturus芯片，这是一个拥有128个计算单元的500亿晶体管GPU。与Nvidia的GA100一样，它也不包含显示器或多媒体引擎。</span></p><p><span>尽管英伟达凭借Quadro和特斯拉(Tesla)等在专业市场占据了主导地位，但Navi 21之类的产品并非旨在与之抗衡，而是进行了相应的设计。这是否会使RDNA 2成为更好的结构体系; Ampere 适应多种市场的要求是否在限制了它的发展?</span></p><p><span>当您查看证据时，答案似乎是：不。</span></p><p><img src="https://img3.gelonghui.com/4cda0-2dfd0bbe-5ff9-4af6-b840-b294490b05aa.png"></p><p><span>AMD将很快发布Radeon RX 6900 XT，它使用了完整的Navi 21(没有禁用CUs)，其性能可能与GeForce RTX 3090或更好。但是那张卡上的GA102也没有被完全释放，所以Nvidia总是可以选择升级到一个“超级”版本，就像他们去年对 Turing所做的那样。</span></p><p><span>可能有人会说，因为RDNA 2被用在Xbox系列X/S和PlayStation 5中，游戏开发者会倾向于将这种架构用于他们的游戏引擎。但是，您只需要查看在Xbox One和PlayStation 4中使用了GCN的时间，便可以了解这种情况如何发挥作用。</span></p><p><span>前者在2013年的第一次发布中使用了基于GCN 1.0架构的GPU——这种设计直到第二年才出现在桌面PC图形卡中。2017年发布的Xbox One X使用的是GCN 2.0，这是一个已经使用了3年多的成熟设计。</span></p><p><span>那么，所有为Xbox One或PS4制作的游戏，只要移植到PC上，就能在AMD显卡上运行得更好吗?实际上，并没有。因此，尽管RDNA 2具有令人印象深刻的功能，但我们不能认为该产品会与RDNA 2有所不同。</span></p><p><span>但这些最终都无关紧要，因为这两种GPU设计都具有非凡的能力，是半导体制造领域的奇迹。英伟达和AMD带来了不同的工具，因为他们都在试图解决不同的问题;Ampere的目标是面向所有人，RDNA 2主要是关于游戏的。</span></p><p><span>这一次，战斗陷入了僵局，尽管双方都可以在特定的一两个区域宣告胜利。GPU之战将持续到明年，一个新的竞争者将加入这场战斗：英特尔的Xe系列芯片。在不久的将来，我们就能看到这场战斗的结果了!</span></p><p></p><p></p><p></p><p></p><p></p>
➜李奇霖：什么是需求侧改革？
https://www.gelonghui.com/p/432930	14213
<p><strong>作者：李奇霖 张德礼 聂政 孙永乐</strong><br></p><p><font color="#363636" style="">来源：</font>奇霖宏观</p><p><span>每年12月政治局会议，承上启下，总结经济工作成绩，部署下一个阶段的重点工作。今年是“十三五”规划收官之年，明年又是新一个五年的开始，这次会议所部署工作的时间跨度自然也会长一些，有不少新提法。</span></p><p><span><strong><span>我们这篇文章，聚焦在“需求侧改革”上。</span></strong></span><span>需求侧管理、加大逆周期调节这些提法，大家都耳熟能详了，但在政治局会议层面上，提“注重需求侧改革”，应该是首次。</span></p><p><span>回想下2015年年底提出供给侧结构性改革时，一开始市场并没有很在意，因为觉得不容易落地。但后来的实际行动，却超出了大家的预料，去产能、上游商品价格暴涨，还记忆犹新。如果没有疫情的外生性冲击，“三去一降一补”这几个重点任务，其实都取得了不小成效。</span></p><p><span><strong><span>既然供给侧结构性改革取得了成效，工作重点就可以向需求侧改革这边转移了。</span></strong></span><span>2016年以来的经验也告诉我们，后续可能会出台不少需求侧改革的政策，不能忽视它。虽然说政策效果可能没有供给侧结构性改革那么立竿见影，但大方向是确定的，也不要低估它对经济和市场的影响。</span></p><p><span>那问题来了，为什么现在要搞需求侧改革呢？具体会怎么搞？</span></p><p><span><strong><span>从需求侧管理到需求侧改革，是因为很多传统的做法，到了现在这个阶段，再去大力推，产出投入比不高了，还会增加潜在的风险，综合来看并不划算。</span></strong></span></p><p><span>和欧美国家相比，中国人不爱超前消费，但有买房的传统。实体部门加杠杆，以及以前常说的逆周期调节和需求侧管理，大多是围绕土地产业链来做文章的。</span></p><p><span>这些年房价上涨幅度，是远大于CPI这些物价指标所显示的通货膨胀程度的，也比收入上涨得更快。虽然说工资也在涨，但占社会大多数的工薪阶层，尤其是需要买房的那种，幸福感并没有和工资同比例增长，甚至有些人觉得生活更难了。周小川行长最近发表的那篇央行政策研究文章，其实也提到了这些。</span></p><p><span>房价涨了，而且比收入涨得更快，这意味上车晚的人，就得多贷款了。所以每一次地产调控放松，后面都会跟着出现居民杠杆率的上升。</span></p><p><span><strong><span>上涨的房价，不光让居民加杠杆，也会让企业和地方政府加杠杆。</span></strong></span></p><p><span>对企业来说，房价涨意味着地价涨，租金、原材料和人工成本都会跟着涨。把房价考虑进去后的实际通胀处在高位，企业不给工人涨工资工人不干，购买的原材料也会涨价，因为这些生产原材料的企业也会面临着同样的问题。在经济向上的时候还好，一旦需求不行了，盈利放缓甚至出现亏损时，或者需要扩大投资时，企业需要举借债务的规模，显然是要比各类生产要素价格都比较低时所需的借债规模要大得多。</span></p><p><span>对地方政府来说，在以GDP为纲的时代，房价上涨除了能给地方政府带来更多的卖地收入外，还让土地成为一个很好的抵押品。地方政府有做大GDP的冲动，手里又握有土地这个跟着房价一起上涨的抵押品，在地方债务监管不严的时候，还能给城投这些主体的融资提供隐性担保，金融机构也愿意跟它们合作，结果就是地方隐性债务激增。</span></p><p><span>缺少严监管，地方债务问题在道德风险下是难以避免的。地方政府追逐GDP，只要能把债务问题隐藏，或者让显性的风险能够最小化就够了。</span></p><p><span><strong><span>但房子不能涨到天上去。之前涨了这么多，负面效应就已经很明显了，最突出的有两点。</span></strong></span></p><p><span><strong><span>一个是金融风险积累。</span></strong></span><span>实体部门的杠杆率高了以后，还本付息的压力就会更大，也更依赖外部融资。一旦经济出现大的波动影响收入，比如今年的新冠疫情，居民和企业偿债负担就陡增。高杠杆也延缓了宽松退出的节奏，因为一旦快速退出，就不得不面临信用违约冲击。</span></p><p><span><strong><span>另一个是贫富差距扩大。</span></strong></span><span>手里有多套房，或者买房早的人，就能坐享房价上涨带来的资产增值。而买房晚的人，尤其是在高房价的一二线城市，需要付出更多的成本来买房，要么是攒钱存首付，要么是削减支出来还房贷。一旦房价涨得快，对很多没有房产的人来说，很可能就是好几年白干了。</span></p><p><span>房价上涨，尤其是二手房涨价，本质上是在居民内部转移财富。当收入跑不赢房价的时候，就是富者越富、贫者越贫。这也会映射到消费上，今年疫情之后，奢侈品消费是要比大众消费更早恢复的。</span></p><p><span>所以不能再靠地产产业链来拉动需求的老路了，构建和畅通内循环体系，更是需要摆脱对地产的依赖。这就是提出“需求侧改革”的大背景。</span></p><p><span><strong><span>那具体怎么开展需求侧改革呢？</span></strong></span></p><p><span><strong><span>我们认为，肯定是会把扩大内需作为基本战略的，需求侧改革并不意味着不需要调节总需求了，只是着力点和之前不一样，从投资转向了消费。</span></strong></span></p><p><span>促消费，本质上和共同富裕的要求是相一致的，因为庞大的中等收入群体才是不断消费的源泉。首当其冲要做的就是坚持“房住不炒”，不能再让房价上涨来扩大贫富差距了，一部分人坐拥房产升值，而更多的人要凑房贷和还贷款，这样的组合是很难形成大规模消费市场的。</span></p><p><span><strong><span>对资本的监管也会加强，防止资本无节制做大。</span></strong></span><span>资本无节制做大，除了通过上市实现资产增值、继续扩大贫富差距外，还在于资本做大后，借助所投资的机构，触角伸得太长、太多。</span></p><p><span>一些靠互联网起家的科技企业，利用它们的渠道优势，不断投资和拓展新业务。很多业务其实是很传统的，只不过披上了互联网的外壳，来跟很多中小企业和个体户抢市场。</span></p><p><span>它们的无节制做大，利益只能惠及少数人，让更多的人来承担成本。为了保障更多人的利益和促进消费，需要有更严格的反垄断措施，并强化大型科技企业的社会责任意识。</span></p><p><span><strong><span>此外，扩大内需还得降低社会租金。</span></strong></span><span>这个租金是广义概念，除了土地租金外，还包括中间商赚差价的部分，也就是流通环节的租金。要降低流通环节的租金，除了降物流费用这些之外，还可以通过技术进步和业务创新来实现，比如带货直播，直接联结企业和买家。</span></p><p><span>当然了，技术进步和业务创新，降低土地租和中间商差价的同时，也需要防止互联网平台做大后形成新的垄断和新的技术租。</span></p><p><span>总而言之促进消费，既要扩大中等收入人群规模，也要挤泡沫、压租金，降低生产和消费的成本。前者重点是解决好收入分配环节的问题，尤其是资产价格泡沫导致的两极分化，后者需要压降土地租和流通环节的租金，但同时得注意技术租与挤泡沫之间的平衡。</span></p><p><span><strong><span>除了扩大消费外，还应该继续推动新基建建设</span></strong></span><span>。过去围绕着土地抵押融资而建设的老基建项目，在降低实体企业投入成本、打造全国统一的要素和产品市场等方面，做出了积极贡献，释放了正外部性。</span></p><p><span>但老基建的问题在于，之前扩张得太快了，尤其是在四万亿刺激之后，就开始出现了很明显的过剩。当时为了托底经济，很多项目是超前建设的，有的甚至是比原先规划建设的时间早十几年。</span></p><p><span>为了能有项目上马，很多边远地区也都修了公路桥梁。这导致老基建项目的边际投资回报率快速下降，产生的外部性也越来越弱。</span></p><p><span>老基建过剩后，能赚钱的项目也越来越少。如果一个基建项目不赚钱，社会资本是不愿意参与的，最终只能由地方政府来买单，这其中又存在着预算软约束的问题，导致地方债务不断堆积。</span></p><p><span>这也解释了为什么专项债一直没能拉动基建投资。使用专项债来投资基建项目，要求项目产生的现金流能够覆盖本息。项目现金流造假的问题普遍存在，但即使这样，还是没有足够多的项目，来对接专项债。给了地方额度，但就是很多没法用到基建上，只能不断扩大专项债资金的可用范围，基建投资也起不来。</span></p><p><span>都已经到了有钱没项目的地步了，确实没有必要再大搞老基建，性价比太低。不光拉动经济的效果有限，反而还会导致地方债务进一步累积，诱发金融风险，遗患无穷。</span></p><p><span>所以，未来应该发力新基建。和老基建一样，新基建也是利用政府“集中力量办大事”的组织和资源优势，完善相关基础设施，提高它的正外部性，降低社会成本。</span></p><p><span>但不一样的地方在于，新基建是面向未来的，更符合中国经济转型的需要，所带来的正外部性也更显着。</span></p><p><span>在新基建领域追加投入，能够促进科技创新和新兴产业崛起，新技术反过来又将赋能传统产业，提升经济的整体效率。比如5G基站建设，它是5G技术推广以及5G背后的应用市场不可或缺的前期投入基础。再比如，通过提高新能源汽车充电桩网络的建设密度，有助于释放新能源汽车的消费需求。</span></p><p><span>目前新基建尚属于新兴事物，这也是它被冠以“新”字的原因。它和传统基建投资相比规模还很小，剩余空间相当广阔。在老基建供给相对过剩，同时又有经济结构转型需求的当下，发力新基建兼具短期稳增长和长期潜在增长动能培育的双重功能。</span></p><p><span><strong><span>做好需求侧改革，不能只从需求方面发力，也得从供给上行动。</span></strong></span><span>很多时候，供给是先于需求出现的，典型的如刚刚上市的泡泡玛特，它的品牌使命中有“创造潮流，传递美好”，上市当日股价大涨，都快千亿市值了。</span></p><p><span>这次会议提出的“供给创造需求”，就是这个意思。但供给创新并不是件容易的事，因为它依赖于科技创新，而科技创新活动前期都是需要资金投入的，得让企业觉得后面能赚回来才行。</span></p><p><span><strong><span>科技创新首先要有市场规模作为基础。</span></strong></span><span>市场规模越大，能够让单位产品所需的创新成本被摊薄得越低，企业也更有动力通过科技创新来抢占市场份额。这也是为什么全球化之后，全球创新步伐会加快的原因。</span></p><p><span>中国在加入WTO之后，创新能力也得到提升。哈佛大学增长实验室的研究显示，中国出口产品的复杂性指数（可以作为衡量产品技术含量的指标），从2000年的全球第39名，上升到2018年的第18名。</span></p><p><span>所以，后面肯定会继续扩大对外开放，打造新的国际合作和竞争优势，通过开拓国际市场来反哺国内创新。</span></p><p><span><strong><span>前面提到的扩大内需，对于促进科技创新也很关键。</span></strong></span><span>必须要做好收入分配工作，严格落实“房住不炒”，提高低收入群体收入，推动区域经济协调发展等方式，来构建超大的国内市场规模。</span></p><p><span><strong><span>科技创新还得解决融资端的问题，核心是要发展资本市场。</span></strong></span><span>科创活动的融资，要和直接融资相匹配，所以要全面推广注册制，让那些创新型企业能够在资本市场上拿到钱，然后砸钱做创新，避免严苛的上市条件让创新型企业错失融资机遇，进而错过了未来的创新。</span></p><p><span>但资本市场支持创新企业，不是让它们乱圈钱的。要推动法制化建设，确定好游戏规则，在规则确定之后，就要大力打击上市公司的违法违规行为，免得市场上出现劣币驱逐良币和投机风盛行的现象。</span></p><p><span>有了好股票，还得有好的投资者，要坚持培育机构投资者。这样做的好处，一是能够平抑市场的波动，一个波动大的市场，很容易扰动人心，助长投机情绪。二是以长期投资和价值投资为准则的机构投资者，不仅能够为市场带来资金，还能帮助创新型企业优化经营模式。</span></p><p><span><strong><span>科技创新也需要制度上的保障。</span></strong></span><span>很多时候，科技创新是个长期活，让企业创新，得让它们对未来有个良性的预期，这需要政策的制定和实施时，能够保持连贯性和稳定性。试问朝令夕改，变来变去，谁敢去创新呢？</span></p><p><span>制定保障的前提是，界定好政府和市场的界限，明晰政府能做什么、不能做什么。加强产权保护，约束政府对产权的干预，支持企业家心无旁骛，以恒心办恒业，逐步建立起高标准的市场化、法治化和国际化营商环境。</span></p><p><span><strong><span>良好的基础设施环境，也能够推动科技创新。</span></strong></span><span>过去几年不少中国互联网企业崛起，除了中国庞大的人口优势外，也跟前期的基建投资有关，这些企业搭上了便车，享受到了基建带来的外部性。</span></p><p><span>比如短视频APP，显然离不开中国4G和5G通讯网络的普及。而诸多电商平台，除了网络基础设施普及外，还跟发达的物流体系，以及纵伸到基层的公路网络有关。如果物流很慢，买个东西都得等很久，网购和去实体店买相比，优势就得大打折扣了。</span></p><p><span>往后看，以5G、城际高速铁路等为代表的新基建设施，也会为一些新技术、新行业的出现提供科技创新环境。</span></p><p><span><strong><span>除科技创新外，组织效率变革，也能够提高供给水平，让供给更好创造需求。</span></strong></span><span>一是推动国企和科研院所改革，提高市场化水平，把长期受困于收入和付出不成正比的很多人的创新动力释放出来。二是逐步放松很多行业尤其是服务业的准入门槛，让市场力量进去，来提高供给效率。</span></p>
➜两月翻倍！下一只海天味业？
https://www.gelonghui.com/p/432932	21609
<p></p><p></p><p><b>作者：X科技实验室</b></p><p>来源：<span style="font-weight: 400;">亿欧网</span></p><p>上个月，国家市场监管总局正式起草平台经济领域反垄断指南，这意味着我们每天都在用的很多App的运营方式，将发生明显改变，同时大量国内科技巨头的经营策略，也势必要做出巨大调整。</p><p><img src="https://img3.gelonghui.com/9439a-2a2d9ba0-b6fa-4841-8ff3-edadb6c75caa.png"></p><p>中国的反垄断指南还在征集意见之中，不过，我们或许可以通过美国人的做法，来了解反垄断，以预判未来。</p><p><br></p><h3 style="text-align: center;"><span><font color="#3daad6">什么样的“垄断”会被重罚？</font></span></h3><p><span><strong><br></strong></span></p><p>迄今为止，对科技行业影响最深远的反垄断案，是从1998年到2001年的“合众国诉微软案”。</p><p><img src="https://img3.gelonghui.com/b1121-bec54581-add5-4c85-ab56-ee0a78f51cdf.jpg"></p><p>你猜，微软因为垄断遭到重罚，是哪款产品惹来的祸？</p><p>A. Windows 操作系统；B. Office 办公软件；C. IE浏览器</p><p><img src="https://img3.gelonghui.com/1ab79-010496ea-2b41-4dea-97c1-c65ec499be9c.jpg"></p><p>正确答案是C，三个选项里最糟糕的、最不能打的产品，IE浏览器。</p><p><b>其实IE推出前，微软也接受过反垄断调查，但总是不了了之。一个很重要的原因是，Windows在公平竞争的前提下真刀真枪赢来了市场地位。</b></p><p>而IE，无论其自身产品素质如何，却是借助Windows的力量才获得了浏览器市场的垄断位置。</p><p>浏览器，作为一种应用软件，本质上与办公软件或游戏软件一样，是独立于操作系统之外的。是否购买下载，下载谁家产品，应该由用户自己决定。</p><p>但95年，微软推出IE浏览器时，将它与已经垄断操作系统市场的Windows捆绑搭售。通过这一策略，微软直接干掉了当时在浏览器市场拥有90%市占率的网景。</p><p><img src="https://img3.gelonghui.com/0252f-611b4f3b-f7fe-4796-a658-ebeef3c76683.jpg"></p><p>这就属于用了不讲武德的阴招，让人无法忍受。</p><p>它意味着对于所有PC软件创业者来说，只要微软看上了你的赛道，就可以模仿出一款类似产品，然后利用绕不开的Windows系统，直接把你的产品整垮，哪怕它并不是一款足够优秀的产品。</p><p>在市场经济中，这种利用某一款产品的垄断地位，帮助自家其它产品打压竞品，获得另一品类的垄断地位，是绝对不能被容忍的。</p><p>前不久，美国司法部正式对谷歌提起反垄断诉讼，与当年微软案异曲同工的是，谷歌被认为利用安卓操作系统的垄断地位，要求移动设备制造商将谷歌作为设备的默认搜索入口，构成了不正当竞争。</p><p>回到中国，我们也可以思考一下：微信上不能转发抖音的链接，却能快速分享快手，微视的内容，请问这种做法和微软、谷歌对比，有哪些本质上的区别呢？大家可以在评论区和我们交流。</p><p><br></p><h3 style="text-align: center;"><span><strong><font color="#3daad6">“反垄断”的具体手段会是什么？</font></strong></span></h3><p><span><strong><br></strong></span></p><p><b>针对“反垄断”最有效的手段是什么？其实就一个字：拆。</b></p><p>继续讲刚才的故事。2000年，“合众国诉微软案”初审结果公布，微软被要求强制性地拆成两个公司，一个做系统的公司和一个经营其他软件的公司。</p><p><img src="https://img3.gelonghui.com/dc987-a0eae2ac-3ef9-47a0-8bed-f25e91dc99b2.jpg"></p><p><span>‍</span>不过这个判决并没有真正执行。</p><p>2000年适逢美国大选，当时与微软关系更密切的共和党代替民主党上台。第二年，微软与美国司法部达成了和解，避免了被拆分的命运。</p><p>微软之外，科技行业并不算太长的历史中，最知名的一次拆分发生在AT&amp;T公司身上。你也许没听过AT&amp;T，但你大概率知道，发明电话的人是贝尔，而AT&amp;T实质上就是贝尔创建的。</p><p><img src="https://img3.gelonghui.com/21acd-d4668f30-9348-4fce-a561-a431af41d6f5.jpg"></p><p>相当长一段时间里，这家公司在美国的体量与地位，可以类比为今天中国的“三大运营商+华为中兴+中科院信息工程研究所”，甚至还要更强。</p><p>现在你很少能听到这家曾经的巨无霸公司，主要是因为在1984年。根据美国的反垄断法，AT&amp;T被拆分，部分电信业务被剥离出公司，划分成了8家小公司。</p><p>通过欧美的一些案例观察，对待所有已经形成垄断的巨头公司，最有效的制裁手段，只有拆分。</p><p>像罚款这样的惩戒，对巨头来说根本无关痛痒。比如谷歌，过往几年，在欧洲经常受到反垄断调查，并且被罚了近百亿美元，但其根基一点没受到动摇。</p><p>而今年美国司法部的诉讼之所以令谷歌紧张，是因为有分析认为，最后的判决结果，很可能会强制谷歌出售全球市占率第一的Chrome浏览器以及部分广告业务。</p><p><img src="https://img3.gelonghui.com/5e53b-683d85fb-c183-4a41-898b-a1603dd91bc6.jpg"></p><p><br></p><h3 style="text-align: center;"><span><strong><font color="#3daad6">“反垄断”会怎样改变普通人的生活？</font></strong></span></h3><p><span><strong><br></strong></span></p><p>80后、90后应该会记得，当我们刚开始接触计算机和互联网时，无论是街头的网吧还是学校的微机室，总会用IE浏览器那个大大的“E”字来指代“上网”。</p><p>2010年之前，仿佛IE浏览器就是互联网，互联网就是IE浏览器。</p><p>如果没有针对微软的那场反垄断案，很可能到今天，所有人用的仍然是IE浏览器。而在没有选择与比较的情况下，我们不会觉得IE难用，只会认为浏览器就是这样，想象不到还有其它可能。</p><p><img src="https://img3.gelonghui.com/3b654-5846c277-30c5-4a7d-b08b-9f908f943e58.png"></p><p>垄断的原罪，往往并不是从你身上赚钱，赚很多钱，而是让整个市场失去可能性，让所有人失去选择的权利，让你认为本应如此，只能如此。</p><p>巨头的触角可以伸入任何行业，并通过本身拥有的资金，资源，品牌优势来碾压其他公司。</p><p>这样持续下去，如果有一天，当你打车、网购、订机票、叫外卖、刷短视频只能在某几个APP上实现的时候，企业是不是还愿意把用户的需求放在第一位，又有谁有权利来约束这些企业的行为？</p><p>所以，让我们一起来关注这份反垄断指南的后续吧，因为它真的与我们每个人的生活，都息息相关。</p><p></p><p></p><p></p>
➜拥有超10亿用户的专业剪辑工具平台，小影科技为何还熬不出头？
https://www.gelonghui.com/p/432934	26664
<p><b>作者：Juice</b></p><p>来源：<span style="font-weight: 400;">车东西</span></p><p><span>就在本月，汽车产业“缺芯”事件引起了极大关注甚至忧虑。</span></p><p><span>月初，多家媒体报道了南北大众因为芯片供应不足被迫临时停产的消息，在华为手机芯片被断供的阴霾之下，汽车缺芯事件迅速刺激起了产业界的敏感神经。</span></p><p><span>越来越多的汽车缺芯事件被报道出来，舆论则频繁探讨着汽车产业被“卡脖子”的话题，似乎中国汽车产业到了最严峻的时刻。</span></p><p><span>但车东西想说的是，关注也好，担忧也罢，在做出反应之前最关键的是要弄明白到底发生了什么。</span></p><p><span>汽车的车机系统、自动驾驶系统、发动机控制系统、车身控制系统都会用到芯片，同时芯片又分为用作计算的主动芯片，比如各种SoC/MCU/CPU，以及为控制器提供支持的被动芯片，比如各种电容电阻。</span></p><p><span>担忧汽车产业被卡脖子，害怕华为手机芯片断供再次上演，就必须要弄明白到底车上哪些子系统缺芯片了，缺的又是哪一类芯片，以及为什么缺。</span></p><p><span>这是目前大量报道所没有说清楚的事情，似乎只要芯片短缺，就是缺最关键的计算芯片，就是有人在使坏——故意卡中国脖子。</span></p><p><span>就在本周，车东西与多家新造车、自主车企电子电气架构的技术高管，还有德国、法国、美国Tier1企业的人士进行了大量的对话，试图找出“产业缺芯”背后真相。</span></p><p><br></p><h3 style="text-align: center;"><font color="#3daad6">核心部件不足 南北大众存缺芯停产风险</font></h3><p><strong><span><br></span></strong></p><p><span>12月5日，央视《经济信息联播》播报了一则消息让汽车芯片短缺问题进入到了公共视野中。报道称大众汽车受芯片供应不足的影响，上汽大众在12月4日开始停产，而一汽大众也在本月初进入了停产状态。</span></p><p><img src="https://img3.gelonghui.com/fe3f3-ae6f66f5-ce05-48c2-82c2-facb142a1dad.png"></p><p style="text-align: center;"><span>▲央视对大众停产的报道截图</span></p><p><span>甚至有媒体报道称，上汽大众的宁波、安亭工厂在内的所有工厂都已经全面停产。而也有媒体称一汽大众内部人士表示本周和下周将会停产，受影响的规模为2万辆，还表示一汽大众将会采取“保大弃小”的策略，优先生产大型车辆的生产。</span></p><p><span>此外，网上也有一张模煳的一汽大众内部邮件的照片流出，邮件显示一汽大众要求筹措工程师将这一邮件转发给所有的一配供应商进行调查，还要求一配供应商转发至下级供应商，调查内容为风险电子电器元件或原材料，包括芯片、二极管、半导体、端子、护套等。</span></p><p><span>其中瑞萨、意法半导体、恩智浦、英飞凌、泰科、安森美、安波福等</span><span>企业的名字都出现在了调查名单中。</span><span>文件显示的反馈时间为12月3日17:00前。</span></p><p><span>一时间，各种传闻不断，央视财经频道也采访了大众中国的公关部相关负责人。大众方面表示，由于新冠肺炎疫情带来的不确定性，影响到了一些特定汽车电子零部件的芯片供应，中国市场的复苏也推动了需求的增长，让芯片供应的问题更加严峻，导致一些汽车生产面临中断的风险。</span></p><p><span>大众方面的回应也算是证实了其目前存在芯片供应的问题，不过大众方面也表示情况并没有传闻中的严重，大众方面正在寻求解决方法。</span></p><p><span>现阶段，大众正在密切关注事态发展，已经和总部、相关供应商展开协调工作，积极采取应对措施。而相关车辆的客户交付目前还没有受到影响。</span></p><p><img src="https://img3.gelonghui.com/0cce2-056f9bb2-ccd1-48ed-b685-35db7aeaed16.png"></p><p style="text-align: center;"><span>▲大众集团回应称相关车辆的客户交付目前还没有受到影响</span></p><p><span><b>那么，目前芯片短缺仅仅是大众集团一家的问题还是整个国内汽车行业普遍存在的问题呢？</b></span></p><p><span>为了得到这个答案，车东西联系了多家车企和零部件供应商的工作人员了解情况，这些企业的工作人员给车东西的反馈是目前确实也存在一些芯片短缺的情况。</span></p><p><span>而此前有媒体报道称，吉利集团也在积极的争抢芯片资源。</span></p><p><span>从这些情况来看，目前国内的汽车生产领域确实存在芯片短缺的现象，而且还不是个例，已经蔓延到了全行业</span><span>。</span></p><p><strong><br></strong></p><h3 style="text-align: center;"><font color="#3daad6">车身控制系统缺芯片 车机和自动驾驶系统无影响</font></h3><p><strong><span><br></span></strong></p><p><span>“我们这边一切供应正常，L2级自动驾驶控制器上的芯片都没问题。”一位美国Tier1企业的员工这样告诉车东西，“不管是计算芯片，还是其他电子元器件都没缺货。”</span></p><p><span>汽车的车机系统、自动驾驶系统、发动机控制系统、车身控制系统都会用到芯片，同时芯片又分为用作计算的主动芯片，比如各种SoC/MCU/CPU，以及为控制器提供支持的被动芯片，比如各种电容电阻。</span></p><p><span>在上述美系Tier1之外，车东西还跟一家头部新造车公司，两家自主车企的电子电气架构工程师、车联网工程师、自动驾驶工程师进行了交流，他们一致的反馈是，自动驾驶和车机系统上用到的主动芯片都没有缺货，比如高通的820A、英伟达的Xavier。</span></p><p><span>“据我了解目前车机系统控制器上，只有一些被动芯片存在短缺问题。”一家总部位于北方的自主品牌员工这样告诉车东西，“不过供应商会优先保证量大车企的供应，影响主要在中小车企。”</span></p><p><img src="https://img3.gelonghui.com/e4994-f01af6b7-a4f7-45d3-89cd-d722e29c087a.png"></p><p style="text-align: center;"><span>▲高通骁龙820A开发板</span></p><p><span>按照此前的媒体报道，这次南北大众出现停产，主要是因为大陆的ESC和发动机ECU两个系统中缺乏芯片供应而断供造成的。</span></p><p><span>上述新造车公司的工程师向车东西表示，“我们也确实遇到了一些短缺情况，主要是各种车身控制器、底盘控制系统缺乏芯片，主动和被动都有。”</span></p><p><span>最后有几个关键细节需要注意。</span></p><p><span>首先，自动驾驶芯片和智能座舱芯片主要是英伟达、Mobileye 和高通这些玩家提供，而这些芯片在车上的占比并不算多，一辆车上安装一个自动驾驶芯片和智能座舱芯片就够用了，需求并不算大，因而不缺货也比较好理解。</span></p><p><img src="https://img3.gelonghui.com/d03bc-88312288-ee65-48d1-8ed3-288ac4ba1e17.jpg"></p><p style="text-align: center;"><span>▲英伟达自动驾驶控制器，带logo的主芯片是Xavier</span></p><p><span>而车企对于车身控制芯片的需求则比较多，新近生产的燃油车至少需要20个车身控制器，换言之也就是至少需要20个芯片，需求量相对比较大，因而存在短缺也有可能。而这些芯片的生产企业还是一些传统的车载芯片玩家如英飞凌、恩智浦、瑞萨、意法半导体等。</span></p><p><span>其次，用于计算的主动芯片比电容电阻等被动芯片更加关键。</span></p><p><span>“电容电阻断供，我们很快就能找到替代品。但计算芯片（主动芯片）</span><span>就那么几个供应商，一旦短缺根本没有替代。</span><span>即使有替代，对研发和生产流程也会产生很大的影响。</span><span>”上述新造车公司工程师这样告诉车东西。</span></p><p><span>按照他的说法，替换一个电容电阻，车企只需要重做一两项测试即可。但是如果要替换一个嵌入式系统的计算芯片，从软件开发到后续的各种测试全部需要重做，极其复杂，所以车企只能停产等待。</span></p><p><span>再次，即使都是主动芯片，自动驾驶芯片和车机系统芯片则更为重要。</span></p><p><span>车辆的底盘控制系统、空调系统、车身硬件（比如车窗门锁）背后都有一个控制器，控制器内部会有一个计算芯片（或者是MCU）进行控制，这些芯片运算的软件相对简单，对算力的需求远远低于自动驾驶、车机系统（座舱）上的主动芯片。</span></p><p><span>所以即使是卡脖子，这些车身控制芯片相对容易被替代。并且长远来看，自动驾驶、车机系统的芯片将逐渐成为汽车的核心芯片，在中央计算架构的趋势下，一两颗主芯片完全可以把现在分布式电子电气架构上的所有MCU和计算芯片所取代。</span></p><p><span>这也是为什么特斯拉选择自己做FSD自动驾驶芯片，而不是车身控制芯片的原因。</span></p><p><span><b>汽车芯片的未来，大概率是握在能够提供大算力的芯片企业手中，现阶段不管是高通、英伟达，还是华为、英特尔，都在往这些方向发力。中国也出现了像是地平线、黑芝麻、芯驰等创企。</b></span></p><p><strong></strong><strong><strong><br></strong></strong></p><h3 style="text-align: center;"><font color="#3daad6">疫情打乱了需求预测 长周期元件普遍短缺</font></h3><p><strong><span><br></span></strong></p><p><span>弄明白了到底是哪些芯片短缺，那么到情况有多严重呢？</span></p><p><span>首先我们来看看上面提到的这些芯片为什么会缺货。</span></p><p><span>汽车芯片是非常精密的产业，从生产到测试再到交付，这一过程不能有任何环节出错，因而芯片的交付周期至少需要6个月。</span></p><p><span>这也就是说，今年12月交付的芯片，都是今年6月份下的订单。</span></p><p><span>“上半年正是疫情严重时期，汽车产销受到明显影响，车企在6月份的时候无法判断12月份的销量情况，给Tier1下的订单就很小，Tier1向Tier2芯片企业下的单子也小。”上述法国Tier1的技术高管这样告诉车东西。</span></p><p><span>得益于我国政府的出色能力，下半年中国疫情被控制住，汽车产销迅速恢复。</span></p><p><span>年初，乘联会预测今年的零售销售同比将会下滑8%，较2019年末1%的预期下调了9个百分点。去年国内汽车总销量为2273.6万辆。也就是说，乘联会认为，今年的汽车销量将会为2091.7万辆，将会缩水约200万辆。</span></p><p><span>但实际情况是，7～11月，国内汽车销量稳步增长，11月份，国内车企共计售出了208.1万辆车，与去年同期相比还实现了8%的增长。</span></p><p><span>上汽集团、东风集团、长安集团、广汽集团、吉利汽车、长城汽车、奇瑞汽车、比亚迪汽车等车企11月的销量均实现了同比增长，最多的同比增长达到了36%。</span></p><p><img src="https://img3.gelonghui.com/2ac1d-4326c1c7-df86-47eb-b921-7a3a2ef3676a.jpg"></p><p style="text-align: center;"><span>▲历年车市销量走势图（图源乘联会）</span></p><p><span>销量增长了，车企就开始加大芯片订单，但在6月份之后下的订单，肯定是12月份之后才能交付。所以12月份就出现了现在各大车企和Tier1向Tier2的芯片企业抢购芯片的现象，造成了短缺。</span></p><p><span>某德国Tier 1员工就明确表示，他们完全可以按时供应今年6月份下的订单，但突然新增的需求就没法满足。</span></p><p><span>他也向车东西举了一个例子来说明今年下半年车企对零部件的需求变化。他表示，去年有个车企一整年只向其订购了6万套零部件，而今年10月份的时候，这家车企单月就订购了10万套，几天之后，这10万套订单就涨到了15万套。</span></p><p><span>也就是说这家车企今年1个月的订单就是去年全年的两倍还多，今年车企对零部件的需求情况从这里也可见一斑。</span></p><p><span>某法国Tier 1内部人士告诉车东西，今年第三季度该公司的营收是历史第二好的成绩，在这样的环境下还能取得这样的成绩，也能看出车企的需求有多旺盛。</span></p><p><span>上述法国Tier1技术高管说道，“对于芯片这类长周期部件来说，临时提需求肯定供应不上。”</span></p><p><span>也正是因为长周期，所以本次芯片短缺潮对中国车企的影响短时间内并不会消失，至少需要半年才能缓解。</span></p><p><span>看到这里，其实汽车芯片的缺货程度，以及影响都已经非常明显了。</span></p><p><span>除了这个根本性的原因，今年也还有一些其他的情况影响到了芯片企业的生产。10月底，日本半导体公司旭化成厂房起火，烧了3天才被扑灭，工厂已经停工了，而这一工厂所生产的晶圆正是芯片的重要原材料，相应也影响到了芯片的生产。</span></p><p><img src="https://img3.gelonghui.com/fa0bd-9777169a-0aea-4f04-9d16-da153db91196.jpg"></p><p style="text-align: center;"><span>▲日本半导体公司旭化成厂房起火后的样子</span></p><p><span>此外，由于疫情的影响东南亚的芯片组装厂停产，而此前意法半导体的工厂也发生了停产事故，这都影响到了芯片的供应。</span></p><p><span>目前各大Tier 1都已经在想办法增加产量来解决这个问题。某德国Tier 1员工向车东西介绍，他们公司正在想尽一切办法来提升生产效率，以此保证给客户供货，现已经采用了空运的方式来压缩运输的时间，减少生产周期，甚至还派了员工去芯片厂进行督导生产。</span></p><p><span>针对大众集团存在停产风险的事件，大陆集团回应称：“半导体厂商已经开始着手扩大产能来应对突然增加的供给需求，但考虑到半导体行业正常的交付时间，目前供应短缺的情况将在6～9个月的时间内改善。因此预计到2021年供应形势依然严峻。“</span></p><p><img src="https://img3.gelonghui.com/fed9b-d9a5f54d-b613-44fc-a448-f564ee99a8d5.png"></p><p style="text-align: center;"><span>▲大陆集团预计半导体产能扩充还需半年左右</span></p><p><span>大陆集团将会和客户继续保持紧密透明的沟通，寻找双方都能接受的解决方案，以应对目前半导体短缺的问题。</span></p><p><span>最后，上述法国Tier 1人士也强调：由于长周期电子元件的存在，这一产品的生产很容易受到销量变化的影响，汽车产业领域经常会出现某一个零部件短缺而让工厂临时性停工的现象。今年因为华为芯片的事件，让国内对这一现象非常关注，实际上，这在汽车行业比较常见。</span></p><p><span><br></span></p><h3 style="text-align: center;"><span><b><font color="#3daad6">结语：汽车缺芯与华为断供不同 未来芯片需求量会锐减</font></b></span></h3><p><span><br></span></p><p><span>南北大众的芯片短缺停产消息让芯片短缺潮这一现象再次进入公众视野，不过这件事与华为芯片断供存在明显区别，这次短缺并不是因为其他国家的限制，而是整个行业对今年汽车产业的发展产生了错误的判断而导致。</span></p><p><span>而且从具体上来看，本次断供缺的多是一些车身控制方面的芯片，事关汽车产业未来发展的自动驾驶、智能座舱芯片并不短缺，这也就是说，本次芯片短缺并不会影响汽车产业的未来发展方向。</span></p><p><span>目前，多个车企都已经在探索更新的汽车架构，一个控制器就能控制全车多个零部件，在这种架构下，车企对于芯片的需求将会大幅减少。</span></p>
➜社区团购，凛冬将至
https://www.gelonghui.com/p/432951	46773
<p><b>作者：赵彬&nbsp;</b></p><p>来源：<span style="font-weight: 400;">期货日报</span></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p><span>生猪期货真的来了！12月12日，大商所就生猪期货合约及相关规则公开征求意见。根据合约细则估算，每手合约总价值或超过50万元，投资门槛或在每手3.5万元之上。</span></p><p><span><br></span></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><h3 style="text-align: center;"><strong><span><font color="#3daad6">大商所就生猪期货合约及相关规则公开征求意见</font></span></strong></h3><div><strong><span><font color="#3daad6"><br></font></span></strong></div><p><span>12月12日，大连商品交易所（下称“大商所”）发布《大连商品交易所生猪期货合约(征求意见稿)》《大连商品交易所生猪期货业务细则(征求意见稿)》等8份文件，对生猪期货合约及相关规则公开征求意见。</span></p><p><img src="https://img3.gelonghui.com/4c6fd-f495141f-03e9-4016-87fe-c25acba4e642.jpg"></p><p><span>据此次公布的合约及业务细则征求意见稿，生猪期货合约交易代码为LH，交易单位为16吨/手，最小变动价位是5元/吨，合约涨跌停板幅度为上一交易日结算价的4%，最低交易保证金为合约价值的5%。合约月份为1、3、5、7、9、11月，最后交易日和最后交割日分别为合约月份倒数第4个交易日和最后交易日后第3个交易日，交割方式为实物交割。</span></p><p><span>根据合约细则估算，每手合约总价值或超过50万元，投资门槛或在每手3.5万元之上。</span></p><p><span>交割质量标准上，大商所参照《瘦肉型猪活体质量评定（GB/T32759-2016）》指标体系，并在广泛开展调研基础上，针对生猪品种特点，贴近现货市场习惯设计了交割质量指标，其中采用了现货习惯中简单有效的外观、体重等指标，保证交割效率，减少交割争议。</span></p><p><span>作为我国首个以活体为交易标的的期货品种，生猪期货综合借鉴、采用国内国际市场上成熟的交割模式，在交割方式上实行车板交割与厂库交割并行，每日选择交割和一次性交割相结合，并配以期转现交割。其中，为贴近现货市场贸易习惯，保证交割量充足，从交割月第一个交易日至生猪合约最后交易日的前一交易日，客户可申请每日选择交割。合约最后交易日后，所有未平仓的生猪期货合约持有者进行一次性交割，交割结算价采用该期货合约交割月最后十个交易日所有成交价格的加权平均价。</span></p><p><span>为确保市场平稳运行，上市初期，大商所将在现有合约规则规定的基础上对生猪期货的保证金、涨跌停板幅度等进行适度上调，以满足风险管理的需要。持仓限额制度设计上，采用从严限仓的原则，自合约上市至交割月份前一个月前，持仓限额为500手（7月合约200手）；交割月份前一个月第一个交易日起至第10个交易日前，持仓限额为125手（7月合约50手）；交割月份前一个月第10个交易日起至该月最后一个交易日，持仓限额为30手（7月合约10手）；进入交割月后，持仓限额10手（7月合约5手）。</span></p><p><span>市场人士表示，生猪期货的上市对于服务生猪产业具有重要意义。一方面，通过发挥价格发现功能，为市场提供公开、透明和连续的价格参考。另一方面，生猪养殖企业可以利用生猪期货套期保值，转移价格波动风险，合理控制养殖规模，从而实现通过市场化手段优化资源配置，促进行业的长远健康发展。</span></p><p><span>大商所相关负责人表示，历经近20年跟踪和研究，在全面深入市场调研及广泛征求意见、充分论证基础上，大商所完成了生猪期货合约规则设计工作。下一步，大商所将梳理并研究各方意见和建议，进一步完善合约和规则，与各方共同做好上市前各项准备工作，确保生猪期货平稳上市和安全运行。生猪期货上市后，大商所将强化一线监管，严控风险，维护市场稳定运行，为相关产业主体和投资者提供公开、公平和有效的价格发现与避险平台，助力产业转型升级和实体经济高质量发展。希望产业企业和投资者理性、规范参与市场，共同呵护这个与国计民生息息相关且为国内首个活体交割的期货品种，保障其功能作用的有效发挥。</span></p><h3 style="text-align: center;"><strong><span><font color="#3daad6"><br></font></span></strong></h3><h3 style="text-align: center;"><strong><span><font color="#3daad6">我国生猪期货与其他国家的有何区别？</font></span></strong></h3><div><strong><span><font color="#3daad6"><br></font></span></strong></div><p><span>目前国际上主要由三家交易所上市了生猪期货品种，分别是美国芝加哥商业交易所的瘦肉猪期货、德国汉诺威商品交易所的生猪期货以及韩国交易所的瘦肉猪期货。我国生猪期货品种与其他国家品种除了有合约规格方面的差异外，还有一个明显差异就是我国生猪期货的交割方式为实物交割，而美国、韩国均采用现金交割。</span></p><p><img src="https://img3.gelonghui.com/c54af-1415868d-2d34-49d9-bac5-01b63e4dd0e3.png"></p><p><strong><span>遇到四种情形可采取紧急措施</span></strong></p><p><span>在12月12日发布的《大连商品交易所生猪期货业务细则(征求意见稿)》中，针对市场关注的风险管理，大商所提出，若某生猪期货合约出现连续的同方向涨跌停板单边无连续报价的情况，除按照《大连商品交易所风险管理办法》采取有关措施外，还可以采取暂停交易、暂停挂牌新合约等措施。</span></p><p><span>在生猪期货交易过程中，出现以下情形之一的，交易所可以采取紧急措施化解风险：</span><span>第一，</span><span>生猪的现货价格、期货价格或者期现货基差明显超出合理范围；</span><span>第二，</span><span>有根据认为出现操纵期货交易价格等违法违规行为，并且对市场正在产生或者即将产生重大影响；</span><span>第三，发生生猪重大疫情或者一定比例指定交割仓库及指定车板交割场所暂停交割业务；第四，</span><span>生猪相关法规政策出现变化，对生猪期货运行正在产生或者即将产生重大影响。</span></p><p><span>大商所表示，出现上述情形时，交易所总经理可采取调整开市收市时间、暂停交易、调整交易时间、暂停挂牌新合约、调整涨跌停板幅度、调整交易保证金、调整升贴水、暂停开仓等措施，并可在已挂牌合约上实施。</span></p><p><span>采取终止交易措施的，终止交易当日结算时，交易所可以对其全部或者部分合约月份持仓进行平仓。</span></p><p><span>此外，对于生猪期货合约，交易所按照有关规定调整涨跌停板幅度时，可单向或双向、同比例或不同比例调整；按照有关规定调整交易保证金时，可单边或双边、同比例或不同比例、部分会员或全部会员调整。</span></p><h3 style="text-align: center;"><strong><span><font color="#3daad6"><br></font></span></strong></h3><h3 style="text-align: center;"><strong><span><font color="#3daad6">企业热盼生猪期货上市</font></span></strong></h3><div><strong><span><font color="#3daad6"><br></font></span></strong></div><p><span>一直以来，产业各方都十分期盼上市生猪期货，以平抑生猪价格波动，助力生猪行业长期稳定发展。这一期待即将变为现实。</span></p><p><span>我国是全球第一大生猪生产国与消费国，生猪出栏量及猪肉消费量占全球的比重均在50%以上，但长期以来，我国生猪价格波动较大，生猪现货价格的大幅波动给产业企业带来极大不确定性，生产经营难以稳定，不利于行业的健康发展。</span></p><p><span>“生猪品种涉及多个行业，随着近两年我国规模化养殖的兴起，大型养殖场也在寻找相应的金融工具规避经营中的风险，比如牧原、新希望等大型企业目前已组建了专业的期货团队为养殖保驾护航。”一德期货生鲜品事业部分析师侯晓瑞告诉记者，豆粕和玉米都是猪饲料的主要原料，是农产品板块较为活跃的品种，生猪期货的上市，对整体产业链有着深刻的影响，比如，养猪场可以利用期货市场进行套期保值，一定程度上锁定养殖利润，饲料厂可以根据猪价和下游企业的养殖情况进行生产和备货，有效规避价格波动对企业造成的风险。</span></p><p><span>随着我国经济快速发展，生猪养殖行业品种、养殖、疾控、环保、销售等环节逐渐规范统一，生猪产业的集约化、规模化发展也成为必然，大型养殖企业数量增加，产业面临的价格风险也会大幅增长。</span></p><p><span>许多业内人士纷纷表示，生猪期货的上市，对于整个行业来说无疑是雪中送炭，能够帮助大型企业更好地根据价格趋势的变化，利用深层次的交易策略规避风险，实现稳定增长，从而在扩张道路上能够走得更加顺利。</span></p>